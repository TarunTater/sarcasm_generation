Sarcasm Detection Model Restored
Batch inverse rewards score*** 0.8548473
Old  loss*** tensor(2227.7029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.3458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675866
Old  loss*** tensor(1109.3456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(962.4534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82783115
Old  loss*** tensor(3557.2878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2944.8337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653445
Old  loss*** tensor(1418.7135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.6759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8262092
Old  loss*** tensor(2695.4080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2226.9707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8301105
Old  loss*** tensor(3164.5398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2626.9177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8351544
Old  loss*** tensor(2282.5435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.2762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7366579
Old  loss*** tensor(5501.5889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4052.7891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89710045
Old  loss*** tensor(772.2116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.7514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.884078
Old  loss*** tensor(2815.0806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2488.7510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7994511
Old  loss*** tensor(4377.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.8950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87324286
Old  loss*** tensor(1172.1544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1023.5755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7709359
Old  loss*** tensor(4917.4829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3791.0640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8214246
Old  loss*** tensor(3870.4980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3179.3223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677424
Old  loss*** tensor(914.3896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(793.4547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716787
Old  loss*** tensor(1412.2433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.0225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88305223
Old  loss*** tensor(1693.7246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1495.6473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81100345
Old  loss*** tensor(3076.3455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2494.9268, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8623068
Old  loss*** tensor(1164.7660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1004.3856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867121
Old  loss*** tensor(124.2945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(110.2134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8843274
Old  loss*** tensor(330.5389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(292.3046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877947
Old  loss*** tensor(351.8020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(312.3279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82231486
Old  loss*** tensor(4642.7524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3817.8042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8945681
Old  loss*** tensor(1101.4248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.2995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8331976
Old  loss*** tensor(3901.0715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3250.3635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79079705
Old  loss*** tensor(4180.6577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3306.0518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8835987
Old  loss*** tensor(1723.2368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.6498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8569101
Old  loss*** tensor(2258.9661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1935.7308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8705797
Old  loss*** tensor(1942.3796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1690.9963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8355657
Old  loss*** tensor(1534.0454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1281.7957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8737527
Old  loss*** tensor(1259.9978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1100.9265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85856414
Old  loss*** tensor(1695.1155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1455.3654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82254565
Old  loss*** tensor(3396.5037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2793.7793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82584214
Old  loss*** tensor(2452.7512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2025.5853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84758914
Old  loss*** tensor(1388.7450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1177.0852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85629475
Old  loss*** tensor(1585.4762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.6349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79790413
Old  loss*** tensor(4294.0942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3426.2756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88851213
Old  loss*** tensor(1460.3301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1297.5210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503479
Old  loss*** tensor(1331.5879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1132.3130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8258394
Old  loss*** tensor(2570.6177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2122.9175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8167229
Old  loss*** tensor(2913.4932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2379.5166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8104211
Old  loss*** tensor(4117.9185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3337.2480, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880897
Old  loss*** tensor(1050.7816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(933.1884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7520124
Old  loss*** tensor(4521.6064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3400.3040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79957366
Old  loss*** tensor(3224.2078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2577.9917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85242605
Old  loss*** tensor(2687.8220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.1694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86351204
Old  loss*** tensor(647.5026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(559.1263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85325146
Old  loss*** tensor(2568.3088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2191.4133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670354
Old  loss*** tensor(2950.0081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2557.7615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781139
Old  loss*** tensor(2787.7427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2447.9556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024302
Old  loss*** tensor(2205.2170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1769.5328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8894766
Old  loss*** tensor(1015.7483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(903.4843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78877175
Old  loss*** tensor(3401.6101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.0940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88150895
Old  loss*** tensor(92.7722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(81.7795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82756263
Old  loss*** tensor(4496.9131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3721.4773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7173005
Old  loss*** tensor(4904.8281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3518.2356, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7528206
Old  loss*** tensor(4158.2832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3130.4414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650203
Old  loss*** tensor(968.4895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.7631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.761392
Old  loss*** tensor(4478.2480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3409.7021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88799787
Old  loss*** tensor(1478.9032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1313.2629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8317431
Old  loss*** tensor(1862.1968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.8694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8134389
Old  loss*** tensor(1921.6526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.1470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384267
Old  loss*** tensor(3446.9858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2890.0449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85356367
Old  loss*** tensor(1959.3293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1672.4124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8103186
Old  loss*** tensor(1072.7186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.2438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739017
Old  loss*** tensor(1131.6938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(988.9892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631039
Old  loss*** tensor(2707.2395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2336.6292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88792187
Old  loss*** tensor(797.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(707.8211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8098682
Old  loss*** tensor(2840.6602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2300.5603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87114227
Old  loss*** tensor(1510.6965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.0316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8335581
Old  loss*** tensor(1663.7360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.8206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87893885
Old  loss*** tensor(1507.7178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1325.1918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8554658
Old  loss*** tensor(2295.1072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1963.3857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455646
Old  loss*** tensor(4195.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3547.1580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8893378
Old  loss*** tensor(623.0733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.1226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890675
Old  loss*** tensor(920.1992, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.1191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792883
Old  loss*** tensor(606.1422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.9738, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616063
Old  loss*** tensor(1594.0970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.4840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83826303
Old  loss*** tensor(1974.7836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.3881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8983063
Old  loss*** tensor(786.5920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.6006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890126
Old  loss*** tensor(900.1548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(801.2512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534673
Old  loss*** tensor(3375.1299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2880.5630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87956476
Old  loss*** tensor(807.5795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(710.3185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8135587
Old  loss*** tensor(2797.7102, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2276.1016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85067
Old  loss*** tensor(1168.4998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(994.0077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8468951
Old  loss*** tensor(816.6087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(691.5819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815698
Old  loss*** tensor(4784.2793, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3902.5271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87989753
Old  loss*** tensor(1931.2419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1699.2950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783145
Old  loss*** tensor(460.6234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.5722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165285
Old  loss*** tensor(3488.7612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2848.6729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622481
Old  loss*** tensor(1633.1860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1408.2115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7962564
Old  loss*** tensor(3414.6184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2718.9119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8269447
Old  loss*** tensor(2957.2322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2445.4675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89061475
Old  loss*** tensor(723.3849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.2573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89385253
Old  loss*** tensor(255.9698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(228.7993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8970889
Old  loss*** tensor(435.4607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.6470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8293066
Old  loss*** tensor(2136.6548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1771.9419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519342
Old  loss*** tensor(3568.8555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3040.4299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000133
Old  loss*** tensor(724.4032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(651.9725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653857
Old  loss*** tensor(3206.3940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2774.7676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7798865
Old  loss*** tensor(2755.4312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2148.9236, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460883
Old  loss*** tensor(1140.4622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(964.9317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853756
Old  loss*** tensor(273.2371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(241.9174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8923757
Old  loss*** tensor(1375.9562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.8699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520416
Old  loss*** tensor(1215.3258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.5082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502917
Old  loss*** tensor(1737.3246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.2327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8479337
Old  loss*** tensor(1711.2466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1451.0237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86890936
Old  loss*** tensor(1211.9623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.0853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617903
Old  loss*** tensor(1771.0306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1526.2571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8247942
Old  loss*** tensor(2351.6492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1939.6266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.761152
Old  loss*** tensor(2940.5312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2238.1914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8909987
Old  loss*** tensor(438.0669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.3170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7491846
Old  loss*** tensor(4237.6606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3174.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86369514
Old  loss*** tensor(2261.0959, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1952.8976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8382511
Old  loss*** tensor(1384.6853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1160.7140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78939366
Old  loss*** tensor(4145.5107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3272.4399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86994696
Old  loss*** tensor(3938.3472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3426.1531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7897576
Old  loss*** tensor(3095.6099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2444.7815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8379924
Old  loss*** tensor(3824.3408, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3204.7686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86829746
Old  loss*** tensor(1454.6547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1263.0730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7951585
Old  loss*** tensor(1971.4772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1567.6368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8551464
Old  loss*** tensor(2263.1296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1935.3071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87479115
Old  loss*** tensor(1122.0583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.5667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849978
Old  loss*** tensor(672.6581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.3009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.859813
Old  loss*** tensor(2488.5437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.6821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86699796
Old  loss*** tensor(1573.2596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1364.0129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8288497
Old  loss*** tensor(4049.8188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3356.6909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83891094
Old  loss*** tensor(2951.1492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2475.7512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77993524
Old  loss*** tensor(4831.1514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3767.9851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8036567
Old  loss*** tensor(4082.9956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3281.3267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858005
Old  loss*** tensor(1303.9741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1118.8163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8344223
Old  loss*** tensor(2112.6448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1762.8379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90383136
Old  loss*** tensor(1194.1427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.3036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84278333
Old  loss*** tensor(1262.8782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.3326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613007
Old  loss*** tensor(1839.5792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.4309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86175144
Old  loss*** tensor(2361.3215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.8722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741199
Old  loss*** tensor(1142.1505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(998.3765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87758106
Old  loss*** tensor(1303.3956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.8353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82383883
Old  loss*** tensor(3980.2942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3279.1208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85931385
Old  loss*** tensor(792.8221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(681.2830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890549
Old  loss*** tensor(540.7840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.7867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85357535
Old  loss*** tensor(1746.7753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1491.0043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9148773
Old  loss*** tensor(774.9144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.9516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8279735
Old  loss*** tensor(2043.3414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.8325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78918934
Old  loss*** tensor(4418.1968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3486.7937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824211
Old  loss*** tensor(1386.0276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1223.0599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520215
Old  loss*** tensor(2118.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1804.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579209
Old  loss*** tensor(2442.5249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2095.4932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8107079
Old  loss*** tensor(2553.3098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.9885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88054025
Old  loss*** tensor(4236.4624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3730.3757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699254
Old  loss*** tensor(1076.7810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(936.7191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9082266
Old  loss*** tensor(1177.3813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1069.3291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83629906
Old  loss*** tensor(4527.9761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3786.7422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76444536
Old  loss*** tensor(4103.3652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3136.7986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81318367
Old  loss*** tensor(3581.7012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2912.5808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8888195
Old  loss*** tensor(371.9869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(330.6292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828106
Old  loss*** tensor(383.5654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(338.6156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8992014
Old  loss*** tensor(866.0461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(778.7499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.854328
Old  loss*** tensor(1689.8081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.6504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8546822
Old  loss*** tensor(4111.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3513.6494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87579226
Old  loss*** tensor(1008.5211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.2549, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8761543
Old  loss*** tensor(1393.2445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.6971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883014
Old  loss*** tensor(179.4530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(159.4084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7940533
Old  loss*** tensor(4549.8481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.8220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87624234
Old  loss*** tensor(149.4232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(130.9310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77795386
Old  loss*** tensor(4106.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3194.4277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8623364
Old  loss*** tensor(1412.1367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1217.7369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619219
Old  loss*** tensor(2331.9209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2009.9337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84945107
Old  loss*** tensor(1311.0159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1113.6438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523905
Old  loss*** tensor(1618.2212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1379.3564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.803174
Old  loss*** tensor(2932.0725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2354.9644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506232
Old  loss*** tensor(2230.4924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.3086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82593036
Old  loss*** tensor(2031.4031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.7975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80843866
Old  loss*** tensor(4565.9409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3691.2832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82892144
Old  loss*** tensor(2742.1292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2273.0095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85500574
Old  loss*** tensor(939.7343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.4782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89483815
Old  loss*** tensor(907.2784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(811.8674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88147223
Old  loss*** tensor(2337.6443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2060.5686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8406925
Old  loss*** tensor(1071.8257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(901.0758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83437824
Old  loss*** tensor(2746.2727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.4302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76238096
Old  loss*** tensor(4492.3418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3424.8757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813385
Old  loss*** tensor(1425.1144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1256.0082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750682
Old  loss*** tensor(1467.9835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1284.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89367604
Old  loss*** tensor(580.5413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.8159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7263217
Old  loss*** tensor(3041.8354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2209.3511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77791417
Old  loss*** tensor(3507.2056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2728.3049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865291
Old  loss*** tensor(1741.2008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1543.6251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7840085
Old  loss*** tensor(3355.0142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2630.3596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870998
Old  loss*** tensor(1192.2074, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1038.4103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701017
Old  loss*** tensor(175.2602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(152.4942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88440925
Old  loss*** tensor(434.4123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(384.1983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624172
Old  loss*** tensor(968.4487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.2068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9047946
Old  loss*** tensor(394.1606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(356.6344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80576706
Old  loss*** tensor(3030.2485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2441.6746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8977527
Old  loss*** tensor(1132.4713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.6792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8973272
Old  loss*** tensor(1268.5399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1138.2954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9058062
Old  loss*** tensor(1692.4609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1533.0416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85521173
Old  loss*** tensor(1417.4846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1212.2495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831557
Old  loss*** tensor(1823.0687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.0536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624527
Old  loss*** tensor(1467.2390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1265.4242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7739877
Old  loss*** tensor(3469.2617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2685.1660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81032526
Old  loss*** tensor(2601.6729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2108.2012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697492
Old  loss*** tensor(736.6735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(640.7211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87923676
Old  loss*** tensor(635.6291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(558.8685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665472
Old  loss*** tensor(1915.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.9702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76496196
Old  loss*** tensor(2282.3406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1745.9037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91412187
Old  loss*** tensor(905.8223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(828.0320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.824002
Old  loss*** tensor(3465.1848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2855.3193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82397366
Old  loss*** tensor(3872.0396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3190.4585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839586
Old  loss*** tensor(530.6498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(469.0725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89577144
Old  loss*** tensor(535.1878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(479.4059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85490227
Old  loss*** tensor(762.0046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(651.4395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85468715
Old  loss*** tensor(572.9890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.7263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86610067
Old  loss*** tensor(1388.4292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1202.5194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8996489
Old  loss*** tensor(964.0859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(867.3389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89675945
Old  loss*** tensor(903.2981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(810.0411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80195713
Old  loss*** tensor(2224.7498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1784.1539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7936765
Old  loss*** tensor(4863.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3859.7766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87120676
Old  loss*** tensor(2008.0784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1749.4514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8912255
Old  loss*** tensor(605.5373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(539.6703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87310135
Old  loss*** tensor(1030.2333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.4980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7806746
Old  loss*** tensor(4825.9360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3767.4856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80641717
Old  loss*** tensor(2885.7358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2327.1069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8197456
Old  loss*** tensor(3956.3108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3243.1685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631545
Old  loss*** tensor(1784.2706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1540.1012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79158247
Old  loss*** tensor(3482.2656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2756.5005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8117092
Old  loss*** tensor(3273.5781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2657.1936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178457
Old  loss*** tensor(2377.3362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1944.2942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8524241
Old  loss*** tensor(2111.6375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1800.0106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8353338
Old  loss*** tensor(2059.9387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.7365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100773
Old  loss*** tensor(3093.2424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2505.7656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.829646
Old  loss*** tensor(2805.5601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2327.6216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89381135
Old  loss*** tensor(2806.6965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2508.6572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81087273
Old  loss*** tensor(2452.8853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1988.9778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89310455
Old  loss*** tensor(712.8232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(636.6257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7953026
Old  loss*** tensor(4117.5864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3274.7273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7795932
Old  loss*** tensor(3789.6191, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2954.3613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91055214
Old  loss*** tensor(731.4994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.0684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8450766
Old  loss*** tensor(1619.6495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1368.7279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852589
Old  loss*** tensor(1707.9872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.0109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8722585
Old  loss*** tensor(1983.4202, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1730.0551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88270783
Old  loss*** tensor(726.2303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(641.0492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929131
Old  loss*** tensor(1148.1396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.1890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84135604
Old  loss*** tensor(3152.3967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2652.2881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879495
Old  loss*** tensor(892.2734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(784.7501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8681336
Old  loss*** tensor(1116.2395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(969.0450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9342906
Old  loss*** tensor(1014.4216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(947.7645, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8253732
Old  loss*** tensor(2311.8955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1908.1765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795943
Old  loss*** tensor(1307.3210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.9122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841901
Old  loss*** tensor(4406.7925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3896.4421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9001454
Old  loss*** tensor(565.9859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(509.4696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8034235
Old  loss*** tensor(4661.2144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3744.9292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8904845
Old  loss*** tensor(391.9532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(349.0283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81691194
Old  loss*** tensor(4587.8291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3747.8523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901205
Old  loss*** tensor(629.2185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(560.0803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562499
Old  loss*** tensor(1274.6146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.3887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7988069
Old  loss*** tensor(3240.1428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2588.2485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862547
Old  loss*** tensor(1715.6315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1479.8127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9048723
Old  loss*** tensor(587.6588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(531.7561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8338294
Old  loss*** tensor(3639.9573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3035.1035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8230941
Old  loss*** tensor(3489.9604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2872.5659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7836633
Old  loss*** tensor(4872.0347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3818.0347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9191922
Old  loss*** tensor(892.0743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(819.9877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88424313
Old  loss*** tensor(989.7825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(875.2084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8096192
Old  loss*** tensor(3882.9434, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3143.7056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86559093
Old  loss*** tensor(986.8959, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.2482, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861749
Old  loss*** tensor(1612.5304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1428.9840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86983335
Old  loss*** tensor(1365.3008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1187.5841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857978
Old  loss*** tensor(1222.9634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.2756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89488107
Old  loss*** tensor(449.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.5720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732319
Old  loss*** tensor(1326.3428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1158.2048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572037
Old  loss*** tensor(1233.4633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.3293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86800027
Old  loss*** tensor(1856.2700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1611.2429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89723676
Old  loss*** tensor(888.8908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.5455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8837743
Old  loss*** tensor(1514.5745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1338.5420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031567
Old  loss*** tensor(2666.9441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.9739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85084474
Old  loss*** tensor(2423.5840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2062.0938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9025644
Old  loss*** tensor(945.3784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(853.2648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89619386
Old  loss*** tensor(628.1008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(562.9000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85378826
Old  loss*** tensor(473.2743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.0760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82112503
Old  loss*** tensor(3448.7063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2831.8191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84328425
Old  loss*** tensor(2102.9612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1773.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459312
Old  loss*** tensor(2094.7998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1772.0564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729942
Old  loss*** tensor(622.4441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(543.3901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83660585
Old  loss*** tensor(1933.7996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1617.8280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85756314
Old  loss*** tensor(1414.8289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.3051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78763807
Old  loss*** tensor(2656.3652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2092.2544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89302266
Old  loss*** tensor(260.0095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(232.1944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84208715
Old  loss*** tensor(1648.9077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1388.5240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88599443
Old  loss*** tensor(855.2604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(757.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8375995
Old  loss*** tensor(2571.1355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2153.5818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90687835
Old  loss*** tensor(608.9970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(552.2862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519666
Old  loss*** tensor(1677.6602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.3104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86202586
Old  loss*** tensor(1237.2665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1066.5557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88069266
Old  loss*** tensor(289.2183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(254.7124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85738385
Old  loss*** tensor(1385.0531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1187.5222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.876117
Old  loss*** tensor(1643.1484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1439.5902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934077
Old  loss*** tensor(724.7825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.5262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8226573
Old  loss*** tensor(3610.6382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2970.3179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72767675
Old  loss*** tensor(4765.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3468.0515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858758
Old  loss*** tensor(2225.5452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1911.2047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86465466
Old  loss*** tensor(2009.3650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1737.4069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861743
Old  loss*** tensor(726.7303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.0097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80184793
Old  loss*** tensor(4011.7219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3216.7910, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87320614
Old  loss*** tensor(1308.8365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.8842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88767385
Old  loss*** tensor(1069.8977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(949.7202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855922
Old  loss*** tensor(1631.8740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1396.7568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85569453
Old  loss*** tensor(2135.5432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1827.3727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654062
Old  loss*** tensor(1974.1498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1708.4415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620328
Old  loss*** tensor(2400.3074, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.1436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78827584
Old  loss*** tensor(3536.2852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2787.5681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86939824
Old  loss*** tensor(702.9510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(611.1443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80682594
Old  loss*** tensor(2715.3000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2190.7744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86371547
Old  loss*** tensor(1629.8403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1407.7183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7364669
Old  loss*** tensor(3557.0427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2619.6443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89373076
Old  loss*** tensor(1342.1412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.5129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8292612
Old  loss*** tensor(4221.8970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3501.0552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71793693
Old  loss*** tensor(3663.8921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2630.4434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82112265
Old  loss*** tensor(3243.6956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2663.4719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88283134
Old  loss*** tensor(1903.8989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.8217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81169534
Old  loss*** tensor(2634.9927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.8113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81934345
Old  loss*** tensor(3331.9595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2730.0190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80867636
Old  loss*** tensor(1867.6884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1510.3555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83147633
Old  loss*** tensor(2796.2444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2325.0110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88312757
Old  loss*** tensor(98.1795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(86.7051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7731383
Old  loss*** tensor(3591.4478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2776.6858, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398107
Old  loss*** tensor(549.4644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.4461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463458
Old  loss*** tensor(2404.2449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.8225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8282695
Old  loss*** tensor(2012.9022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1667.2255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8755225
Old  loss*** tensor(4212.3540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3688.0107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8515109
Old  loss*** tensor(1954.8503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1664.5763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80953753
Old  loss*** tensor(3163.2349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2560.7573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81317925
Old  loss*** tensor(3203.4736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2604.9983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79173076
Old  loss*** tensor(4577.7031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3624.3083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8688709
Old  loss*** tensor(4024.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3497.0359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86076844
Old  loss*** tensor(1573.6161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1354.5190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8367299
Old  loss*** tensor(3002.6951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2512.4446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7730702
Old  loss*** tensor(4036.3413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3120.3752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839633
Old  loss*** tensor(803.2624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.4456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87073433
Old  loss*** tensor(2072.8220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1804.8773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680829
Old  loss*** tensor(1077.8336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(935.6489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452643
Old  loss*** tensor(2688.8967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2272.8284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677435
Old  loss*** tensor(3385.7551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2937.9670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8491201
Old  loss*** tensor(3101.9329, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.9136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050173
Old  loss*** tensor(3046.0952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2452.1594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84342146
Old  loss*** tensor(3404.3569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2871.3076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8693005
Old  loss*** tensor(1480.0566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1286.6140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89860547
Old  loss*** tensor(496.5655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(446.2165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86961293
Old  loss*** tensor(1083.3075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.0582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81319153
Old  loss*** tensor(2580.6084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2098.5288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86989295
Old  loss*** tensor(1883.3208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1638.2875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8837663
Old  loss*** tensor(1415.9016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1251.3262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88599753
Old  loss*** tensor(1225.0249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.3690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8902143
Old  loss*** tensor(1033.7201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(920.2324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80019844
Old  loss*** tensor(3429.1890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2744.0317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8909894
Old  loss*** tensor(1002.7405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(893.4312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689035
Old  loss*** tensor(1152.3665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.2953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81527805
Old  loss*** tensor(1679.7833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1369.4905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86778533
Old  loss*** tensor(918.1014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(796.7150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84533054
Old  loss*** tensor(2731.7351, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2309.2190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78235304
Old  loss*** tensor(4603.1924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3601.3215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592715
Old  loss*** tensor(1378.4989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1184.5049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647205
Old  loss*** tensor(1710.8579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1479.4139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85068893
Old  loss*** tensor(3743.3721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3184.4453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85287523
Old  loss*** tensor(1788.3661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1525.2532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87820065
Old  loss*** tensor(1293.7012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1136.1292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8380954
Old  loss*** tensor(2072.6172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1737.0510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8886634
Old  loss*** tensor(806.0626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(716.3183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669697
Old  loss*** tensor(1705.7362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1478.8217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7886903
Old  loss*** tensor(2280.4307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1798.5536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88438743
Old  loss*** tensor(203.6246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(180.0830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84538627
Old  loss*** tensor(1278.5641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.8805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84352744
Old  loss*** tensor(3041.0037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2565.1699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8355121
Old  loss*** tensor(2399.8501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2005.1038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80919075
Old  loss*** tensor(2545.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2060.0872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531034
Old  loss*** tensor(2057.7151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1755.4437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8180395
Old  loss*** tensor(2829.9502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2315.0110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9123335
Old  loss*** tensor(462.6944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(422.1316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.891173
Old  loss*** tensor(623.5138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.6587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8099538
Old  loss*** tensor(3836.6443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3107.5046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8596283
Old  loss*** tensor(1266.9089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1089.0708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8128655
Old  loss*** tensor(2588.9224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2104.4456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82885015
Old  loss*** tensor(2275.1018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.7185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84254456
Old  loss*** tensor(1498.6746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1262.7001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8194334
Old  loss*** tensor(1481.8635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.2885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87760115
Old  loss*** tensor(1054.6473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.5597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89065367
Old  loss*** tensor(810.2456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(721.6482, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8788911
Old  loss*** tensor(1670.3416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1468.0483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9123779
Old  loss*** tensor(664.1856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(605.9883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934774
Old  loss*** tensor(1368.5079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1222.7308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699974
Old  loss*** tensor(751.7200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(653.9944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716417
Old  loss*** tensor(1638.9833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1428.6062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8199349
Old  loss*** tensor(2033.2223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1667.1100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88064927
Old  loss*** tensor(3136.1733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2761.8687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86572325
Old  loss*** tensor(448.6321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(388.3913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931104
Old  loss*** tensor(252.4519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(225.4674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.868124
Old  loss*** tensor(1226.4185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752618
Old  loss*** tensor(1423.4132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1245.8591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8313198
Old  loss*** tensor(4001.4976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3326.5242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8352173
Old  loss*** tensor(4502.0742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3760.2102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88205147
Old  loss*** tensor(675.7440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(596.0410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9001215
Old  loss*** tensor(458.2727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.5011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84792584
Old  loss*** tensor(3889.3115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3297.8477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421461
Old  loss*** tensor(2546.2471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2144.3120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359713
Old  loss*** tensor(2513.2351, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2100.9924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9081168
Old  loss*** tensor(962.3145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(873.8940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8905935
Old  loss*** tensor(2231.5881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1987.4380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86628526
Old  loss*** tensor(1957.6882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.9165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7640847
Old  loss*** tensor(4181.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3195.1074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8985871
Old  loss*** tensor(718.5205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(645.6533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75919306
Old  loss*** tensor(4456.4941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3383.3394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8010066
Old  loss*** tensor(4537.6104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3634.6560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86922014
Old  loss*** tensor(1277.0472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1110.0352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84572345
Old  loss*** tensor(2551.5547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2157.9097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8214047
Old  loss*** tensor(2927.3506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.5396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89422894
Old  loss*** tensor(735.9739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.1292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8406898
Old  loss*** tensor(3901.2024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3279.7009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79351616
Old  loss*** tensor(4192.3677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3326.7114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87311345
Old  loss*** tensor(1131.1792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(987.6478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7687823
Old  loss*** tensor(3900.3445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2998.5159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8871615
Old  loss*** tensor(447.1891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(396.7289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8474028
Old  loss*** tensor(1720.8307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1458.2368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771533
Old  loss*** tensor(465.4373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.2598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84410906
Old  loss*** tensor(2412.5166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.4271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613728
Old  loss*** tensor(741.3540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(638.5822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81563866
Old  loss*** tensor(2915.7117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2378.1672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83143055
Old  loss*** tensor(1948.8754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1620.3545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81702685
Old  loss*** tensor(1894.6356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1547.9681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86536217
Old  loss*** tensor(3853.7104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3334.8552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.882154
Old  loss*** tensor(1315.3850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1160.3722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88403213
Old  loss*** tensor(879.4772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(777.4861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82368153
Old  loss*** tensor(4676.6509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3852.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418063
Old  loss*** tensor(3633.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3059.0168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84428495
Old  loss*** tensor(2267.8079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1914.6760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89321554
Old  loss*** tensor(251.8295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(224.9380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739051
Old  loss*** tensor(715.2086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.0244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7531417
Old  loss*** tensor(5178.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3900.4160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82772994
Old  loss*** tensor(3139.7874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2598.8960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.777926
Old  loss*** tensor(4328.8203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3367.5020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879768
Old  loss*** tensor(2903.6724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2554.5581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78389084
Old  loss*** tensor(3075.0234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2410.4827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7448954
Old  loss*** tensor(3317.2456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2471.0010, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575737
Old  loss*** tensor(3131.8948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2685.8306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85460657
Old  loss*** tensor(1922.2068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1642.7306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88203764
Old  loss*** tensor(1069.8479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(943.6461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100171
Old  loss*** tensor(2039.9373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.3840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8725175
Old  loss*** tensor(600.1559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(523.6465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88727814
Old  loss*** tensor(647.3938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(574.4183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85267437
Old  loss*** tensor(2481.9363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.2834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822722
Old  loss*** tensor(2333.8350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.0776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900583
Old  loss*** tensor(805.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(716.7484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863091
Old  loss*** tensor(1866.3473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.8275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87690485
Old  loss*** tensor(959.3254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(841.2371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8093034
Old  loss*** tensor(4395.9326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3557.6433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77585
Old  loss*** tensor(3224.7537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2501.9250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82826024
Old  loss*** tensor(1970.7542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1632.2974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8858279
Old  loss*** tensor(451.5994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(400.0394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585514
Old  loss*** tensor(2172.8813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1865.5303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884692
Old  loss*** tensor(1560.8259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.7458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85056496
Old  loss*** tensor(1605.0067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1365.1625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776414
Old  loss*** tensor(1522.3252, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.0555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83200616
Old  loss*** tensor(4021.4299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3345.8545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86028457
Old  loss*** tensor(1944.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1673.2094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76536244
Old  loss*** tensor(3860.2065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2954.4570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.69275784
Old  loss*** tensor(5060.4331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3505.6548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84901845
Old  loss*** tensor(4542.7065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3856.8418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88637424
Old  loss*** tensor(753.5566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(667.9332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.751101
Old  loss*** tensor(2834.9099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2129.3037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8977074
Old  loss*** tensor(1869.9858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1678.7001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85405624
Old  loss*** tensor(1572.1814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1342.7313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81561375
Old  loss*** tensor(4394.9907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3584.6147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8751804
Old  loss*** tensor(321.8438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(281.6714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590567
Old  loss*** tensor(1431.3319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.5953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8424674
Old  loss*** tensor(2151.3735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1812.4622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81585
Old  loss*** tensor(3107.0669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2534.9006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8962598
Old  loss*** tensor(760.4728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(681.5812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7700511
Old  loss*** tensor(4771.1836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3674.0552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88882625
Old  loss*** tensor(1456.7054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.7581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8582615
Old  loss*** tensor(1321.8363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1134.4812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86137944
Old  loss*** tensor(1911.0385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1646.1293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88029724
Old  loss*** tensor(1372.2646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.0007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8906651
Old  loss*** tensor(1320.4696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1176.0962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80658317
Old  loss*** tensor(3612.9746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2914.1646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892489
Old  loss*** tensor(154.3388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(137.7457, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545081
Old  loss*** tensor(1407.8397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1203.0105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8303814
Old  loss*** tensor(1424.7968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.1248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8184902
Old  loss*** tensor(4470.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3658.6541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.772331
Old  loss*** tensor(3179.1309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2455.3413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9010083
Old  loss*** tensor(482.9460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(435.1384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86080587
Old  loss*** tensor(926.5956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.6189, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80736804
Old  loss*** tensor(2708.5530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2186.7991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7987397
Old  loss*** tensor(3844.1045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3070.4387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87924725
Old  loss*** tensor(736.9784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.9862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79205364
Old  loss*** tensor(3413.0872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2703.3481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.782783
Old  loss*** tensor(4956.1592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3879.5969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75398695
Old  loss*** tensor(4037.4590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3044.1914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80459213
Old  loss*** tensor(3313.4504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2665.9761, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795278
Old  loss*** tensor(162.3916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(142.8279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8164588
Old  loss*** tensor(4064.6292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3318.6023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85014385
Old  loss*** tensor(1142.9572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(971.6780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8430965
Old  loss*** tensor(2796.3770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2357.6157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86373854
Old  loss*** tensor(1249.8295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.5259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8002483
Old  loss*** tensor(3963.7729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3172.0027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78538835
Old  loss*** tensor(2954.6489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2320.5469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79247224
Old  loss*** tensor(2936.6641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2327.2249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769368
Old  loss*** tensor(1101.7061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(966.1266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8044066
Old  loss*** tensor(1479.3660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.0117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8833854
Old  loss*** tensor(2090.0269, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1846.2992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89727443
Old  loss*** tensor(1020.0839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(915.2952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545443
Old  loss*** tensor(2608.3801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2228.9763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903369
Old  loss*** tensor(544.6868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(484.9548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82314426
Old  loss*** tensor(2640.4165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2173.4436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89393795
Old  loss*** tensor(580.1758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.6412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8508115
Old  loss*** tensor(1527.7654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.8403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85578746
Old  loss*** tensor(597.0933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.9850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860582
Old  loss*** tensor(2196.7224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1890.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8091772
Old  loss*** tensor(4361.1733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3528.9622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847537
Old  loss*** tensor(858.2935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.3784, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.846864
Old  loss*** tensor(2203.1086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1865.7334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7801195
Old  loss*** tensor(3570.9270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2785.7498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749072
Old  loss*** tensor(1115.6410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(976.0823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8457891
Old  loss*** tensor(2767.6030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2340.8083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861294
Old  loss*** tensor(730.4721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.2928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86374974
Old  loss*** tensor(1742.9950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.5115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90258694
Old  loss*** tensor(4137.5200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3734.4714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80470407
Old  loss*** tensor(2449.0081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1970.7268, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631604
Old  loss*** tensor(1680.0420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.1456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85559964
Old  loss*** tensor(1779.8876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.8712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8423091
Old  loss*** tensor(2656.6216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2237.6965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426591
Old  loss*** tensor(3779.8955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3185.1633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8886672
Old  loss*** tensor(439.6302, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.6850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850472
Old  loss*** tensor(1071.4397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(948.2747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81378907
Old  loss*** tensor(2775.6335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2258.7803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9115744
Old  loss*** tensor(530.3043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.4119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806143
Old  loss*** tensor(1035.0883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.5135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81939304
Old  loss*** tensor(2547.4451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2087.3586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900809
Old  loss*** tensor(824.7190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(734.0667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819516
Old  loss*** tensor(384.7327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(339.3156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8600838
Old  loss*** tensor(2522.2197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2169.3203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84885347
Old  loss*** tensor(2169.0122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1841.1736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711278
Old  loss*** tensor(1126.9280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.6983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8402767
Old  loss*** tensor(3461.6042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2908.7056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87330294
Old  loss*** tensor(1714.3313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1497.1306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87423384
Old  loss*** tensor(1080.7568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.8342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7577152
Old  loss*** tensor(4384.8267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3322.4500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8932704
Old  loss*** tensor(693.9124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(619.8514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87589574
Old  loss*** tensor(2018.7534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1768.2175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85505885
Old  loss*** tensor(1637.6223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1400.2634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79787755
Old  loss*** tensor(5114.1055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4080.4299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7810394
Old  loss*** tensor(4680.1328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3655.3682, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.757547
Old  loss*** tensor(3615.6577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.0308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8307065
Old  loss*** tensor(3321.4580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2759.1567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7853751
Old  loss*** tensor(3020.4727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2372.2041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81901026
Old  loss*** tensor(3101.6987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2540.3230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7941129
Old  loss*** tensor(3808.9290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3024.7197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7576529
Old  loss*** tensor(1938.0181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1468.3450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81588066
Old  loss*** tensor(2999.2073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2446.9951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84965026
Old  loss*** tensor(1382.3933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1174.5508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594177
Old  loss*** tensor(1396.3459, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.0444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8782233
Old  loss*** tensor(557.6754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.7635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85753644
Old  loss*** tensor(2289.5264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1963.3523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653911
Old  loss*** tensor(861.2412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.3105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8449694
Old  loss*** tensor(1727.5079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1459.6913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79255915
Old  loss*** tensor(3503.7512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2776.9302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796448
Old  loss*** tensor(485.9762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(427.4865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8223151
Old  loss*** tensor(2740.0312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2253.1689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82339764
Old  loss*** tensor(2268.1438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1867.5842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7824466
Old  loss*** tensor(2337.2764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1828.7939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76138103
Old  loss*** tensor(3990.9648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3038.6450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86336684
Old  loss*** tensor(943.6621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(814.7266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8065533
Old  loss*** tensor(4651.6060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3751.7681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7738868
Old  loss*** tensor(3861.2344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2988.1582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519251
Old  loss*** tensor(1731.0183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.6979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85085136
Old  loss*** tensor(1466.0900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.4247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86044073
Old  loss*** tensor(1166.2385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.4791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8137065
Old  loss*** tensor(1858.7594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.4846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83750117
Old  loss*** tensor(3559.0039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2980.6699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8383296
Old  loss*** tensor(2086.5496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1749.2163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84867513
Old  loss*** tensor(1169.0691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(992.1599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86699903
Old  loss*** tensor(1375.3951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1192.4663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88413584
Old  loss*** tensor(465.6674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(411.7133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758903
Old  loss*** tensor(2590.2842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2268.8049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297908
Old  loss*** tensor(2998.2712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2487.9377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736243
Old  loss*** tensor(860.3635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(751.6345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556013
Old  loss*** tensor(1652.6085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1413.9740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9094252
Old  loss*** tensor(3701.3672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3366.1167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85297865
Old  loss*** tensor(1239.6605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.4039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873876
Old  loss*** tensor(919.1075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.1860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255837
Old  loss*** tensor(2452.7258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2024.9304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939103
Old  loss*** tensor(1064.4514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(951.5240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90967315
Old  loss*** tensor(476.5773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(433.5296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8838142
Old  loss*** tensor(170.9503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(151.0883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81329256
Old  loss*** tensor(3656.1138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2973.4902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865411
Old  loss*** tensor(380.7722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(337.5702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778354
Old  loss*** tensor(1383.7266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.6842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8599247
Old  loss*** tensor(964.3380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(829.2581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85299104
Old  loss*** tensor(2039.3672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1739.5619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82573473
Old  loss*** tensor(1571.9518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.0151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84847444
Old  loss*** tensor(1802.1661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.0919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81315136
Old  loss*** tensor(2133.7271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1735.0431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.896913
Old  loss*** tensor(105.5683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(94.6856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8938832
Old  loss*** tensor(685.7051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.9403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77271605
Old  loss*** tensor(4598.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3552.9617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8694831
Old  loss*** tensor(2138.2852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1859.2029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82757986
Old  loss*** tensor(3089.1042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2556.4805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878379
Old  loss*** tensor(791.2998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(695.0611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8611884
Old  loss*** tensor(1153.5876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(993.4563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90285766
Old  loss*** tensor(967.5145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(873.5279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592171
Old  loss*** tensor(1619.3889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1391.4066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8440904
Old  loss*** tensor(3325.7581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2807.2405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81893253
Old  loss*** tensor(3240.4297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2653.6934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8164406
Old  loss*** tensor(3909.9114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3192.2102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931958
Old  loss*** tensor(638.4037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(570.2195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89398515
Old  loss*** tensor(275.4118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(246.2141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83289933
Old  loss*** tensor(2648.8911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2206.2595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832117
Old  loss*** tensor(744.8871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.8929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74789286
Old  loss*** tensor(5042.2363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3771.0525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8407011
Old  loss*** tensor(2726.0186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.7668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8666182
Old  loss*** tensor(1322.9253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.4712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85767025
Old  loss*** tensor(1819.1006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1560.1885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87121576
Old  loss*** tensor(1364.7382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1188.9814, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82277715
Old  loss*** tensor(2387.5625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1964.4319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83186626
Old  loss*** tensor(2328.4131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1936.9283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80029655
Old  loss*** tensor(4406.9058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3526.8315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84805095
Old  loss*** tensor(2521.6438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.4824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88349146
Old  loss*** tensor(676.1278, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(597.3531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79974353
Old  loss*** tensor(2763.0049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2209.6953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.738688
Old  loss*** tensor(4513.1748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3333.8281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298278
Old  loss*** tensor(3009.4712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2497.3428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885423
Old  loss*** tensor(1043.9052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(924.2976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88203704
Old  loss*** tensor(758.7789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(669.2711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528042
Old  loss*** tensor(3109.6787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2651.9470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8944988
Old  loss*** tensor(1179.1342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1054.7341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629298
Old  loss*** tensor(2044.8835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1764.5909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90398014
Old  loss*** tensor(862.1669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(779.3817, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446333
Old  loss*** tensor(1668.4132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1409.1973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8761802
Old  loss*** tensor(1400.6967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.2627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8261343
Old  loss*** tensor(2148.7041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1775.1182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8441298
Old  loss*** tensor(1658.3506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.8632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8464845
Old  loss*** tensor(4066.2439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3442.0125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85030127
Old  loss*** tensor(2474.7798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2104.3083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736756
Old  loss*** tensor(1664.8428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1454.5325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85860574
Old  loss*** tensor(1332.3352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.9507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621097
Old  loss*** tensor(1140.5112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(983.2458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690325
Old  loss*** tensor(3834.7000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3332.4790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91181886
Old  loss*** tensor(441.9153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.9467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87776744
Old  loss*** tensor(1779.6127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.0861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87428516
Old  loss*** tensor(1408.7411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.6415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8419636
Old  loss*** tensor(2033.3574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1712.0129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78220195
Old  loss*** tensor(4267.9326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3338.3853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85889304
Old  loss*** tensor(2974.5737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2554.8406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8740424
Old  loss*** tensor(1360.0537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1188.7446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7747915
Old  loss*** tensor(4933.1895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3822.1931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9082819
Old  loss*** tensor(810.6320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(736.2824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81800675
Old  loss*** tensor(3288.6272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2690.1191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8116646
Old  loss*** tensor(4143.3081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.9763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839637
Old  loss*** tensor(461.1776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(407.6643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84834766
Old  loss*** tensor(1956.8162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1660.0604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7443118
Old  loss*** tensor(4346.4609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3235.1223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7670696
Old  loss*** tensor(4706.0576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3609.8735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87718296
Old  loss*** tensor(649.7808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(569.9767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87187433
Old  loss*** tensor(1552.0114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1353.1588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85683143
Old  loss*** tensor(1439.3751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.3019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8423794
Old  loss*** tensor(1149.5764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(968.3795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670112
Old  loss*** tensor(2459.1951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.1497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255364
Old  loss*** tensor(1929.2205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1592.6416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85712874
Old  loss*** tensor(1634.8611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.2864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75889325
Old  loss*** tensor(3904.5645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2963.1477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79526484
Old  loss*** tensor(3891.7131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3094.9426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87772036
Old  loss*** tensor(1112.2397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(976.2355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.793996
Old  loss*** tensor(1767.4390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1403.3395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85562134
Old  loss*** tensor(1584.8947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1356.0697, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90360177
Old  loss*** tensor(1337.4183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.4935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8309405
Old  loss*** tensor(2537.4558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2108.4749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8936422
Old  loss*** tensor(1269.0227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1134.0522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82005537
Old  loss*** tensor(2772.4954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2273.5996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81989527
Old  loss*** tensor(1934.0757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.7395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90679234
Old  loss*** tensor(1097.2600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(994.9870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87821805
Old  loss*** tensor(2302.9780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2022.5168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883775
Old  loss*** tensor(1383.6342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8605056
Old  loss*** tensor(1525.6218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1312.8062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78596556
Old  loss*** tensor(4500.2949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3537.0769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87035197
Old  loss*** tensor(2239.8823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1949.4860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556111
Old  loss*** tensor(1309.5576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1120.4720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81345004
Old  loss*** tensor(3322.3296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2702.5491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8243703
Old  loss*** tensor(2064.0237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1701.5199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87349474
Old  loss*** tensor(895.1103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.8741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85814106
Old  loss*** tensor(775.1690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.2043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8041991
Old  loss*** tensor(3031.1780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2437.6707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7794025
Old  loss*** tensor(3347.6509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2609.1675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75657165
Old  loss*** tensor(5230.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3957.2776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8718987
Old  loss*** tensor(1069.6205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(932.6007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9205644
Old  loss*** tensor(853.3618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(785.5745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80336064
Old  loss*** tensor(3413.5203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2742.2878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83160776
Old  loss*** tensor(3072.1770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2554.8462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703834
Old  loss*** tensor(1394.7050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.9280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622527
Old  loss*** tensor(1005.3859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(866.8967, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8489203
Old  loss*** tensor(2470.5896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2097.3337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86828023
Old  loss*** tensor(3112.4553, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2702.4834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84072375
Old  loss*** tensor(2154.7007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1811.5081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.894261
Old  loss*** tensor(617.4714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(552.1805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78007597
Old  loss*** tensor(3307.4429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2580.0566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562391
Old  loss*** tensor(1883.4897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1612.7175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87596786
Old  loss*** tensor(125.7405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(110.1446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7746223
Old  loss*** tensor(3538.0562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2740.6572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8927213
Old  loss*** tensor(552.7451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(493.4473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8279196
Old  loss*** tensor(3780.9253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3130.3022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88615566
Old  loss*** tensor(907.0498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.7873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74557436
Old  loss*** tensor(4393.2261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3275.4768, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624308
Old  loss*** tensor(268.8589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(231.8722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83534217
Old  loss*** tensor(2275.8523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1901.1154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631368
Old  loss*** tensor(1456.8767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1257.4839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664288
Old  loss*** tensor(790.5550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(684.9596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639787
Old  loss*** tensor(769.8755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.1561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81404865
Old  loss*** tensor(2446.7212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1991.7501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711194
Old  loss*** tensor(745.5150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.4325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667314
Old  loss*** tensor(267.6221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(231.9565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78394544
Old  loss*** tensor(4411.2905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3458.2112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83843327
Old  loss*** tensor(2664.4702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2233.9805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699514
Old  loss*** tensor(4433.5229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3413.5972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76014555
Old  loss*** tensor(4206.7476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3197.7405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601388
Old  loss*** tensor(2192.1453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.5492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528304
Old  loss*** tensor(1214.1630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.4751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9061325
Old  loss*** tensor(541.8654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(491.0019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8114121
Old  loss*** tensor(2214.3799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1796.7747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690013
Old  loss*** tensor(1184.8147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1029.6056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.822724
Old  loss*** tensor(2799.1531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2302.9304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.810207
Old  loss*** tensor(3241.1301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2625.9863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86803335
Old  loss*** tensor(952.4254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.7370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89027905
Old  loss*** tensor(4194.7773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3734.5225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570336
Old  loss*** tensor(2082.6333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1784.8867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88643765
Old  loss*** tensor(933.0941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(827.1298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88334215
Old  loss*** tensor(589.0905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.3684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9070812
Old  loss*** tensor(427.3495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(387.6407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9089545
Old  loss*** tensor(1468.9375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.1974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83917105
Old  loss*** tensor(2468.2236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2071.2617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731172
Old  loss*** tensor(991.1486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(865.3889, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8958711
Old  loss*** tensor(3838.8979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3439.1577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84887564
Old  loss*** tensor(1463.5116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.3394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819804
Old  loss*** tensor(1571.0922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.6725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87483084
Old  loss*** tensor(1337.2638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1169.8796, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609521
Old  loss*** tensor(1652.6779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1422.8765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337693
Old  loss*** tensor(3188.4778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2658.4551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.69232595
Old  loss*** tensor(5066.5317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3507.6914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86497176
Old  loss*** tensor(1083.0643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(936.8201, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83991706
Old  loss*** tensor(3895.2939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3271.7239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87629133
Old  loss*** tensor(846.0843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(741.4163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89102757
Old  loss*** tensor(924.5020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(823.7568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8356585
Old  loss*** tensor(2394.0371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2000.5974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.849181
Old  loss*** tensor(3621.7891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3075.5544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83459526
Old  loss*** tensor(2113.5752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1763.9799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658484
Old  loss*** tensor(1908.2642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.2675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9020904
Old  loss*** tensor(306.0809, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(276.1127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934761
Old  loss*** tensor(533.3849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(476.5667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84640944
Old  loss*** tensor(1884.1835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1594.7906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523476
Old  loss*** tensor(3125.2708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2663.8171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77867347
Old  loss*** tensor(2520.7371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1962.8311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877256
Old  loss*** tensor(820.6534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(728.5151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86526155
Old  loss*** tensor(1866.1869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.7397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87856925
Old  loss*** tensor(1408.0131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1237.0370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8899479
Old  loss*** tensor(1399.6023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1245.5731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728964
Old  loss*** tensor(1364.2506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.8494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8846259
Old  loss*** tensor(638.0626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(564.4467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79559666
Old  loss*** tensor(4278.7061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3404.1243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7997751
Old  loss*** tensor(5103.2026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4081.4146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7461958
Old  loss*** tensor(3481.2468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2597.6917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8974728
Old  loss*** tensor(930.2393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.8644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8228841
Old  loss*** tensor(723.5393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.3890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8567139
Old  loss*** tensor(1796.9614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1539.4818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83496064
Old  loss*** tensor(2516.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2100.9221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7775949
Old  loss*** tensor(3894.9053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3028.6587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8789288
Old  loss*** tensor(991.3436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(871.3204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8679192
Old  loss*** tensor(1262.3340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1095.6039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.899518
Old  loss*** tensor(390.4091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(351.1800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592007
Old  loss*** tensor(1477.3567, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1269.3459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8382168
Old  loss*** tensor(2491.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2088.7896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84457934
Old  loss*** tensor(3915.2783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3306.7632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624682
Old  loss*** tensor(1984.8844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.8997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89601743
Old  loss*** tensor(709.5083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.7318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89001036
Old  loss*** tensor(601.1481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(535.0280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314314
Old  loss*** tensor(4138.6553, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3441.0078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86780775
Old  loss*** tensor(1762.5229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.5311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.882532
Old  loss*** tensor(1284.3041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1133.4395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85715145
Old  loss*** tensor(2418.9426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2073.4001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061827
Old  loss*** tensor(3375.5635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2721.3208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7731143
Old  loss*** tensor(3440.2407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2659.6995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86717
Old  loss*** tensor(1539.0447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.6133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314527
Old  loss*** tensor(1966.2726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1634.8627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463768
Old  loss*** tensor(1273.8512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1078.1581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8014245
Old  loss*** tensor(4171.0967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3342.8191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89253455
Old  loss*** tensor(277.0035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(247.2352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89467585
Old  loss*** tensor(672.3756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(601.5582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7911869
Old  loss*** tensor(3609.3079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2855.6372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8341567
Old  loss*** tensor(3299.9915, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2752.7100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7615483
Old  loss*** tensor(3892.7783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2964.5386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8456652
Old  loss*** tensor(1464.6770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.6263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80549943
Old  loss*** tensor(4524.2739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3644.3000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8478533
Old  loss*** tensor(1887.5735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1600.3854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87840873
Old  loss*** tensor(1280.6794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1124.9600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398155
Old  loss*** tensor(3951.8604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3318.8335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452538
Old  loss*** tensor(1409.9717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1191.7839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86740094
Old  loss*** tensor(589.0665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.9568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.838251
Old  loss*** tensor(2038.1177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1708.4542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895459
Old  loss*** tensor(943.0488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.4615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86366165
Old  loss*** tensor(2187.1514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1888.9587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8720479
Old  loss*** tensor(896.1708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.5038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165834
Old  loss*** tensor(3148.4663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2570.9854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592206
Old  loss*** tensor(2417.0227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2076.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77901304
Old  loss*** tensor(3536.5916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2755.0510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7381323
Old  loss*** tensor(4779.1562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3527.6497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8998552
Old  loss*** tensor(1093.9597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(984.4053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779863
Old  loss*** tensor(598.2593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(525.2634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82459795
Old  loss*** tensor(2816.4448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2322.4346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88659096
Old  loss*** tensor(1025.9236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(909.5746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89494026
Old  loss*** tensor(986.2938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(882.6741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89030826
Old  loss*** tensor(1188.0988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.7742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887825
Old  loss*** tensor(1747.9645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1551.8866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8565664
Old  loss*** tensor(2122.5825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1818.1329, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87589705
Old  loss*** tensor(141.2118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(123.6870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547883
Old  loss*** tensor(1588.4366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.7771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8131694
Old  loss*** tensor(3972.2397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3230.1040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.801783
Old  loss*** tensor(2714.1418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2176.1528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91420084
Old  loss*** tensor(535.8945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.9152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776168
Old  loss*** tensor(972.2372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(853.2517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82007504
Old  loss*** tensor(3002.9666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2462.6580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85759497
Old  loss*** tensor(1775.6179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.7610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87448597
Old  loss*** tensor(2817.5825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2463.9363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7789149
Old  loss*** tensor(3899.8730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3037.6694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81729007
Old  loss*** tensor(3987.3645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3258.8335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8229308
Old  loss*** tensor(2273.7224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1871.1162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619964
Old  loss*** tensor(2259.6907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1947.8452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86945593
Old  loss*** tensor(1549.7703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1347.4569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8517462
Old  loss*** tensor(3954.8628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3368.5393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244726
Old  loss*** tensor(1864.1969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.9792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85180295
Old  loss*** tensor(1527.3306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1300.9846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.828311
Old  loss*** tensor(1769.3599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.5803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861079
Old  loss*** tensor(1026.6093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(909.6866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281474
Old  loss*** tensor(3171.5256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2626.4907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786786
Old  loss*** tensor(863.4581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(758.7022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775997
Old  loss*** tensor(471.4614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(413.7544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82297546
Old  loss*** tensor(2596.9128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2137.1956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81883323
Old  loss*** tensor(2670.4373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2186.6428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7411895
Old  loss*** tensor(4628.4985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3430.5945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81571555
Old  loss*** tensor(2668.0535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2176.3728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86117035
Old  loss*** tensor(1031.9572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.6909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88451844
Old  loss*** tensor(784.0776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(693.5311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89134693
Old  loss*** tensor(422.3748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(376.4825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87310266
Old  loss*** tensor(570.2820, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(497.9148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908076
Old  loss*** tensor(1191.7638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.6323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85652137
Old  loss*** tensor(3846.5193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3294.6260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8285366
Old  loss*** tensor(2768.2097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2293.5632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795268
Old  loss*** tensor(612.5873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(538.7870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815375
Old  loss*** tensor(2173.4941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1772.2128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81919444
Old  loss*** tensor(2339.8364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1916.7810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7692448
Old  loss*** tensor(2706.4368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2081.9124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8391088
Old  loss*** tensor(1122.6078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(941.9901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88061285
Old  loss*** tensor(1218.3999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1072.9386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86998844
Old  loss*** tensor(2179.9888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1896.5651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73544043
Old  loss*** tensor(4603.2085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3385.3857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.92032313
Old  loss*** tensor(726.8313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.9197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87980473
Old  loss*** tensor(1250.0021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1099.7577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101655
Old  loss*** tensor(3199.2839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2591.9495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8945153
Old  loss*** tensor(741.2897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(663.0949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8048916
Old  loss*** tensor(4491.7617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3615.3811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399221
Old  loss*** tensor(2784.0183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2338.3584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87141275
Old  loss*** tensor(1822.5432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.1874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852895
Old  loss*** tensor(2234.6626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1905.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85027975
Old  loss*** tensor(1656.6826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1408.6437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547722
Old  loss*** tensor(2677.1821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2288.3809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8235727
Old  loss*** tensor(4272.9854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.1140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8753763
Old  loss*** tensor(1161.8871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.0884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8510604
Old  loss*** tensor(2173.0212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1849.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588401
Old  loss*** tensor(1802.9312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.4296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74530727
Old  loss*** tensor(5063.6733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3773.9924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8164864
Old  loss*** tensor(1619.3477, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1322.1754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597576
Old  loss*** tensor(2143.5093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1842.8984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74669933
Old  loss*** tensor(3986.7720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2976.9199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7748611
Old  loss*** tensor(3300.7861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2557.6509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534509
Old  loss*** tensor(3431.4619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2928.5842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.824963
Old  loss*** tensor(2113.7859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1743.7950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76794875
Old  loss*** tensor(4659.4238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3578.1987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82443607
Old  loss*** tensor(3730.0586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3075.1948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8546236
Old  loss*** tensor(1595.8901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1363.8854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79876214
Old  loss*** tensor(3807.2610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3041.0959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8403516
Old  loss*** tensor(1477.8536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1241.9166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.884053
Old  loss*** tensor(780.4529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.9617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749403
Old  loss*** tensor(1657.1627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.9185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87321174
Old  loss*** tensor(593.8738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.5776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631123
Old  loss*** tensor(1194.4438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1030.9391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000201
Old  loss*** tensor(1094.9325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.4613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492581
Old  loss*** tensor(1974.3649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1676.7454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785378
Old  loss*** tensor(214.4736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(188.4232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88121414
Old  loss*** tensor(824.8027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(726.8278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924245
Old  loss*** tensor(376.2458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(335.7710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88443255
Old  loss*** tensor(843.3044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.8459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86514544
Old  loss*** tensor(1538.9543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1331.4193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8657305
Old  loss*** tensor(4361.0068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3775.4568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772824
Old  loss*** tensor(1565.7699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.6223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88474196
Old  loss*** tensor(918.3775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.5271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83365095
Old  loss*** tensor(3620.9797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3018.6333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83671737
Old  loss*** tensor(1896.5398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1586.8678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654307
Old  loss*** tensor(2192.3633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.3385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76088583
Old  loss*** tensor(4314.5771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3282.9006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847474
Old  loss*** tensor(1024.8099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(906.6979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7297288
Old  loss*** tensor(3361.9131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2453.2849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89044744
Old  loss*** tensor(782.4776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(696.7552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684344
Old  loss*** tensor(1552.8839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1348.5779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800009
Old  loss*** tensor(1682.7793, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1480.8473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8239049
Old  loss*** tensor(2528.4417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.1953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115878
Old  loss*** tensor(3632.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2948.4241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8581231
Old  loss*** tensor(3141.9851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2696.2100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84374094
Old  loss*** tensor(1445.2285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.3984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8186978
Old  loss*** tensor(4155.1753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3401.8330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855843
Old  loss*** tensor(1034.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(885.4674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901608
Old  loss*** tensor(891.2297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(793.3377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7838687
Old  loss*** tensor(3757.0315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2945.0193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493409
Old  loss*** tensor(2486.3096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2111.7244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86111045
Old  loss*** tensor(1246.9949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1073.8003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87472284
Old  loss*** tensor(1032.6481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(903.2808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87863064
Old  loss*** tensor(989.3176, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.2448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775332
Old  loss*** tensor(1481.1252, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.7366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88338363
Old  loss*** tensor(1734.4797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1532.2111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862499
Old  loss*** tensor(432.2899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(383.1169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.826357
Old  loss*** tensor(3134.8840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2590.5334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.783159
Old  loss*** tensor(4485.2285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3512.6472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80065393
Old  loss*** tensor(3808.8789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3049.5940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79784536
Old  loss*** tensor(3297.6423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2631.0085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90246326
Old  loss*** tensor(507.4229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(457.9305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.875489
Old  loss*** tensor(460.0564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.7744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8444395
Old  loss*** tensor(1939.4780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1637.7719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863261
Old  loss*** tensor(2372.3640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2047.9692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88065964
Old  loss*** tensor(121.8475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(107.3062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79560214
Old  loss*** tensor(2649.7454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2108.1431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89114267
Old  loss*** tensor(254.4594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(226.7596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590597
Old  loss*** tensor(3128.0991, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2687.2239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83629537
Old  loss*** tensor(3799.4971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3177.5017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8457962
Old  loss*** tensor(2882.6580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2438.1411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8020983
Old  loss*** tensor(2597.6150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.5425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696915
Old  loss*** tensor(1406.4216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1223.1530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77960134
Old  loss*** tensor(2727.7036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2126.5215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793505
Old  loss*** tensor(1367.4589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1202.4756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519936
Old  loss*** tensor(1714.9559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1461.1315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84438014
Old  loss*** tensor(1873.3823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.8468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87648785
Old  loss*** tensor(1124.2808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.4185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78389513
Old  loss*** tensor(3490.2292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2735.9736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81695247
Old  loss*** tensor(3530.8093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2884.5034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877797
Old  loss*** tensor(1010.2757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.8170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781853
Old  loss*** tensor(826.3219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(725.6637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586023
Old  loss*** tensor(1510.2350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1296.6912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.774321
Old  loss*** tensor(4373.0337, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3386.1318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85857
Old  loss*** tensor(2455.0139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2107.8013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84252095
Old  loss*** tensor(2780.9788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2343.0330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648406
Old  loss*** tensor(1453.2415, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1256.8223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7541521
Old  loss*** tensor(3417.8281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2577.5623, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79868233
Old  loss*** tensor(2588.4392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2067.3406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90922654
Old  loss*** tensor(619.3201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(563.1023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85570073
Old  loss*** tensor(1508.5179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1290.8400, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83050567
Old  loss*** tensor(3378.0818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2805.5161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80671084
Old  loss*** tensor(2744.5247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2214.0378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8904712
Old  loss*** tensor(1643.6973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1463.6652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506966
Old  loss*** tensor(2805.0354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2386.2341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82126147
Old  loss*** tensor(2796.9294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2297.0103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85981655
Old  loss*** tensor(732.3348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.6736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88595945
Old  loss*** tensor(615.7375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(545.5185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88690895
Old  loss*** tensor(436.6324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(387.2532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8765738
Old  loss*** tensor(1177.2396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1031.9374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86379397
Old  loss*** tensor(1341.8818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1159.1095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8232147
Old  loss*** tensor(2143.1902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1764.3057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87292105
Old  loss*** tensor(3786.9407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3305.7002, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87297297
Old  loss*** tensor(633.4235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(552.9616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8240136
Old  loss*** tensor(3845.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3168.8098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9049623
Old  loss*** tensor(882.2607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(798.4127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87237155
Old  loss*** tensor(1419.7811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.5767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82757175
Old  loss*** tensor(4168.5107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3449.7417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78329784
Old  loss*** tensor(3859.0005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3022.7468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87602717
Old  loss*** tensor(433.4138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.6823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87256134
Old  loss*** tensor(1293.9512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1129.0518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7641537
Old  loss*** tensor(2769.6221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.4170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806076
Old  loss*** tensor(1814.6045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1597.9545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86744475
Old  loss*** tensor(2456.2214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2130.6365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87758636
Old  loss*** tensor(1381.4303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1212.3243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8266984
Old  loss*** tensor(4940.0156, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4083.9031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7774105
Old  loss*** tensor(4564.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3548.7385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.871537
Old  loss*** tensor(1414.5646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1232.8455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81696576
Old  loss*** tensor(4263.6113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3483.2244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77362317
Old  loss*** tensor(3337.6440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2582.0789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77714914
Old  loss*** tensor(4463.3516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3468.6899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8377073
Old  loss*** tensor(2037.1630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1706.5463, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8375499
Old  loss*** tensor(1014.6960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.8585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8846953
Old  loss*** tensor(362.6997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(320.8787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82528305
Old  loss*** tensor(2210.0808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1823.9423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674338
Old  loss*** tensor(1214.2778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.3057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.867158
Old  loss*** tensor(1809.8875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1569.4584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7854383
Old  loss*** tensor(3405.3975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2674.7295, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82447284
Old  loss*** tensor(4045.5500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3335.4460, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787938
Old  loss*** tensor(106.2817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(93.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9112048
Old  loss*** tensor(658.6649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(600.1786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800036
Old  loss*** tensor(588.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(517.5551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892668
Old  loss*** tensor(332.4644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(296.7804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7625085
Old  loss*** tensor(4204.2046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3205.7417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926045
Old  loss*** tensor(903.3602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(806.3433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9016626
Old  loss*** tensor(447.3466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(403.3557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86857516
Old  loss*** tensor(558.2158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(484.8524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798624
Old  loss*** tensor(1180.1003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1038.3259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87904125
Old  loss*** tensor(1776.5035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1561.6199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8383311
Old  loss*** tensor(1707.0874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.1045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87820435
Old  loss*** tensor(1730.4664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1519.7031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81967473
Old  loss*** tensor(2991.1194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2451.7449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86072433
Old  loss*** tensor(1599.4968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1376.7258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8246254
Old  loss*** tensor(2353.9629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1941.1376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8136834
Old  loss*** tensor(2357.9463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1918.6217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050597
Old  loss*** tensor(1907.5664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1535.7048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660816
Old  loss*** tensor(905.5071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(784.2430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520316
Old  loss*** tensor(3556.4019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3030.1667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86609745
Old  loss*** tensor(733.3608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.1619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8679011
Old  loss*** tensor(1624.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.2778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785907
Old  loss*** tensor(1449.3605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1273.3947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708871
Old  loss*** tensor(1176.2562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1024.3864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388399
Old  loss*** tensor(4180.4160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3506.6997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79015625
Old  loss*** tensor(2482.6011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1961.6427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8994052
Old  loss*** tensor(1365.1591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.8312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588706
Old  loss*** tensor(898.8474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(771.9936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81471336
Old  loss*** tensor(2019.3387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1645.1823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7440399
Old  loss*** tensor(4061.2551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3021.7358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80798626
Old  loss*** tensor(4745.4517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3834.2598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88935494
Old  loss*** tensor(128.1077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(113.9332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7568747
Old  loss*** tensor(4235.7319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3205.9182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85980946
Old  loss*** tensor(4192.4067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3604.6709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87009525
Old  loss*** tensor(1042.0431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(906.6768, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7945217
Old  loss*** tensor(3045.5684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2419.7700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857779
Old  loss*** tensor(1575.8514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.8544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8286489
Old  loss*** tensor(2470.9353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2047.5378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8242703
Old  loss*** tensor(2097.5435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1728.9427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85652214
Old  loss*** tensor(1273.9185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.1394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81820387
Old  loss*** tensor(1839.0797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1504.7422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915379
Old  loss*** tensor(1040.5593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(927.6981, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8984375
Old  loss*** tensor(746.7954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(670.9490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87935185
Old  loss*** tensor(989.2360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.8865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842854
Old  loss*** tensor(2245.5891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1892.7039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75229585
Old  loss*** tensor(3345.6960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2516.9534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8264993
Old  loss*** tensor(2496.2021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2063.1094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8583303
Old  loss*** tensor(2351.4856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2018.3513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9009918
Old  loss*** tensor(516.4722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(465.3372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8433205
Old  loss*** tensor(1719.1481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.7928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8154535
Old  loss*** tensor(2664.9834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2173.1702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88695335
Old  loss*** tensor(2235.9656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1983.1971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8263536
Old  loss*** tensor(3116.1350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2575.0293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76884544
Old  loss*** tensor(3760.5559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2891.2864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77713615
Old  loss*** tensor(3958.5330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3076.3191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8187028
Old  loss*** tensor(4077.1760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3337.9956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84006554
Old  loss*** tensor(2422.4214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.9927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661468
Old  loss*** tensor(1256.3688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1088.1998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8350415
Old  loss*** tensor(3015.6008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2518.1519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8063445
Old  loss*** tensor(4050.5776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3266.1611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739451
Old  loss*** tensor(2485.9041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2172.5437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85320127
Old  loss*** tensor(3102.8970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2647.3958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80823755
Old  loss*** tensor(4719.1782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3814.2170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337753
Old  loss*** tensor(2243.5786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1870.6404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8291725
Old  loss*** tensor(3212.4009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2663.6345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8730157
Old  loss*** tensor(1483.3141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.9565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934423
Old  loss*** tensor(534.0011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(477.0992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.810074
Old  loss*** tensor(4724.8892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3827.5098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86965555
Old  loss*** tensor(1832.5833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1593.7162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685124
Old  loss*** tensor(2528.1406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2195.7214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864932
Old  loss*** tensor(955.0878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.0860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9027699
Old  loss*** tensor(1637.1652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.9835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88342404
Old  loss*** tensor(1287.0348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1136.9974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88104135
Old  loss*** tensor(1462.6769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1288.6788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659566
Old  loss*** tensor(1435.6105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.1764, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779701
Old  loss*** tensor(581.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.5208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87932944
Old  loss*** tensor(1190.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1047.1332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8668351
Old  loss*** tensor(559.3097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(484.8293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509243
Old  loss*** tensor(2065.7583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1757.8040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634025
Old  loss*** tensor(1656.2104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.9762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82419693
Old  loss*** tensor(2127.4446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.4333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736651
Old  loss*** tensor(1976.1235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1726.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862585
Old  loss*** tensor(1829.2870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1621.2211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9035189
Old  loss*** tensor(404.3071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(365.2991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8810096
Old  loss*** tensor(882.3827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(777.3876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88278294
Old  loss*** tensor(124.8059, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(110.1766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87702584
Old  loss*** tensor(1342.2588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1177.1957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874486
Old  loss*** tensor(578.2667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(505.6861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88389933
Old  loss*** tensor(410.4015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(362.7536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83312756
Old  loss*** tensor(1654.1448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1378.1136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86268675
Old  loss*** tensor(3189.0791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2751.1763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8918993
Old  loss*** tensor(731.9561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.8311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84389997
Old  loss*** tensor(2009.9855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1696.2267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8283637
Old  loss*** tensor(2148.9976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1780.1516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.735531
Old  loss*** tensor(4798.7866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3529.6562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8293257
Old  loss*** tensor(2865.0186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2376.0334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8332498
Old  loss*** tensor(3928.5276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3273.4448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88400686
Old  loss*** tensor(1181.0654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.0699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90003085
Old  loss*** tensor(235.5078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(211.9643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8381027
Old  loss*** tensor(3313.6658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2777.1921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8091843
Old  loss*** tensor(3539.4460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2864.0642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83795166
Old  loss*** tensor(2305.5667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1931.9534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78568846
Old  loss*** tensor(2559.4409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2010.9232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656864
Old  loss*** tensor(1162.8940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.7016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8192712
Old  loss*** tensor(3366.9495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2758.4448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801656
Old  loss*** tensor(781.6870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(688.0140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85096234
Old  loss*** tensor(2155.4893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1834.2402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89380765
Old  loss*** tensor(505.3147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.6541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8933381
Old  loss*** tensor(421.9425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(376.9373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767807
Old  loss*** tensor(994.7754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.1998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88449264
Old  loss*** tensor(1086.2516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(960.7816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78586304
Old  loss*** tensor(3940.2158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3096.4700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8593611
Old  loss*** tensor(3086.0005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2651.9888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82941115
Old  loss*** tensor(3034.6418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2516.9658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72948873
Old  loss*** tensor(4176.2554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3046.5312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81729186
Old  loss*** tensor(2762.6040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2257.8538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73402625
Old  loss*** tensor(4642.3052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3407.5740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8364584
Old  loss*** tensor(1432.5947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1198.3059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852412
Old  loss*** tensor(1269.5908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1082.2145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78068984
Old  loss*** tensor(4570.5771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3568.2031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926711
Old  loss*** tensor(728.8635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.6354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88512284
Old  loss*** tensor(428.5536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.3226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8214466
Old  loss*** tensor(3526.0933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2896.4973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.896343
Old  loss*** tensor(1507.7268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1351.4403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9139178
Old  loss*** tensor(797.2191, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(728.5927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8103239
Old  loss*** tensor(3891.5928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.4507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90802217
Old  loss*** tensor(1092.3459, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(991.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8467826
Old  loss*** tensor(2349.0039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1989.0957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8564912
Old  loss*** tensor(1045.1666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.1760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88054085
Old  loss*** tensor(1072.3910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.2841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8290239
Old  loss*** tensor(445.2873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(369.1538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87484014
Old  loss*** tensor(776.6698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(679.4619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80966437
Old  loss*** tensor(3096.8127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2507.3789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7841211
Old  loss*** tensor(2559.1621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.6930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84543276
Old  loss*** tensor(2327.2231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1967.5107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91442716
Old  loss*** tensor(800.2139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(731.7373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588865
Old  loss*** tensor(1718.9697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1476.3999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7642391
Old  loss*** tensor(4615.0586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3527.0081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509377
Old  loss*** tensor(1564.7416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1331.4977, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85335773
Old  loss*** tensor(1234.0831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.1144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674425
Old  loss*** tensor(800.4916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(694.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8179641
Old  loss*** tensor(2724.3193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2228.3953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83765936
Old  loss*** tensor(3714.4814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3111.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8688377
Old  loss*** tensor(1317.2288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1144.4580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880681
Old  loss*** tensor(953.7328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(846.9797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495179
Old  loss*** tensor(1780.5029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.5691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84027576
Old  loss*** tensor(2848.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2393.7219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84176385
Old  loss*** tensor(1613.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.7661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85244393
Old  loss*** tensor(5103.5610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4350.4995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84798265
Old  loss*** tensor(2324.8108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1971.3992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8633789
Old  loss*** tensor(1648.5658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1423.3369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000095
Old  loss*** tensor(456.5720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(410.9192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79947865
Old  loss*** tensor(2754.7749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2202.3838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851006
Old  loss*** tensor(1076.5439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(952.8497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83405256
Old  loss*** tensor(2179.5845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1817.8881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87622416
Old  loss*** tensor(1400.0424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.7510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802131
Old  loss*** tensor(2439.1484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2146.9705, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900095
Old  loss*** tensor(141.2548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(125.7181, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8925477
Old  loss*** tensor(1028.7402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(918.1998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8199875
Old  loss*** tensor(4210.7710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3452.7795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81846654
Old  loss*** tensor(3128.5769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2560.6355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7778777
Old  loss*** tensor(2691.1924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2093.4185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86896855
Old  loss*** tensor(551.1119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.8989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87712777
Old  loss*** tensor(1807.4701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.3822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86117303
Old  loss*** tensor(1842.6462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1586.8373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8702975
Old  loss*** tensor(1014.7313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.1180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85496575
Old  loss*** tensor(1936.5968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.7239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000584
Old  loss*** tensor(791.7892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.6566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439955
Old  loss*** tensor(1857.1125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1567.3947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89435786
Old  loss*** tensor(449.6077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.1101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562101
Old  loss*** tensor(2387.7585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2044.4230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.849606
Old  loss*** tensor(1642.4769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.4583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88097924
Old  loss*** tensor(3727.2190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3283.6025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86716914
Old  loss*** tensor(825.1356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(715.5322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7757244
Old  loss*** tensor(3206.2197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2487.1428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824487
Old  loss*** tensor(1034.1254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(912.5626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575599
Old  loss*** tensor(1453.3201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1246.3091, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531629
Old  loss*** tensor(1627.8625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1388.8319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87343496
Old  loss*** tensor(1882.6084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1644.3359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8106414
Old  loss*** tensor(4216.3369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3417.9373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83673143
Old  loss*** tensor(1986.2650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1661.9703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539556
Old  loss*** tensor(2080.9707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1777.0566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758925
Old  loss*** tensor(113.7971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(99.6740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87970304
Old  loss*** tensor(1739.5298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1530.2697, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84801716
Old  loss*** tensor(1467.6057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1244.5548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8299738
Old  loss*** tensor(3617.2283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3002.2048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8450955
Old  loss*** tensor(4067.7612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.6467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621836
Old  loss*** tensor(1408.2365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.1583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88964516
Old  loss*** tensor(518.0100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(460.8451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747506
Old  loss*** tensor(1016.7954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(889.4424, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8893657
Old  loss*** tensor(1623.3972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.7937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7640662
Old  loss*** tensor(3982.8872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3043.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746667
Old  loss*** tensor(1305.0516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1141.4852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86154747
Old  loss*** tensor(2223.6863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1915.8113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298665
Old  loss*** tensor(2849.3154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2364.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8854227
Old  loss*** tensor(1419.9033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1257.2146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82470596
Old  loss*** tensor(3045.5015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2511.6433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84838665
Old  loss*** tensor(3950.6821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3351.7061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79774594
Old  loss*** tensor(3094.2625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2468.4353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7773013
Old  loss*** tensor(4297.3682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3340.3499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8119339
Old  loss*** tensor(1088.0801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.4491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7168192
Old  loss*** tensor(5201.5435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3728.5664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8348751
Old  loss*** tensor(2791.1768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2330.2839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79336846
Old  loss*** tensor(3166.2612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2512.0117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7829985
Old  loss*** tensor(4129.5215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3233.4092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729384
Old  loss*** tensor(1509.9700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1318.1107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75237453
Old  loss*** tensor(4051.7961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3048.4683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82950294
Old  loss*** tensor(2736.8618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2270.2349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81830597
Old  loss*** tensor(2336.6885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1912.1261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874058
Old  loss*** tensor(593.4849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(526.6620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89803576
Old  loss*** tensor(652.5679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.0294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8306767
Old  loss*** tensor(2032.0322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1687.9618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7576622
Old  loss*** tensor(4281.5454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3243.9651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79378986
Old  loss*** tensor(2682.6687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2129.4753, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8967114
Old  loss*** tensor(755.8563, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.7849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9169692
Old  loss*** tensor(575.5327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(527.7458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869763
Old  loss*** tensor(1662.2920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1445.8000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7868799
Old  loss*** tensor(2696.9214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2122.1533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85239804
Old  loss*** tensor(1393.0953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1187.4717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787923
Old  loss*** tensor(550.6639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.9192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795066
Old  loss*** tensor(774.2559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.9631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540559
Old  loss*** tensor(2919.7729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2493.6492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674704
Old  loss*** tensor(1861.7697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1615.0300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847455
Old  loss*** tensor(713.2090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(631.0085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876095
Old  loss*** tensor(253.8938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(225.3586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563788
Old  loss*** tensor(4547.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3894.7668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8304654
Old  loss*** tensor(3606.8916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2995.3987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762258
Old  loss*** tensor(458.7438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.9632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685949
Old  loss*** tensor(2094.2981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1819.0966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255305
Old  loss*** tensor(4149.1582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3425.2568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711445
Old  loss*** tensor(933.1801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.9346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811501
Old  loss*** tensor(1012.3403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(892.0237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8766133
Old  loss*** tensor(744.0388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.2343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7655186
Old  loss*** tensor(3547.6179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2715.7676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438411
Old  loss*** tensor(3503.1121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2956.0698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88957256
Old  loss*** tensor(1153.0944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.7611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8202647
Old  loss*** tensor(3925.9404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3220.3103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8322102
Old  loss*** tensor(3317.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2760.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756885
Old  loss*** tensor(1198.2842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.3236, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80762136
Old  loss*** tensor(4580.6836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3699.4580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336191
Old  loss*** tensor(2483.7644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2070.5134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162327
Old  loss*** tensor(3658.8301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2986.4568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9102999
Old  loss*** tensor(965.8002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.1678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778671
Old  loss*** tensor(1075.6903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.3131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8644333
Old  loss*** tensor(1216.1355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1051.2681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7873769
Old  loss*** tensor(4271.9043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3363.5986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631205
Old  loss*** tensor(1138.4071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(982.5825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545522
Old  loss*** tensor(1194.3022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.5936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89118516
Old  loss*** tensor(703.9876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(627.3833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88260996
Old  loss*** tensor(1368.5411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.8881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84213907
Old  loss*** tensor(1991.7537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.3336, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.753752
Old  loss*** tensor(5058.6348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3812.9561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82461905
Old  loss*** tensor(2915.4124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.1045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85774094
Old  loss*** tensor(3500.3328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3002.3787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89320874
Old  loss*** tensor(1156.9785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.4233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86439204
Old  loss*** tensor(2346.7285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2028.4934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8416686
Old  loss*** tensor(1553.6997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1307.7003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88008714
Old  loss*** tensor(608.3944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(535.4401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88143003
Old  loss*** tensor(1393.4985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1228.2715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86240935
Old  loss*** tensor(1850.9619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1596.2869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8525104
Old  loss*** tensor(2023.9871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1725.4700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7535169
Old  loss*** tensor(5181.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3904.5242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8676574
Old  loss*** tensor(1053.1744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.7946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8891362
Old  loss*** tensor(382.2260, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(339.8510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7629281
Old  loss*** tensor(3485.1494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2658.9185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83218217
Old  loss*** tensor(3034.9343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2525.6182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.821823
Old  loss*** tensor(4564.1343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3750.9106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781173
Old  loss*** tensor(1310.8671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1151.0951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89881015
Old  loss*** tensor(1006.5815, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.7256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81557435
Old  loss*** tensor(3370.2136, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2748.6597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872064
Old  loss*** tensor(1061.7770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.9375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.836511
Old  loss*** tensor(2169.2900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1814.6350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8246343
Old  loss*** tensor(2526.0054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.0308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310583
Old  loss*** tensor(2904.2119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2413.5696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8403355
Old  loss*** tensor(1754.0280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1473.9719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742347
Old  loss*** tensor(1240.7727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.7266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7705755
Old  loss*** tensor(4217.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3249.8857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86757505
Old  loss*** tensor(1512.8060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1312.4728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85831165
Old  loss*** tensor(1842.7927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.6904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.903844
Old  loss*** tensor(222.3713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.9890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83021295
Old  loss*** tensor(1151.0435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(955.6112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8014609
Old  loss*** tensor(4462.3291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3576.3823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83043045
Old  loss*** tensor(2962.2180, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.9160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563545
Old  loss*** tensor(1563.1843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1338.6399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808421
Old  loss*** tensor(1299.3612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1144.5320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8286904
Old  loss*** tensor(2062.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1708.9813, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8712946
Old  loss*** tensor(2078.2976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1810.8096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87208754
Old  loss*** tensor(937.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(817.6162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8207854
Old  loss*** tensor(2162.9814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1775.3436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9030561
Old  loss*** tensor(678.1095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.3709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85457313
Old  loss*** tensor(1281.2015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1094.8804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670405
Old  loss*** tensor(1704.5486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.9127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85364527
Old  loss*** tensor(3328.8325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2841.6421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86144316
Old  loss*** tensor(609.5068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(525.0554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.900404
Old  loss*** tensor(751.8530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(676.9714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87409246
Old  loss*** tensor(1526.7766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.5439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208
Old  loss*** tensor(2538.0422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.2251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.916072
Old  loss*** tensor(842.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(771.7410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81680566
Old  loss*** tensor(3500.1897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2858.9749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8625132
Old  loss*** tensor(1909.9734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1647.3772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759341
Old  loss*** tensor(722.1615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.5659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86525345
Old  loss*** tensor(959.4461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(830.1641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518787
Old  loss*** tensor(2634.9370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2244.6467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82484037
Old  loss*** tensor(2777.1880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.7368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75621575
Old  loss*** tensor(4436.5664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3355.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813975
Old  loss*** tensor(121.5583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(107.1412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86160755
Old  loss*** tensor(1614.1204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1390.7383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8905678
Old  loss*** tensor(319.7702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(284.7771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90714586
Old  loss*** tensor(712.5986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.4308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815981
Old  loss*** tensor(4252.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3470.0239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85200167
Old  loss*** tensor(2822.3501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.6470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76867414
Old  loss*** tensor(3917.0618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3010.9441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88304293
Old  loss*** tensor(1023.4036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(903.7094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529779
Old  loss*** tensor(1865.9044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1591.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86254764
Old  loss*** tensor(3175.6841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.1787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084958
Old  loss*** tensor(2095.1150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.8917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90894693
Old  loss*** tensor(520.7990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(473.3787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81632984
Old  loss*** tensor(351.3877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(286.8483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731376
Old  loss*** tensor(1546.1128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1349.9692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421593
Old  loss*** tensor(2327.6792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1960.2766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7841706
Old  loss*** tensor(3573.8350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2802.4963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77618617
Old  loss*** tensor(4904.6436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3806.9165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7930223
Old  loss*** tensor(2478.1826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1965.2540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82402515
Old  loss*** tensor(2434.3601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2005.9740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86736155
Old  loss*** tensor(736.2480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(638.5932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7550592
Old  loss*** tensor(3146.8997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2376.0955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86614424
Old  loss*** tensor(1097.4835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(950.5790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81756806
Old  loss*** tensor(2618.8604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.0967, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88487875
Old  loss*** tensor(1723.8407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1525.3900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347826
Old  loss*** tensor(3744.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3126.1392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886073
Old  loss*** tensor(460.8236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.3234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8623595
Old  loss*** tensor(3956.4180, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3411.8547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78780967
Old  loss*** tensor(5327.7573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4197.2588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841139
Old  loss*** tensor(1916.0507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.0071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8587043
Old  loss*** tensor(1015.7513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.2301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8941305
Old  loss*** tensor(1223.1624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.6667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388702
Old  loss*** tensor(1169.6967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.2237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86482894
Old  loss*** tensor(831.6866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.2667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7827317
Old  loss*** tensor(2868.7356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2245.4504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77821004
Old  loss*** tensor(3472.2983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2702.1775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87725276
Old  loss*** tensor(508.9020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(446.4357, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506267
Old  loss*** tensor(3968.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3375.3628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7882712
Old  loss*** tensor(4038.8411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3183.7021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78478974
Old  loss*** tensor(4064.2788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3189.6042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8679594
Old  loss*** tensor(962.1343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.0934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7290908
Old  loss*** tensor(3478.8481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2536.3962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7847132
Old  loss*** tensor(2558.3481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2007.5696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862624
Old  loss*** tensor(1616.8359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1394.7214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793858
Old  loss*** tensor(496.5219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(436.6343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8254924
Old  loss*** tensor(2387.5039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1970.8663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787639
Old  loss*** tensor(945.8889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(831.2130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83614737
Old  loss*** tensor(1710.2424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.0146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711639
Old  loss*** tensor(1485.3032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1293.9425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483081
Old  loss*** tensor(1007.9901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.0862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8958561
Old  loss*** tensor(1655.9796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1483.5194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88621336
Old  loss*** tensor(724.7446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.2784, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8740158
Old  loss*** tensor(682.2327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(596.2822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85523105
Old  loss*** tensor(1840.0009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1573.6259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.836974
Old  loss*** tensor(2074.9548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1736.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84644276
Old  loss*** tensor(1915.9540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1621.7454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874181
Old  loss*** tensor(943.8182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(825.0679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418325
Old  loss*** tensor(1673.2885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1408.6287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742194
Old  loss*** tensor(1112.3276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.4184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.68960047
Old  loss*** tensor(5168.6758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3564.3213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86387354
Old  loss*** tensor(4479.3452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3869.5879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.859262
Old  loss*** tensor(1024.4965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(880.3109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83266544
Old  loss*** tensor(1984.0468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.0471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80927277
Old  loss*** tensor(2440.6077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1975.1173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88892317
Old  loss*** tensor(647.9352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(575.9647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88240886
Old  loss*** tensor(1259.4240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.3269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690182
Old  loss*** tensor(1145.5933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(995.5414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89012516
Old  loss*** tensor(1268.3752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1129.0127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9027294
Old  loss*** tensor(617.2247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(557.1868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83420897
Old  loss*** tensor(2496.2288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2082.3765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8829814
Old  loss*** tensor(2306.8682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.9218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9218774
Old  loss*** tensor(682.8516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.5055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8431511
Old  loss*** tensor(4257.4565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3589.6792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89254916
Old  loss*** tensor(483.1713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(431.2541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87119305
Old  loss*** tensor(135.7801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(118.2906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802788
Old  loss*** tensor(1951.9343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1718.2465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756876
Old  loss*** tensor(620.3641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(543.2452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81829894
Old  loss*** tensor(3966.4690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3245.7573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80971575
Old  loss*** tensor(2828.4827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.2668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8323349
Old  loss*** tensor(2994.0330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2492.0381, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86770725
Old  loss*** tensor(1423.5510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1235.2256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88559103
Old  loss*** tensor(2594.8142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2297.9441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873757
Old  loss*** tensor(789.4209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(700.5129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85449404
Old  loss*** tensor(2955.5454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2525.4958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78495437
Old  loss*** tensor(4733.4565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3715.5474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7858783
Old  loss*** tensor(4083.0046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3208.7446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8419262
Old  loss*** tensor(2917.4993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2456.3191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831847
Old  loss*** tensor(1359.3137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.5250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503818
Old  loss*** tensor(1654.3969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1406.8690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821734
Old  loss*** tensor(951.7504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.6089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915894
Old  loss*** tensor(441.3668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(393.5179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83055115
Old  loss*** tensor(1196.0665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(993.3944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674488
Old  loss*** tensor(1429.5227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.0377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560213
Old  loss*** tensor(2715.1479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2324.2244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87144065
Old  loss*** tensor(1873.0375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1632.2410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89131474
Old  loss*** tensor(281.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(250.6030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89513814
Old  loss*** tensor(457.0800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(409.1497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87828124
Old  loss*** tensor(1187.3428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1042.8209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7678219
Old  loss*** tensor(4194.6880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3220.7734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8128836
Old  loss*** tensor(3140.0356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2552.4836, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7380595
Old  loss*** tensor(4179.9604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3085.0596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8490143
Old  loss*** tensor(2395.9995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.2378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88330734
Old  loss*** tensor(2107.0706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1861.1909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8060358
Old  loss*** tensor(3229.3196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2602.9473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9119556
Old  loss*** tensor(1174.7240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1071.2961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81535184
Old  loss*** tensor(3444.1528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2808.1963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9015175
Old  loss*** tensor(1588.1465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.7418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91387856
Old  loss*** tensor(1728.6895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1579.8123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84546137
Old  loss*** tensor(2383.4697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2015.1316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885044
Old  loss*** tensor(1328.7512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1180.6013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678955
Old  loss*** tensor(969.1583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(841.1281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.795324
Old  loss*** tensor(2925.7485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2326.9182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682662
Old  loss*** tensor(4206.0488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3651.9702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337351
Old  loss*** tensor(2885.9900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2406.1511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8630117
Old  loss*** tensor(1203.1469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1038.3298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8006171
Old  loss*** tensor(2844.6646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2277.4871, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82628846
Old  loss*** tensor(2441.5417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2017.4177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883823
Old  loss*** tensor(1305.8322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1160.0782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82451814
Old  loss*** tensor(2223.7324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1833.5077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685567
Old  loss*** tensor(1684.8468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1463.3849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8953079
Old  loss*** tensor(1034.7286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(926.4007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7486873
Old  loss*** tensor(4940.0532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3698.5552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.827578
Old  loss*** tensor(2087.4172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.5006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7707462
Old  loss*** tensor(3388.4045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2611.5999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.826404
Old  loss*** tensor(2906.8994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2402.2732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.898561
Old  loss*** tensor(1650.4619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1483.0406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86358804
Old  loss*** tensor(965.7531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.0128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88951707
Old  loss*** tensor(314.1521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(279.4437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82662296
Old  loss*** tensor(2481.9666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2051.6506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85501015
Old  loss*** tensor(1691.6062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.3405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81965005
Old  loss*** tensor(4037.5662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3309.3914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77990514
Old  loss*** tensor(4337.3545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3382.7251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7520648
Old  loss*** tensor(3652.3936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2746.8367, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865784
Old  loss*** tensor(1721.7683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.6794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88961947
Old  loss*** tensor(427.8875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(380.6571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88237715
Old  loss*** tensor(592.4524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(522.7665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85175
Old  loss*** tensor(3321.6768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2829.2383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79853356
Old  loss*** tensor(4040.7944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3226.7100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8425275
Old  loss*** tensor(3523.7673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2968.8708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7735997
Old  loss*** tensor(5038.3169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3897.6404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711935
Old  loss*** tensor(1510.0354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1315.5331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80526674
Old  loss*** tensor(4020.6938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3237.7310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771104
Old  loss*** tensor(701.0247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(614.8760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8976936
Old  loss*** tensor(909.7065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(816.6377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127285
Old  loss*** tensor(3193.8240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2595.7119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8600593
Old  loss*** tensor(1657.4895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.5393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86091375
Old  loss*** tensor(794.1744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(683.7156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8167212
Old  loss*** tensor(2711.7949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2214.7805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78561914
Old  loss*** tensor(4042.6025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3175.9460, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88763213
Old  loss*** tensor(852.8433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(757.0111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895736
Old  loss*** tensor(2618.1482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2329.0354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281393
Old  loss*** tensor(1696.1747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.6689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636575
Old  loss*** tensor(1132.2900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(977.9108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85130465
Old  loss*** tensor(489.4565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(416.6766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.829424
Old  loss*** tensor(4255.7017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3529.7812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7525501
Old  loss*** tensor(4754.6748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3578.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8477571
Old  loss*** tensor(2499.2871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2118.7883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8494449
Old  loss*** tensor(1660.9341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.8721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8437556
Old  loss*** tensor(2555.6199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2156.3186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88883936
Old  loss*** tensor(315.3540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(280.2991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82067883
Old  loss*** tensor(3653.0454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2997.9771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7895208
Old  loss*** tensor(2982.9878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2355.1309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90087724
Old  loss*** tensor(1139.0302, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.1263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830775
Old  loss*** tensor(1545.8730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1365.1257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8805027
Old  loss*** tensor(1071.3317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(943.3104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87512374
Old  loss*** tensor(1041.0566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.0534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83227575
Old  loss*** tensor(2762.5498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2299.2031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8555596
Old  loss*** tensor(1615.4075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1382.0774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84461045
Old  loss*** tensor(2276.2925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1922.5804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85940176
Old  loss*** tensor(2000.7010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1719.4060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.823187
Old  loss*** tensor(4070.6614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3350.9155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87853867
Old  loss*** tensor(429.6472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(377.4617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7976967
Old  loss*** tensor(3683.2766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2938.1377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852943
Old  loss*** tensor(2212.1609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.8472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76558304
Old  loss*** tensor(2839.2480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2173.6802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492592
Old  loss*** tensor(2196.2791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1865.2102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85168755
Old  loss*** tensor(1458.0348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1241.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8147128
Old  loss*** tensor(3579.8547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2916.5535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783774
Old  loss*** tensor(491.9081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(432.0810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783729
Old  loss*** tensor(1381.0878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.1101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080792
Old  loss*** tensor(3471.1069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2804.9292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8078353
Old  loss*** tensor(2497.7852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2017.7990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8623917
Old  loss*** tensor(2712.4954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2339.2334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88761485
Old  loss*** tensor(1254.4404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1113.4600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503487
Old  loss*** tensor(2403.6479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2043.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284328
Old  loss*** tensor(2993.9092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2480.2524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8905436
Old  loss*** tensor(775.2033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.3524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638672
Old  loss*** tensor(1546.7767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.2097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80922234
Old  loss*** tensor(2058.0908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1665.4531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88391536
Old  loss*** tensor(529.8026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(468.3006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818782
Old  loss*** tensor(958.8956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(845.6292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82654124
Old  loss*** tensor(3979.4910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3289.2134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8261587
Old  loss*** tensor(2848.0159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2352.9131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86461866
Old  loss*** tensor(1780.9575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1539.8491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8271503
Old  loss*** tensor(3034.1714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2509.7158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79044163
Old  loss*** tensor(4189.3608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3311.4453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8942204
Old  loss*** tensor(573.1800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(512.5493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.70575756
Old  loss*** tensor(5328.9390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3760.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8705119
Old  loss*** tensor(755.7592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.8973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84198964
Old  loss*** tensor(1695.7946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1427.8414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88050365
Old  loss*** tensor(950.8115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.1930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9291607
Old  loss*** tensor(925.2909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(859.7440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85222805
Old  loss*** tensor(1402.0588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.8739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795968
Old  loss*** tensor(1042.0271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(916.5637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769729
Old  loss*** tensor(553.7000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(485.5799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8217425
Old  loss*** tensor(2726.2803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2240.3003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8969814
Old  loss*** tensor(933.9178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.7069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85493624
Old  loss*** tensor(1161.8766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(993.3304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89826447
Old  loss*** tensor(1959.2118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.8904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9002481
Old  loss*** tensor(1259.4192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1133.7898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88879776
Old  loss*** tensor(956.4418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.0834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.785326
Old  loss*** tensor(4735.3892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3718.8242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438269
Old  loss*** tensor(1510.9166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1274.9520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867645
Old  loss*** tensor(607.2798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(538.5142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7775419
Old  loss*** tensor(5537.9756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4306.0078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85702044
Old  loss*** tensor(4192.2534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3592.8469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84399647
Old  loss*** tensor(3024.5378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2552.6992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85631925
Old  loss*** tensor(913.1212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.9233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82806605
Old  loss*** tensor(3239.8511, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2682.8108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91334534
Old  loss*** tensor(626.7725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(572.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8878035
Old  loss*** tensor(1165.7775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.9813, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84771776
Old  loss*** tensor(1899.2319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.0127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87846184
Old  loss*** tensor(386.7096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(339.7097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87511015
Old  loss*** tensor(1370.3480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.2054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82310665
Old  loss*** tensor(2212.6350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1821.2346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76007974
Old  loss*** tensor(4737.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3600.6436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799591
Old  loss*** tensor(2011.8000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1770.3018, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281704
Old  loss*** tensor(2953.7288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2446.1907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.778808
Old  loss*** tensor(3277.5935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2552.6160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8321398
Old  loss*** tensor(2524.1465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2100.4426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673769
Old  loss*** tensor(945.6693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(820.2517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742048
Old  loss*** tensor(1445.4651, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1263.6326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80612695
Old  loss*** tensor(963.3328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(776.5685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7564699
Old  loss*** tensor(3920.2947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2965.5850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84947294
Old  loss*** tensor(1698.7518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.0437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88133836
Old  loss*** tensor(233.0342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(205.3820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384087
Old  loss*** tensor(2084.6084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1747.7538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78923124
Old  loss*** tensor(4226.0898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3335.3621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90277445
Old  loss*** tensor(732.3188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.1188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75601125
Old  loss*** tensor(3510.8716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2654.2583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87868285
Old  loss*** tensor(73.6336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(64.7005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8644592
Old  loss*** tensor(1349.8928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.9272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77427125
Old  loss*** tensor(3960.2419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3066.3015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81825095
Old  loss*** tensor(1862.8691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1524.2944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732953
Old  loss*** tensor(1790.4584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.5989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545821
Old  loss*** tensor(1622.0403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.1665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90241444
Old  loss*** tensor(1732.5133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.4451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852309
Old  loss*** tensor(1159.7053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.6069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8628284
Old  loss*** tensor(1641.8849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1416.6649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780267
Old  loss*** tensor(229.6536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(201.6420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7865788
Old  loss*** tensor(4181.4487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3289.0388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401228
Old  loss*** tensor(3691.9358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3101.6794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717035
Old  loss*** tensor(2289.5210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1995.7834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8436919
Old  loss*** tensor(2191.1077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1848.6198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8070853
Old  loss*** tensor(1308.8711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.3706, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8238559
Old  loss*** tensor(1275.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1051.1979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8005198
Old  loss*** tensor(2243.9238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1796.3055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88518953
Old  loss*** tensor(1129.2302, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.5828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8715844
Old  loss*** tensor(780.7692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.5063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8487731
Old  loss*** tensor(1886.9529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1601.5948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8878042
Old  loss*** tensor(276.4436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(245.4278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89414567
Old  loss*** tensor(842.2965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(753.1358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647529
Old  loss*** tensor(676.9525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(585.3967, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883352
Old  loss*** tensor(1761.6549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1564.9401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875868
Old  loss*** tensor(495.9874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(440.2319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7773583
Old  loss*** tensor(2541.2454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1975.4581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750136
Old  loss*** tensor(1287.7913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1126.8348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71076846
Old  loss*** tensor(5471.1758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3888.7393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8316884
Old  loss*** tensor(2957.4504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.6772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88500786
Old  loss*** tensor(979.4464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(866.8177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78945184
Old  loss*** tensor(4250.7080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3355.7292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87773436
Old  loss*** tensor(1463.8402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1284.8629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76729316
Old  loss*** tensor(4115.5469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3157.8311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880679
Old  loss*** tensor(824.5458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(732.2527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8226902
Old  loss*** tensor(5001.7993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4114.9312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84149206
Old  loss*** tensor(3129.4746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91269493
Old  loss*** tensor(660.8964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(603.1968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78752387
Old  loss*** tensor(4188.2578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3298.3530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82105017
Old  loss*** tensor(2901.5127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2382.2876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769429
Old  loss*** tensor(979.0027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.5294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480748
Old  loss*** tensor(1375.9781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.9324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87804437
Old  loss*** tensor(1000.1329, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(878.1611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8034971
Old  loss*** tensor(3525.5979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2832.8076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8508642
Old  loss*** tensor(1994.2312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1696.8198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85956556
Old  loss*** tensor(971.6560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.2020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398143
Old  loss*** tensor(2285.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1919.3501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9108097
Old  loss*** tensor(716.5023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.5972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86416954
Old  loss*** tensor(1239.9603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1071.5359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77316386
Old  loss*** tensor(5061.5405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3913.4001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889792
Old  loss*** tensor(1520.0768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1351.3167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87796015
Old  loss*** tensor(1813.7477, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1592.3982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84067345
Old  loss*** tensor(2553.1323, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2146.3506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88802236
Old  loss*** tensor(1561.2635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.4369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80684936
Old  loss*** tensor(3502.6848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2826.1389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88126135
Old  loss*** tensor(1688.0089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1487.5770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8262853
Old  loss*** tensor(1893.1597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1564.2900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8163526
Old  loss*** tensor(2567.9346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2096.3401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746608
Old  loss*** tensor(1353.6577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.9913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8906333
Old  loss*** tensor(1129.5588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.0227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8395285
Old  loss*** tensor(2949.1006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2475.8540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8913238
Old  loss*** tensor(1251.8412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1115.7959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8106303
Old  loss*** tensor(3410.8181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2764.9126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855618
Old  loss*** tensor(2882.6145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2466.4167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86627007
Old  loss*** tensor(1318.6914, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.3429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8220327
Old  loss*** tensor(2684.0559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2206.3816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8312695
Old  loss*** tensor(709.2618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(589.5877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8522465
Old  loss*** tensor(1532.9094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.4167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653016
Old  loss*** tensor(2661.1101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2302.6628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85588884
Old  loss*** tensor(3903.3708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3340.8516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88428956
Old  loss*** tensor(521.5209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.1755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841565
Old  loss*** tensor(1106.3236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.1632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7785666
Old  loss*** tensor(4388.6670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3416.8696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934357
Old  loss*** tensor(559.8568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.1960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82036126
Old  loss*** tensor(3247.3538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2664.0032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74158823
Old  loss*** tensor(4136.0518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3067.2473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86352086
Old  loss*** tensor(1782.4640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1539.1948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88738596
Old  loss*** tensor(946.7999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(840.1769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84127676
Old  loss*** tensor(2039.6202, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1715.8851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89061344
Old  loss*** tensor(475.3539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(423.3566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8343159
Old  loss*** tensor(3433.9060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2864.9624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585528
Old  loss*** tensor(1931.9541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1658.6846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8201374
Old  loss*** tensor(4267.1680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.6641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890253
Old  loss*** tensor(1096.4755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.7944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87648463
Old  loss*** tensor(134.6785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(118.0437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781786
Old  loss*** tensor(983.3499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(863.5568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8567005
Old  loss*** tensor(3045.7676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2609.3105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85236543
Old  loss*** tensor(2323.4443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1980.4236, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8576013
Old  loss*** tensor(2462.0212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2111.4326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8168385
Old  loss*** tensor(4399.7388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3593.8760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87777036
Old  loss*** tensor(423.9554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(372.1355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658524
Old  loss*** tensor(2473.1855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.4136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881835
Old  loss*** tensor(1435.1333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1265.5508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84989727
Old  loss*** tensor(3303.5784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2807.7021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87280726
Old  loss*** tensor(897.8804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(783.6765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8988255
Old  loss*** tensor(1062.0331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(954.5825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7928584
Old  loss*** tensor(4454.9199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3532.1208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878968
Old  loss*** tensor(1346.4734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.5071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8630487
Old  loss*** tensor(1168.1428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1008.1641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7528608
Old  loss*** tensor(4714.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3548.9880, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88092995
Old  loss*** tensor(751.7922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(662.2762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853163
Old  loss*** tensor(1858.2778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.4139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8607603
Old  loss*** tensor(1760.5564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.4170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88334394
Old  loss*** tensor(628.2889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.9952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80870193
Old  loss*** tensor(2803.6936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2267.3525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7724333
Old  loss*** tensor(3115.7791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2406.7314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534004
Old  loss*** tensor(1506.1888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1285.3822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708618
Old  loss*** tensor(1013.7469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(882.8335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7939632
Old  loss*** tensor(3857.2578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3062.5208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87658656
Old  loss*** tensor(1899.3071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1664.9071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82715905
Old  loss*** tensor(3472.7539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2872.5198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8194056
Old  loss*** tensor(3113.9429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2551.5823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77293545
Old  loss*** tensor(5104.1899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3945.2092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83821523
Old  loss*** tensor(2279.0242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1910.3127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7372992
Old  loss*** tensor(4094.2649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3018.6982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8958841
Old  loss*** tensor(1288.3358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1154.1996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8220726
Old  loss*** tensor(2320.3923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1907.5310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076436
Old  loss*** tensor(2077.2397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.6693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8321465
Old  loss*** tensor(2834.4912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2358.7119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79130316
Old  loss*** tensor(3922.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3104.1489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.795221
Old  loss*** tensor(3480.7622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2767.9751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.897238
Old  loss*** tensor(1138.9218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.8839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8469816
Old  loss*** tensor(4069.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3446.5947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.844571
Old  loss*** tensor(1027.4854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(867.7843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85335445
Old  loss*** tensor(2784.6877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2376.3257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82841754
Old  loss*** tensor(2138.1453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1771.2771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804879
Old  loss*** tensor(518.6476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(456.6629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842297
Old  loss*** tensor(2119.0503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1784.8698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.745648
Old  loss*** tensor(5006.1880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3732.8542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8917633
Old  loss*** tensor(1206.6696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1076.0637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9039567
Old  loss*** tensor(413.2267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(373.5390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88597226
Old  loss*** tensor(1370.1285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.8959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654854
Old  loss*** tensor(2002.8541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1733.4410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88804346
Old  loss*** tensor(641.0241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(569.2573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7792188
Old  loss*** tensor(3946.6089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3075.2717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8584099
Old  loss*** tensor(2053.7344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1762.9459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75171024
Old  loss*** tensor(3735.5989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2808.0879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8687093
Old  loss*** tensor(966.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.8955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82783055
Old  loss*** tensor(2456.5103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2033.5742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88082814
Old  loss*** tensor(783.4469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.0821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9066459
Old  loss*** tensor(808.7274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(733.2294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704444
Old  loss*** tensor(1439.3462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1252.8708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165406
Old  loss*** tensor(2668.5740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2178.9990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677513
Old  loss*** tensor(1348.8789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1170.4915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865842
Old  loss*** tensor(1544.3507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1337.1637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86322963
Old  loss*** tensor(2847.1545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2457.7480, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88003194
Old  loss*** tensor(515.8641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(453.9769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8726529
Old  loss*** tensor(1911.6132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1668.1748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8649225
Old  loss*** tensor(2197.2344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1900.4375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81791896
Old  loss*** tensor(3198.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2615.7075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75328636
Old  loss*** tensor(4742.6392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3572.5654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664958
Old  loss*** tensor(1205.3961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.4707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8691726
Old  loss*** tensor(1704.0227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1481.0898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7959813
Old  loss*** tensor(3672.2703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2923.0583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87040913
Old  loss*** tensor(363.5936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(316.4752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8254392
Old  loss*** tensor(1768.4934, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1459.7838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8794986
Old  loss*** tensor(634.3776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(557.9342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588668
Old  loss*** tensor(1489.6040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1279.3715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85855424
Old  loss*** tensor(786.7853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(675.4979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.689424
Old  loss*** tensor(5150.4810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3550.8650, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519253
Old  loss*** tensor(1167.8462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(994.9177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78538346
Old  loss*** tensor(2884.1606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.1721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763821
Old  loss*** tensor(3916.2820, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3432.1594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832711
Old  loss*** tensor(768.1644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.4974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853371
Old  loss*** tensor(206.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(182.7309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8309951
Old  loss*** tensor(3711.5762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3084.3015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89463395
Old  loss*** tensor(851.8821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(762.1227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7995578
Old  loss*** tensor(2065.1824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1651.2327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889693
Old  loss*** tensor(401.6317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(357.0383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8285701
Old  loss*** tensor(2331.2505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1931.6045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8351243
Old  loss*** tensor(1598.5746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.0085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83923256
Old  loss*** tensor(2574.9119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2160.9500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8740616
Old  loss*** tensor(809.8257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(707.8376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85534227
Old  loss*** tensor(1633.3966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1397.1132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89939153
Old  loss*** tensor(1702.4801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1531.1962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77753943
Old  loss*** tensor(4349.1675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3381.6492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8368828
Old  loss*** tensor(1812.9275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1517.2079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8306285
Old  loss*** tensor(1970.0906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1636.4135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85891056
Old  loss*** tensor(2324.8013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1996.7964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669034
Old  loss*** tensor(1884.6465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1633.8065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101538
Old  loss*** tensor(4411.8882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3574.3079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87552685
Old  loss*** tensor(1074.7186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(940.9450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7834071
Old  loss*** tensor(4305.3550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3372.8457, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82178974
Old  loss*** tensor(2611.2729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2145.9172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588792
Old  loss*** tensor(2005.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1722.2177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779743
Old  loss*** tensor(444.7868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.5114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78032243
Old  loss*** tensor(3043.7783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.1284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579816
Old  loss*** tensor(1508.3708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.1544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8417591
Old  loss*** tensor(2396.1721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2016.9996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860571
Old  loss*** tensor(133.8286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(118.5798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87715495
Old  loss*** tensor(1031.0054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.3514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86265594
Old  loss*** tensor(327.0799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(282.1574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8605076
Old  loss*** tensor(2358.1396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2029.1971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7289678
Old  loss*** tensor(3892.7219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2837.6689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8221801
Old  loss*** tensor(2290.0100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1882.8007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586259
Old  loss*** tensor(1270.6715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.0315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872236
Old  loss*** tensor(738.6177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.2490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85348713
Old  loss*** tensor(4145.8296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3538.4121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801712
Old  loss*** tensor(1770.4418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1558.2919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82123905
Old  loss*** tensor(3221.4590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2645.5879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8829286
Old  loss*** tensor(931.5052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.4526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8514148
Old  loss*** tensor(3608.3628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3072.2134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8951762
Old  loss*** tensor(411.9711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(368.7867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86186624
Old  loss*** tensor(1274.2754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.2549, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873554
Old  loss*** tensor(1106.1160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(966.2520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731058
Old  loss*** tensor(664.3831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(580.0767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87168723
Old  loss*** tensor(896.9011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.8173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89344585
Old  loss*** tensor(1000.5880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(893.9712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855506
Old  loss*** tensor(1190.1312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.9214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8181081
Old  loss*** tensor(4329.3457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3541.8728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86313486
Old  loss*** tensor(1144.0310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(987.4531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80631155
Old  loss*** tensor(5098.2627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4110.7881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8754126
Old  loss*** tensor(462.6524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.0117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7827827
Old  loss*** tensor(4712.2124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3688.6382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8627569
Old  loss*** tensor(848.7166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(732.2361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84539104
Old  loss*** tensor(2145.9575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1814.1732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390703
Old  loss*** tensor(1704.3787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.0935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832301
Old  loss*** tensor(860.8450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(760.3242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634702
Old  loss*** tensor(2620.1560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2262.4265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81212556
Old  loss*** tensor(2475.4292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2010.3594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84843254
Old  loss*** tensor(695.2903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(589.9069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86457926
Old  loss*** tensor(1403.0077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.0114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867439
Old  loss*** tensor(1273.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1129.2025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545232
Old  loss*** tensor(3525.5247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3012.6426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8904135
Old  loss*** tensor(468.6308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(417.2752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803797
Old  loss*** tensor(851.5761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(749.7103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88494813
Old  loss*** tensor(2930.8015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2593.6074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90104645
Old  loss*** tensor(1190.8923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1073.0493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8175822
Old  loss*** tensor(2461.7917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2012.7170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347244
Old  loss*** tensor(3826.0317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3193.6821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8087846
Old  loss*** tensor(2845.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2301.6980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8424128
Old  loss*** tensor(1761.7371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1484.1099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8854221
Old  loss*** tensor(1201.1018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1063.4821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879732
Old  loss*** tensor(105.0199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(93.2549, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7365699
Old  loss*** tensor(5370.6240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3955.8398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86349845
Old  loss*** tensor(720.6323, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(622.2649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455777
Old  loss*** tensor(3442.3625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2910.7852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827671
Old  loss*** tensor(999.5928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(882.4076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79991275
Old  loss*** tensor(2672.8491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.0461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8602087
Old  loss*** tensor(1264.6488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1087.8619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88993484
Old  loss*** tensor(1350.1488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1201.5444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8515184
Old  loss*** tensor(1775.6937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.0359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7421862
Old  loss*** tensor(3485.7891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2587.1045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8630867
Old  loss*** tensor(1547.6805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.7825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8910018
Old  loss*** tensor(384.7079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(342.7754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82169056
Old  loss*** tensor(2083.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.9727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8737577
Old  loss*** tensor(1111.1135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(970.8440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646728
Old  loss*** tensor(1818.4644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1572.3766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8755795
Old  loss*** tensor(2428.5095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2126.3530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.884292
Old  loss*** tensor(960.2375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.1304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74246365
Old  loss*** tensor(4854.6704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3604.4163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716148
Old  loss*** tensor(954.8940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(832.2997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699795
Old  loss*** tensor(3477.3977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2677.5249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7908186
Old  loss*** tensor(2537.1226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.4037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719671
Old  loss*** tensor(2096.4358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1828.0229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88563967
Old  loss*** tensor(1506.8342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.5122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7749357
Old  loss*** tensor(4525.6890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3507.1182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88530654
Old  loss*** tensor(953.0007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(843.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81429064
Old  loss*** tensor(2329.7900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.1262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8553819
Old  loss*** tensor(2014.1404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1722.8593, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8953041
Old  loss*** tensor(476.1906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(426.3354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87236
Old  loss*** tensor(630.6967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(550.1946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8516072
Old  loss*** tensor(1451.7648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1236.3334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87142235
Old  loss*** tensor(1221.7273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.6405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87074393
Old  loss*** tensor(1394.5277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.2765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481939
Old  loss*** tensor(2001.0918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1697.3138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.899803
Old  loss*** tensor(487.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(438.6620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88674694
Old  loss*** tensor(678.2366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(601.4243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82850343
Old  loss*** tensor(4263.6372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3532.4380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7978077
Old  loss*** tensor(2568.8157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2049.4209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8238981
Old  loss*** tensor(3698.1460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3046.8953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.797522
Old  loss*** tensor(4256.3872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3394.5625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82857704
Old  loss*** tensor(4247.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.3196, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79258835
Old  loss*** tensor(3248.2566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2574.5303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.755231
Old  loss*** tensor(5194.5684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3923.0991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7991314
Old  loss*** tensor(3596.8882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2874.3862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826616
Old  loss*** tensor(1736.0194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1532.3176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87719285
Old  loss*** tensor(1516.8055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1330.5310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255292
Old  loss*** tensor(3022.4460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2495.1174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8930535
Old  loss*** tensor(1520.3523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8102822
Old  loss*** tensor(2475.9004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.1780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8964042
Old  loss*** tensor(742.2346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.3422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879856
Old  loss*** tensor(1060.5563, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(941.7587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8360696
Old  loss*** tensor(2359.8787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1973.0228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609375
Old  loss*** tensor(3643.0813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3136.4653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480544
Old  loss*** tensor(711.4940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(603.3856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683171
Old  loss*** tensor(1595.1345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.0826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7881172
Old  loss*** tensor(2537.7188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2000.0198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8269651
Old  loss*** tensor(2867.0386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2370.9409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86890644
Old  loss*** tensor(815.7067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.7728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88472724
Old  loss*** tensor(715.1834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.7422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84477043
Old  loss*** tensor(1999.9031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1689.4590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86106557
Old  loss*** tensor(1874.2380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1613.8418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890251
Old  loss*** tensor(166.8914, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(148.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8626318
Old  loss*** tensor(1712.6654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8462167
Old  loss*** tensor(1758.6802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1488.2245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648155
Old  loss*** tensor(1747.7261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1511.4606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024185
Old  loss*** tensor(3077.9587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2469.8110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86229193
Old  loss*** tensor(1173.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1012.1625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885153
Old  loss*** tensor(1080.7239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(960.2397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8282707
Old  loss*** tensor(3351.2046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2775.7046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7908123
Old  loss*** tensor(4167.2925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3295.5461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88926053
Old  loss*** tensor(280.2072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(249.1772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83862203
Old  loss*** tensor(4008.0962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3361.2778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8041094
Old  loss*** tensor(3840.1973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3087.9387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8476761
Old  loss*** tensor(1546.3711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1310.8218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85210097
Old  loss*** tensor(2089.2507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1780.2526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7954584
Old  loss*** tensor(2131.7524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.7203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529918
Old  loss*** tensor(1895.8798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1617.1699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82928085
Old  loss*** tensor(3356.3975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2783.3962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8458123
Old  loss*** tensor(2532.3574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.8992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656143
Old  loss*** tensor(1084.4919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(938.7517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79738396
Old  loss*** tensor(3395.7690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2707.7317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8993028
Old  loss*** tensor(972.1280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(874.2374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83002996
Old  loss*** tensor(2364.6033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1962.6915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88170785
Old  loss*** tensor(1407.0167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.5776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8498808
Old  loss*** tensor(1138.9757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(967.9936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76152086
Old  loss*** tensor(4082.0027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3108.5303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8788212
Old  loss*** tensor(1953.6537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1716.9122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8210006
Old  loss*** tensor(2308.9531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1895.6519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.830699
Old  loss*** tensor(1410.8009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1171.9509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455669
Old  loss*** tensor(4298.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3635.0273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786732
Old  loss*** tensor(589.7870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.2300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80874765
Old  loss*** tensor(3487.6582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2820.6353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8425339
Old  loss*** tensor(1635.1694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1377.6857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.821569
Old  loss*** tensor(1603.7432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877305
Old  loss*** tensor(1124.5657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(998.3112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87029475
Old  loss*** tensor(811.5255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.2664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85347575
Old  loss*** tensor(1406.2242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.1783, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85506713
Old  loss*** tensor(2256.8206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.7330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8187136
Old  loss*** tensor(1369.2964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1121.0615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442972
Old  loss*** tensor(2556.5740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2158.5081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767116
Old  loss*** tensor(517.4576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(453.6611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79169
Old  loss*** tensor(4045.9077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3203.1047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88650453
Old  loss*** tensor(324.7740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(287.9137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719909
Old  loss*** tensor(904.8839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(789.0505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8628861
Old  loss*** tensor(1951.4658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1683.8927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631698
Old  loss*** tensor(2383.6174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2057.4666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9077052
Old  loss*** tensor(800.5734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(726.6846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8797442
Old  loss*** tensor(1332.4606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1172.2244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90923166
Old  loss*** tensor(1333.4583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1212.4225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79121184
Old  loss*** tensor(4574.8145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3619.6475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8516891
Old  loss*** tensor(1310.3278, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1115.9918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8373245
Old  loss*** tensor(1927.7020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.1122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7815019
Old  loss*** tensor(2830.8003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2212.2759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864787
Old  loss*** tensor(4263.6577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3687.1558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8891387
Old  loss*** tensor(572.3850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(508.9297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914215
Old  loss*** tensor(1780.4064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.0925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8709268
Old  loss*** tensor(765.2985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.5190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8992612
Old  loss*** tensor(500.5630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(450.1369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81938905
Old  loss*** tensor(2492.3289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2042.1870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88241017
Old  loss*** tensor(87.1463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(76.8988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86472845
Old  loss*** tensor(1225.0293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.3176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79754984
Old  loss*** tensor(2520.5168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2010.2378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390879
Old  loss*** tensor(1677.3152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1407.4149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83711386
Old  loss*** tensor(2666.9141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2232.5107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8533102
Old  loss*** tensor(983.6331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.3442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87291354
Old  loss*** tensor(1209.0657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1055.4098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845077
Old  loss*** tensor(2858.6177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2415.7520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84043145
Old  loss*** tensor(3886.2581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3266.1335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82418025
Old  loss*** tensor(3642.5544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3002.1213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85310054
Old  loss*** tensor(1664.2240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1419.7504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87393034
Old  loss*** tensor(1592.7808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1391.9794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81626004
Old  loss*** tensor(2599.8274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2122.1353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8299411
Old  loss*** tensor(2332.0471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1935.4618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8637961
Old  loss*** tensor(1589.5632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.0586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.807448
Old  loss*** tensor(3146.1196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2540.3281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8996326
Old  loss*** tensor(1011.8173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(910.2638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81787485
Old  loss*** tensor(4214.4092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3446.8594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89903027
Old  loss*** tensor(367.6979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(330.5715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86809015
Old  loss*** tensor(2081.7246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1807.1246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7880002
Old  loss*** tensor(3624.5017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2856.1082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77832997
Old  loss*** tensor(3162.7717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2461.6799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.804743
Old  loss*** tensor(3584.3242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2884.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8144086
Old  loss*** tensor(3311.2236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2696.6890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8030647
Old  loss*** tensor(3064.1069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2460.6760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88395673
Old  loss*** tensor(692.4858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.1275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7719636
Old  loss*** tensor(4300.8579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3320.1057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7287326
Old  loss*** tensor(4637.2017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3379.2800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851777
Old  loss*** tensor(602.8716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(533.6485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88977945
Old  loss*** tensor(944.6240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(840.5070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699609
Old  loss*** tensor(2796.8540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2153.4683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807044
Old  loss*** tensor(707.6788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.2559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728087
Old  loss*** tensor(3049.2234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2661.3887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870528
Old  loss*** tensor(122.7592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(106.8653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87770987
Old  loss*** tensor(3090.5398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2712.5972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85361534
Old  loss*** tensor(1422.5634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.3219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88624716
Old  loss*** tensor(1217.4899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1078.9969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88055325
Old  loss*** tensor(1451.5396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1278.1578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864187
Old  loss*** tensor(1283.4314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1109.1248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536879
Old  loss*** tensor(3850.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3287.4917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80483735
Old  loss*** tensor(3585.9163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2886.0793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7576382
Old  loss*** tensor(4989.8403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3780.4937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773101
Old  loss*** tensor(1064.6807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(934.0551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659451
Old  loss*** tensor(733.6492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.2999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83225244
Old  loss*** tensor(4397.6260, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3659.9351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87636733
Old  loss*** tensor(1027.6709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(900.6172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8188413
Old  loss*** tensor(3012.9453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2467.1240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87747663
Old  loss*** tensor(2318.2788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.2355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813743
Old  loss*** tensor(1017.8093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(897.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.788919
Old  loss*** tensor(4548.4248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3588.3386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7817831
Old  loss*** tensor(1694.9834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1325.1094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86776125
Old  loss*** tensor(790.9194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.3292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8589097
Old  loss*** tensor(1194.9091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.3190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85210353
Old  loss*** tensor(1148.4609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.6076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493034
Old  loss*** tensor(1471.7427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.9561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87731576
Old  loss*** tensor(421.8242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(370.0731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8033682
Old  loss*** tensor(4492.2744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3608.9504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9001405
Old  loss*** tensor(255.8947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(230.3412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8449744
Old  loss*** tensor(1433.1914, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1211.0100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83249706
Old  loss*** tensor(2182.8481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1817.2147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89066386
Old  loss*** tensor(238.0434, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(212.0166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81084734
Old  loss*** tensor(2559.5044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.3674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89895743
Old  loss*** tensor(835.8505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(751.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8254828
Old  loss*** tensor(2259.2014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.9319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.834059
Old  loss*** tensor(3960.5562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3303.3374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79947037
Old  loss*** tensor(2480.8777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1983.3882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8886955
Old  loss*** tensor(1768.8768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1571.9928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88059133
Old  loss*** tensor(938.8546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.7472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8149195
Old  loss*** tensor(1971.2335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1606.3966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81829023
Old  loss*** tensor(3588.1685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2936.1631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8047646
Old  loss*** tensor(3956.7808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3184.2771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8034989
Old  loss*** tensor(2741.6982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2202.9517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8571791
Old  loss*** tensor(1911.8066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1638.7607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82520163
Old  loss*** tensor(3238.4116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2672.3425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83692515
Old  loss*** tensor(4459.9067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3732.6082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8944661
Old  loss*** tensor(1373.6304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1228.6658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89671093
Old  loss*** tensor(518.9158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(465.3174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8376438
Old  loss*** tensor(1778.7854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1489.9885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87266177
Old  loss*** tensor(753.4722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.5264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8933675
Old  loss*** tensor(994.5152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.4676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85055196
Old  loss*** tensor(2151.4607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1829.9291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336154
Old  loss*** tensor(2183.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1820.1793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74992716
Old  loss*** tensor(4393.8115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3295.0386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77866507
Old  loss*** tensor(3157.1648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2458.3740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8343426
Old  loss*** tensor(4521.6519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3772.6067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85989183
Old  loss*** tensor(4042.3491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3475.9829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654503
Old  loss*** tensor(2473.5039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2140.6948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88450706
Old  loss*** tensor(468.5587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(414.4435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8369505
Old  loss*** tensor(4220.9946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3532.7634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.833922
Old  loss*** tensor(1515.2145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1263.5707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8478575
Old  loss*** tensor(1985.6865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1683.5791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483908
Old  loss*** tensor(1235.3210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.0350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79974777
Old  loss*** tensor(4305.3643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3443.2053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926623
Old  loss*** tensor(399.9203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(356.9937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659657
Old  loss*** tensor(1540.9481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.4082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78650314
Old  loss*** tensor(3349.3103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2634.2432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85645175
Old  loss*** tensor(1758.2286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.8380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88316405
Old  loss*** tensor(1153.5648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1018.7870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773637
Old  loss*** tensor(2040.6174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1790.3636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8020598
Old  loss*** tensor(2465.3403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1977.3505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698932
Old  loss*** tensor(640.6644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(557.3096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79889995
Old  loss*** tensor(2600.6013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2077.6204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78175294
Old  loss*** tensor(3747.6875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2929.7656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89926237
Old  loss*** tensor(1150.8033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.8741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78885174
Old  loss*** tensor(4849.7090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3825.7014, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683878
Old  loss*** tensor(485.8640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(421.9184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88226485
Old  loss*** tensor(693.9325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.2322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89610887
Old  loss*** tensor(1100.3679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(986.0494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75736094
Old  loss*** tensor(4079.7419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3089.8372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90786225
Old  loss*** tensor(891.4574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(809.3205, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7628013
Old  loss*** tensor(4589.6240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3500.9712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86219984
Old  loss*** tensor(1202.4435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1036.7466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874686
Old  loss*** tensor(680.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(603.4812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8666897
Old  loss*** tensor(1014.9311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.6303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89947844
Old  loss*** tensor(1127.1022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1013.8041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793792
Old  loss*** tensor(1620.5699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.0956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85056305
Old  loss*** tensor(2343.2905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1993.1163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481424
Old  loss*** tensor(1801.7699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.1575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86763513
Old  loss*** tensor(3200.4514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2776.8240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8761632
Old  loss*** tensor(716.0021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(627.3347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558619
Old  loss*** tensor(1390.6062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.1669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85758525
Old  loss*** tensor(1091.3120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(935.8931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83673304
Old  loss*** tensor(2126.1604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1779.0287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418445
Old  loss*** tensor(2206.3931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1857.4398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77294886
Old  loss*** tensor(2766.0471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.0129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7726676
Old  loss*** tensor(2473.0586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1910.8522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8087249
Old  loss*** tensor(2371.7109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1918.0616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87433493
Old  loss*** tensor(1095.6392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(957.9556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8718404
Old  loss*** tensor(741.1715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.1833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9048168
Old  loss*** tensor(726.5252, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.3722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557273
Old  loss*** tensor(2067.6426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1769.3383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86456907
Old  loss*** tensor(1791.6411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.9974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8982518
Old  loss*** tensor(599.1354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(538.1744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512944
Old  loss*** tensor(1970.6771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.6263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75657403
Old  loss*** tensor(4877.4634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3690.1621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87128437
Old  loss*** tensor(951.7866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(829.2767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619574
Old  loss*** tensor(1376.6632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1186.6250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895321
Old  loss*** tensor(940.8540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(836.9198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878387
Old  loss*** tensor(1378.0436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1210.4556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86517495
Old  loss*** tensor(1436.5266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.8468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82534826
Old  loss*** tensor(2531.2473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2089.1606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90742934
Old  loss*** tensor(804.4977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(730.0248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8056549
Old  loss*** tensor(2848.1147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2294.5977, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84234184
Old  loss*** tensor(3037.1069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2558.2822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8892342
Old  loss*** tensor(225.6773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.6800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801965
Old  loss*** tensor(119.9885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(105.6135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857277
Old  loss*** tensor(361.8662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(320.5150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89812386
Old  loss*** tensor(728.9484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(654.6859, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85530514
Old  loss*** tensor(1928.8584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1649.7625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8068801
Old  loss*** tensor(4500.8257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3631.6267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87097484
Old  loss*** tensor(1507.9840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1313.4161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8155421
Old  loss*** tensor(2788.1101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2273.8213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632128
Old  loss*** tensor(1965.9105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1696.9991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.757954
Old  loss*** tensor(3813.2913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2890.2993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8153185
Old  loss*** tensor(3639.3442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2967.2249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806008
Old  loss*** tensor(2183.3508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1922.6605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86228746
Old  loss*** tensor(1934.7605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1668.3197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85588694
Old  loss*** tensor(911.1451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(779.8372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87418973
Old  loss*** tensor(2352.7368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2056.7383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84292966
Old  loss*** tensor(2684.6108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2262.9380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8194338
Old  loss*** tensor(2749.0420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2252.6580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89778817
Old  loss*** tensor(553.4708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.8996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573194
Old  loss*** tensor(1422.6146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.6351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8371649
Old  loss*** tensor(2998.9583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2510.6226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678496
Old  loss*** tensor(3002.2026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2605.4602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76149404
Old  loss*** tensor(4142.8462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3154.7527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.834781
Old  loss*** tensor(2409.5852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2011.4760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8229915
Old  loss*** tensor(2845.3933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2341.7344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80742395
Old  loss*** tensor(4610.3628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3722.5173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86457
Old  loss*** tensor(2011.2084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1738.8304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8265552
Old  loss*** tensor(3550.1094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2934.3613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82276255
Old  loss*** tensor(2857.3823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2350.9473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869989
Old  loss*** tensor(1526.2119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1327.7876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9074532
Old  loss*** tensor(856.1466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(776.9130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8327292
Old  loss*** tensor(1835.2388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.2570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8576654
Old  loss*** tensor(3937.2659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3376.8567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8113818
Old  loss*** tensor(3072.9595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2493.3435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86704046
Old  loss*** tensor(1579.6721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1369.6396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848305
Old  loss*** tensor(1603.8801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1419.1620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88303137
Old  loss*** tensor(142.8616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(126.1513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8794875
Old  loss*** tensor(1644.9579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.7200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87661016
Old  loss*** tensor(941.0542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(824.9377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80028164
Old  loss*** tensor(3942.2048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3154.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8207735
Old  loss*** tensor(3546.3833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2910.7773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.851487
Old  loss*** tensor(2392.4609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2037.1493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8614415
Old  loss*** tensor(2040.7488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1757.9857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89784646
Old  loss*** tensor(525.8102, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(472.0969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8448677
Old  loss*** tensor(3547.8940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2997.5012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82096
Old  loss*** tensor(3016.4873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2476.4153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8662603
Old  loss*** tensor(638.9318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(553.4812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83847535
Old  loss*** tensor(1517.5710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1272.4459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84621906
Old  loss*** tensor(1666.8965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.5596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828194
Old  loss*** tensor(94.4264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(83.3614, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8250271
Old  loss*** tensor(1035.0308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(853.9284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7805047
Old  loss*** tensor(4563.6807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3561.9741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8906437
Old  loss*** tensor(648.5826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(577.6561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86853695
Old  loss*** tensor(1126.1194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83195573
Old  loss*** tensor(1935.4462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.2056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8431132
Old  loss*** tensor(1288.0571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.9779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8988477
Old  loss*** tensor(867.3929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(779.6541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80698586
Old  loss*** tensor(3450.9680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2784.8823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87877214
Old  loss*** tensor(514.1196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.7940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87098885
Old  loss*** tensor(909.4816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.1484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83318007
Old  loss*** tensor(4017.6948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3347.4631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8294906
Old  loss*** tensor(2501.5935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.0483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563269
Old  loss*** tensor(4222.4663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3615.8113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76205474
Old  loss*** tensor(3614.5303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2754.4700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656726
Old  loss*** tensor(1099.2833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(951.6194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8338002
Old  loss*** tensor(2938.5583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2450.1704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7951262
Old  loss*** tensor(2161.5776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1718.7271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81454325
Old  loss*** tensor(2288.8835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.3947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592042
Old  loss*** tensor(1860.7939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.8019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89812386
Old  loss*** tensor(1320.6155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1186.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762696
Old  loss*** tensor(2095.3923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1836.1285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81060493
Old  loss*** tensor(3219.1160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2609.4312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888083
Old  loss*** tensor(1549.6899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1376.2533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747865
Old  loss*** tensor(930.6135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(814.0881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8098918
Old  loss*** tensor(4267.6040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3456.2976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87991947
Old  loss*** tensor(1135.8079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.4194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802848
Old  loss*** tensor(604.0588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(531.7438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84733546
Old  loss*** tensor(1323.7045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1121.6217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87581164
Old  loss*** tensor(1090.1801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(954.7924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.875443
Old  loss*** tensor(725.1040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(634.7872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77890986
Old  loss*** tensor(4233.8203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3297.7644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7970267
Old  loss*** tensor(3531.5522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2814.7415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79832774
Old  loss*** tensor(3958.5872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3160.2500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87196505
Old  loss*** tensor(1431.0149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.7949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78723705
Old  loss*** tensor(4157.1538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3272.6655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82608855
Old  loss*** tensor(3017.3979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2492.6379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7160058
Old  loss*** tensor(4647.6006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3327.7090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82418007
Old  loss*** tensor(3882.4995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3199.8787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82923704
Old  loss*** tensor(2599.9714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2155.9927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8343169
Old  loss*** tensor(3025.4253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2524.1636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8733345
Old  loss*** tensor(735.2414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.1117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88525057
Old  loss*** tensor(365.6270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(323.6715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84847414
Old  loss*** tensor(1991.3264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1689.5890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8139254
Old  loss*** tensor(1600.2783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1302.5072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89389193
Old  loss*** tensor(152.2716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(136.1143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710321
Old  loss*** tensor(1407.4150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1225.9037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8532034
Old  loss*** tensor(2026.2784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1728.8276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7893116
Old  loss*** tensor(4559.4937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3598.8611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81269014
Old  loss*** tensor(2657.7258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2159.9075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.899897
Old  loss*** tensor(743.4826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(669.0577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8397279
Old  loss*** tensor(4170.6338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3502.1975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826103
Old  loss*** tensor(675.3193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(596.0438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86489326
Old  loss*** tensor(3638.2786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3146.7227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7989639
Old  loss*** tensor(3483.6028, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2783.2729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845243
Old  loss*** tensor(2119.6248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1791.5979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89093244
Old  loss*** tensor(297.1878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(264.7742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8185125
Old  loss*** tensor(4809.2207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3936.4072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811493
Old  loss*** tensor(755.9821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.1331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746402
Old  loss*** tensor(952.8243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(833.3785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85933924
Old  loss*** tensor(900.6236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(773.9412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8499373
Old  loss*** tensor(3255.2322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2766.7434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7569511
Old  loss*** tensor(4516.5981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3418.8440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864397
Old  loss*** tensor(1665.5773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1439.7200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89413023
Old  loss*** tensor(1187.2732, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.5769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463663
Old  loss*** tensor(2281.3318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1930.8423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795692
Old  loss*** tensor(2052.2183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1805.0679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80979705
Old  loss*** tensor(3336.2012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2701.6458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85019207
Old  loss*** tensor(1947.7268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.9419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8507713
Old  loss*** tensor(1535.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.5583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8968167
Old  loss*** tensor(997.1592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(894.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8945527
Old  loss*** tensor(488.2652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(436.7790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.894838
Old  loss*** tensor(1185.8021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.1008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8382669
Old  loss*** tensor(2257.6050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1892.4756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778616
Old  loss*** tensor(1956.9763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1717.9543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80664563
Old  loss*** tensor(4218.6318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3402.9409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914602
Old  loss*** tensor(1418.4525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1264.4939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88603437
Old  loss*** tensor(358.1548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(317.3375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87151706
Old  loss*** tensor(1219.5957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1062.8984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78125435
Old  loss*** tensor(4404.5083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3441.0413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87451494
Old  loss*** tensor(1723.9181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.5922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892039
Old  loss*** tensor(684.4691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(610.5731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8226892
Old  loss*** tensor(2915.2783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2398.3679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81738436
Old  loss*** tensor(3049.4707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2492.5896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915765
Old  loss*** tensor(1445.6597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1288.9163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162595
Old  loss*** tensor(2533.6284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2068.0984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89832324
Old  loss*** tensor(927.8005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(833.4647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847535
Old  loss*** tensor(1211.1079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1071.5320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85021514
Old  loss*** tensor(1345.1506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.6675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8219277
Old  loss*** tensor(1982.5795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1629.5370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84741277
Old  loss*** tensor(2515.4058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2131.5869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85426086
Old  loss*** tensor(2708.6624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2313.9043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88552296
Old  loss*** tensor(656.6824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(581.5074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88468045
Old  loss*** tensor(1510.4431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.2595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808177
Old  loss*** tensor(1294.8602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1140.5358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86786884
Old  loss*** tensor(1952.7657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.7445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7616403
Old  loss*** tensor(4374.6548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3331.9133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388802
Old  loss*** tensor(1973.0209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.1281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784537
Old  loss*** tensor(143.7604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(126.2868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557743
Old  loss*** tensor(1571.2354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1344.6228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8950801
Old  loss*** tensor(937.6051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.2317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7965915
Old  loss*** tensor(2641.8298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2104.4592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83828557
Old  loss*** tensor(945.0576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.2281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88301355
Old  loss*** tensor(843.3494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(744.6889, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8046249
Old  loss*** tensor(3612.8479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2906.9875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85818624
Old  loss*** tensor(1222.2152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.8883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8596902
Old  loss*** tensor(2568.7996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2208.3718, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84452575
Old  loss*** tensor(2285.4993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1930.1630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8978195
Old  loss*** tensor(994.2832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(892.6869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8887472
Old  loss*** tensor(400.5253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(355.9658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86127436
Old  loss*** tensor(1739.8788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1498.5129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7666464
Old  loss*** tensor(3520.7834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2699.1958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91576463
Old  loss*** tensor(1315.2764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1204.4835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82232785
Old  loss*** tensor(2674.6970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2199.4778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7554015
Old  loss*** tensor(3227.8240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2438.3030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85435724
Old  loss*** tensor(1966.7474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.3049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7693533
Old  loss*** tensor(5076.1699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3905.3679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8150157
Old  loss*** tensor(1166.8331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(950.9873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8866344
Old  loss*** tensor(2594.0635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2299.9858, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85161245
Old  loss*** tensor(1724.5399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1468.6396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84269917
Old  loss*** tensor(1911.5398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.8530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.835734
Old  loss*** tensor(257.2004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(214.9512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75803083
Old  loss*** tensor(4355.9521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3301.9460, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83759004
Old  loss*** tensor(3058.1855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2561.5059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85607225
Old  loss*** tensor(1010.0239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.6534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552464
Old  loss*** tensor(3005.8364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2570.7310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8894607
Old  loss*** tensor(1531.4628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1362.1759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7748151
Old  loss*** tensor(2286.2119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1771.3915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74659115
Old  loss*** tensor(4792.8022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3578.2637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83577955
Old  loss*** tensor(3807.4863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3182.2192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100126
Old  loss*** tensor(4386.8457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3553.4001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7865
Old  loss*** tensor(4413.3486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3471.0986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87006545
Old  loss*** tensor(1145.4205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(996.5908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82392734
Old  loss*** tensor(3041.4138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2505.9041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88232285
Old  loss*** tensor(807.8010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.7413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729702
Old  loss*** tensor(1517.8224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1325.0138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9034823
Old  loss*** tensor(1878.5292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1697.2179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87731326
Old  loss*** tensor(1044.0044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(915.9189, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80659163
Old  loss*** tensor(3088.9509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2491.5220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556515
Old  loss*** tensor(1337.6986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1144.6038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76059294
Old  loss*** tensor(5001.5127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3804.1152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784988
Old  loss*** tensor(953.3653, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.5303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8733145
Old  loss*** tensor(1527.5289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.0132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87530303
Old  loss*** tensor(145.4009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(127.2699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88623005
Old  loss*** tensor(1703.9247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1510.0692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86647505
Old  loss*** tensor(1124.3611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.2308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81672174
Old  loss*** tensor(2252.3408, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1839.5358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7898971
Old  loss*** tensor(4703.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3714.8882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85419536
Old  loss*** tensor(3061.6272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2615.2278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500999
Old  loss*** tensor(1754.9846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1491.9122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8766783
Old  loss*** tensor(498.5182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(437.0400, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7978817
Old  loss*** tensor(3559.2583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2839.8672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100418
Old  loss*** tensor(4407.9824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3570.6499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8122759
Old  loss*** tensor(4115.7979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3343.1633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8328363
Old  loss*** tensor(2872.8162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2392.5854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870463
Old  loss*** tensor(477.8800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(415.9769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78965485
Old  loss*** tensor(4081.3447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3222.8538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89172864
Old  loss*** tensor(991.9689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(884.5671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821173
Old  loss*** tensor(778.6402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.8520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877102
Old  loss*** tensor(1183.3459, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.4683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87030923
Old  loss*** tensor(1157.1591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1007.0862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90392697
Old  loss*** tensor(659.1108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.7881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86646414
Old  loss*** tensor(1145.1036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(992.1912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8335785
Old  loss*** tensor(2520.2432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2100.8206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7185291
Old  loss*** tensor(5091.5005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3658.3914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81263644
Old  loss*** tensor(3078.5942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2501.7778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359486
Old  loss*** tensor(4072.5083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3404.4075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88569826
Old  loss*** tensor(766.3215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.7296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745844
Old  loss*** tensor(1203.3452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1052.4269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8413248
Old  loss*** tensor(4352.5894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3661.9414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727076
Old  loss*** tensor(1424.6749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.3246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87794673
Old  loss*** tensor(1838.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.0399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298259
Old  loss*** tensor(3368.8696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2795.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659202
Old  loss*** tensor(1557.8160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1348.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9045479
Old  loss*** tensor(524.7522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(474.6635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663134
Old  loss*** tensor(1610.3676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.0830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85218596
Old  loss*** tensor(2521.5295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2148.8120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87220824
Old  loss*** tensor(688.7919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(600.7700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86425185
Old  loss*** tensor(527.6772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(456.0461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80675757
Old  loss*** tensor(2875.4878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2319.8215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90000266
Old  loss*** tensor(807.5953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(726.8379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779094
Old  loss*** tensor(979.3834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(859.8099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83883023
Old  loss*** tensor(1366.7694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.4875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8805454
Old  loss*** tensor(370.6313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(326.3577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655873
Old  loss*** tensor(1328.8652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.2489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8482212
Old  loss*** tensor(2159.7456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1831.9420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8095368
Old  loss*** tensor(3008.9399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2435.8477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86558694
Old  loss*** tensor(1577.8792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1365.7916, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83832335
Old  loss*** tensor(2314.1101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1939.9725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839777
Old  loss*** tensor(2248.9290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1888.5988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85892606
Old  loss*** tensor(1197.6942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1028.7307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8434466
Old  loss*** tensor(1173.0208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8405918
Old  loss*** tensor(2430.4111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2042.9836, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556389
Old  loss*** tensor(1473.4506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.7417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888448
Old  loss*** tensor(1089.9642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(968.3765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853142
Old  loss*** tensor(405.0175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(345.5374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85455066
Old  loss*** tensor(2179.1458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1862.1904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72939694
Old  loss*** tensor(4350.1235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3172.9668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85025805
Old  loss*** tensor(2184.1396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1857.0823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86652595
Old  loss*** tensor(646.3766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(560.1021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556963
Old  loss*** tensor(2126.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1819.9115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8064519
Old  loss*** tensor(3682.5139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2969.7705, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85048854
Old  loss*** tensor(2541.1562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2161.2244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9030722
Old  loss*** tensor(1609.9106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1453.8655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336494
Old  loss*** tensor(2962.6707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2469.8286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9114921
Old  loss*** tensor(953.2725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.9004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819262
Old  loss*** tensor(1224.6920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.0879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84112394
Old  loss*** tensor(1993.1390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1676.4769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8196051
Old  loss*** tensor(4741.8569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3886.4502, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903147
Old  loss*** tensor(1773.3474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1578.8373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8051723
Old  loss*** tensor(3619.4746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2914.3008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552495
Old  loss*** tensor(2231.3774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1908.3845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8912222
Old  loss*** tensor(1666.7491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.4438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675985
Old  loss*** tensor(844.3607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(732.5660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81897366
Old  loss*** tensor(3178.5312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2603.1333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86715305
Old  loss*** tensor(765.4100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(663.7276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542011
Old  loss*** tensor(2416.0676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2063.8076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701723
Old  loss*** tensor(549.7111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.3434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84019095
Old  loss*** tensor(1121.6566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.4058, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8411661
Old  loss*** tensor(1630.3552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1371.3995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7688929
Old  loss*** tensor(2911.2493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2238.4390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83296585
Old  loss*** tensor(1673.8538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1394.2631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7631564
Old  loss*** tensor(4563.8052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3482.8972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7878804
Old  loss*** tensor(3483.8010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2744.8186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81065464
Old  loss*** tensor(3912.6384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3171.7986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85106516
Old  loss*** tensor(2383.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2028.2255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8285233
Old  loss*** tensor(1895.0531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1570.0956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903633
Old  loss*** tensor(324.4305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(288.8610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89988947
Old  loss*** tensor(932.0999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(838.7869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804983
Old  loss*** tensor(1051.5205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.8620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8589059
Old  loss*** tensor(951.7571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(817.4698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81909597
Old  loss*** tensor(3290.0239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2694.8452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793956
Old  loss*** tensor(1504.9971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1323.4878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8385922
Old  loss*** tensor(965.9405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(810.0302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764719
Old  loss*** tensor(1055.3496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(924.9843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892519
Old  loss*** tensor(1570.7126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.8909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616158
Old  loss*** tensor(862.1157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(742.8124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79016423
Old  loss*** tensor(4098.6558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3238.6111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9282279
Old  loss*** tensor(1179.6470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1094.9812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885151
Old  loss*** tensor(569.1544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(503.7876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78010976
Old  loss*** tensor(3483.3486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2717.3943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88031185
Old  loss*** tensor(3975.1082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.3347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85077274
Old  loss*** tensor(2827.3628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2405.4431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8036083
Old  loss*** tensor(2260.8499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1816.8376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857241
Old  loss*** tensor(810.2091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(717.6218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804609
Old  loss*** tensor(87.1533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(76.7351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84516436
Old  loss*** tensor(2877.8450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2432.2520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81200343
Old  loss*** tensor(3628.9092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2946.6868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8191476
Old  loss*** tensor(3780.0505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3096.4192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90139323
Old  loss*** tensor(1024.1615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(923.1722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83925366
Old  loss*** tensor(1956.9656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1642.3905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831171
Old  loss*** tensor(420.8702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(371.6777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89384365
Old  loss*** tensor(1229.3646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.8597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84204096
Old  loss*** tensor(3172.6831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2671.5291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885528
Old  loss*** tensor(1530.6201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1355.4070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82730675
Old  loss*** tensor(2060.7429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1704.8666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699462
Old  loss*** tensor(3351.2197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2580.2590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88232756
Old  loss*** tensor(1583.8893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1397.5092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8686797
Old  loss*** tensor(2837.9250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2465.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76539433
Old  loss*** tensor(4533.6802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3470.0532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8138418
Old  loss*** tensor(2958.3049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2407.5923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8768245
Old  loss*** tensor(665.4866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(583.5150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82132614
Old  loss*** tensor(4354.2285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3576.2417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90607965
Old  loss*** tensor(538.7433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(488.1443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601041
Old  loss*** tensor(1704.0975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.7013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71597505
Old  loss*** tensor(4501.2524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3222.7844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85691863
Old  loss*** tensor(1302.7931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1116.3877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7816125
Old  loss*** tensor(3932.0852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3073.3669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677689
Old  loss*** tensor(810.4212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(703.2583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85564417
Old  loss*** tensor(2543.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2176.2427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89915866
Old  loss*** tensor(372.0254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(334.5099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88005424
Old  loss*** tensor(1266.5385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1114.6226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80880964
Old  loss*** tensor(2708.9944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2191.0608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549204
Old  loss*** tensor(2884.7690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2466.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853883
Old  loss*** tensor(706.9377, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.9144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061798
Old  loss*** tensor(4054.8423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3268.9321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80710477
Old  loss*** tensor(4418.4854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3566.1807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861911
Old  loss*** tensor(1401.7751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.2407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87217665
Old  loss*** tensor(1268.9153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1106.7183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519043
Old  loss*** tensor(1809.9340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1541.8905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653872
Old  loss*** tensor(742.6103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.6454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88982457
Old  loss*** tensor(306.8594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(273.0510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83463407
Old  loss*** tensor(2461.4314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2054.3945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7573118
Old  loss*** tensor(4923.7500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3728.8140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7997828
Old  loss*** tensor(3246.6572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2596.6206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81195927
Old  loss*** tensor(2461.0054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1998.2361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8107984
Old  loss*** tensor(2641.9353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2142.0769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82134414
Old  loss*** tensor(1999.9186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1642.6215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85691094
Old  loss*** tensor(1458.5470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.8448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88278174
Old  loss*** tensor(459.4946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.6334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89666
Old  loss*** tensor(214.3091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(192.1624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8300687
Old  loss*** tensor(2046.5624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1698.7874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81357753
Old  loss*** tensor(3022.2476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2458.8328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8676114
Old  loss*** tensor(925.2067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.7199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8033984
Old  loss*** tensor(962.6545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(773.3951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84668624
Old  loss*** tensor(2029.9620, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1718.7410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81700444
Old  loss*** tensor(4393.8843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3589.8230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850235
Old  loss*** tensor(851.7987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(753.8619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8511722
Old  loss*** tensor(2057.5100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1751.2953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807162
Old  loss*** tensor(752.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(662.6736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506818
Old  loss*** tensor(1352.1055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.2115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9106509
Old  loss*** tensor(231.3985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(210.7233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7844636
Old  loss*** tensor(2430.1921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.3972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881974
Old  loss*** tensor(2810.6626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.9314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8374143
Old  loss*** tensor(1711.9553, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1433.6160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536469
Old  loss*** tensor(1895.8927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1618.4229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735484
Old  loss*** tensor(1006.7032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.4039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860246
Old  loss*** tensor(3360.9309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2891.2273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82907933
Old  loss*** tensor(1304.3708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1081.4269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084513
Old  loss*** tensor(4465.4556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3610.1033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806024
Old  loss*** tensor(2964.1431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2610.2314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717687
Old  loss*** tensor(4135.8462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3605.5012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8475033
Old  loss*** tensor(2247.7178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.9482, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809672
Old  loss*** tensor(1202.2777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.1672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539332
Old  loss*** tensor(1535.3993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1311.1284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82533586
Old  loss*** tensor(2386.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1969.8029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646822
Old  loss*** tensor(2090.0178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1807.2012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7562443
Old  loss*** tensor(5158.6812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3901.2231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88622344
Old  loss*** tensor(703.1635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.1600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83390033
Old  loss*** tensor(2713.8596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2263.0884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639165
Old  loss*** tensor(960.4888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(829.7821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8574197
Old  loss*** tensor(2476.5854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2123.4731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88458335
Old  loss*** tensor(1392.5850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.8574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826866
Old  loss*** tensor(530.3898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(468.1679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80557764
Old  loss*** tensor(3687.2874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2970.3962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8017681
Old  loss*** tensor(4792.4766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3842.4548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670538
Old  loss*** tensor(1631.0815, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.2355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86953545
Old  loss*** tensor(1295.3423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1126.3461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8132845
Old  loss*** tensor(3241.3787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2636.1631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90632254
Old  loss*** tensor(347.8967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(315.3066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7818295
Old  loss*** tensor(3589.1680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2806.1174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81394637
Old  loss*** tensor(2141.5435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1743.1016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776816
Old  loss*** tensor(3057.7222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.7065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84378535
Old  loss*** tensor(1769.6636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1493.2162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76017416
Old  loss*** tensor(3321.1191, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2524.6289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9080907
Old  loss*** tensor(1058.5287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.2401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79918706
Old  loss*** tensor(2426.1033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1938.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86651397
Old  loss*** tensor(1234.8485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1070.0134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8550633
Old  loss*** tensor(1534.0084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1311.6743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8517947
Old  loss*** tensor(1726.1063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1470.2882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621694
Old  loss*** tensor(1030.8497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.7671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85298145
Old  loss*** tensor(1453.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.1567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88487446
Old  loss*** tensor(1089.6478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(964.2015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8952274
Old  loss*** tensor(517.7209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(463.4779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74360245
Old  loss*** tensor(4121.1953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3064.5310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8011147
Old  loss*** tensor(3253.6006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2606.5071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86243296
Old  loss*** tensor(1320.1271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1138.5211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9060588
Old  loss*** tensor(1192.5492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.5197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8488802
Old  loss*** tensor(1649.0066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.8090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.6801585
Old  loss*** tensor(4114.2383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2798.3342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601282
Old  loss*** tensor(1410.6727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.3594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872319
Old  loss*** tensor(1254.4338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1094.2665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91256523
Old  loss*** tensor(934.7294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(853.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750404
Old  loss*** tensor(593.7292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.5370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87180173
Old  loss*** tensor(1903.1237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.1465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764404
Old  loss*** tensor(399.8496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(350.4444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8898908
Old  loss*** tensor(131.7793, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(117.2692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415224
Old  loss*** tensor(984.1005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(828.1426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87975657
Old  loss*** tensor(1341.8108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1180.4669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90246624
Old  loss*** tensor(1243.1312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1121.8839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77722114
Old  loss*** tensor(2887.8306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2244.4829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7513372
Old  loss*** tensor(5079.9355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3816.7444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8207707
Old  loss*** tensor(2275.8975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1867.9899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87304986
Old  loss*** tensor(1052.3557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(918.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8963555
Old  loss*** tensor(705.0205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(631.9490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807695
Old  loss*** tensor(531.7249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(468.3270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080581
Old  loss*** tensor(3733.3416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3016.7568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775052
Old  loss*** tensor(382.7889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(335.8993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84786624
Old  loss*** tensor(2886.8745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2447.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85612893
Old  loss*** tensor(1948.9822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1668.5801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8782767
Old  loss*** tensor(4158.9346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3652.6953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86512697
Old  loss*** tensor(1391.2328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1203.5930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.836336
Old  loss*** tensor(3535.0310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2956.4736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9120682
Old  loss*** tensor(1487.6007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1356.7933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86859393
Old  loss*** tensor(791.6451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(687.6181, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86130244
Old  loss*** tensor(1157.7031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(997.1325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79665405
Old  loss*** tensor(2435.3254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1940.1118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7905949
Old  loss*** tensor(4444.1328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3513.5085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8498144
Old  loss*** tensor(4006.6106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3404.8755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7503389
Old  loss*** tensor(4978.3770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3735.4700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85586786
Old  loss*** tensor(1955.8839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1673.9781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88328016
Old  loss*** tensor(709.0223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(626.2653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7842689
Old  loss*** tensor(4511.4990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3538.2285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8279295
Old  loss*** tensor(4558.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3774.0989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8994671
Old  loss*** tensor(746.0156, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(671.0165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558781
Old  loss*** tensor(1027.3130, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.2547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8044877
Old  loss*** tensor(3069.0588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2469.0200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8249301
Old  loss*** tensor(3314.7356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2734.4250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8766047
Old  loss*** tensor(89.8919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(78.7997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7835376
Old  loss*** tensor(4174.1606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3270.6118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8119931
Old  loss*** tensor(2567.5535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2084.8357, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585652
Old  loss*** tensor(1024.9438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.9811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8394608
Old  loss*** tensor(1815.1124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1523.7157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8940207
Old  loss*** tensor(252.5390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(225.7751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81292284
Old  loss*** tensor(1761.1428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.6732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90427744
Old  loss*** tensor(943.0081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(852.7409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.825696
Old  loss*** tensor(2875.1357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2373.9880, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86966956
Old  loss*** tensor(1524.0566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1325.4257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647064
Old  loss*** tensor(1870.3608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1617.3130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7901873
Old  loss*** tensor(3507.3530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2771.4658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74466336
Old  loss*** tensor(4317.7080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3215.2390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7986276
Old  loss*** tensor(4103.7900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3277.4001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.816537
Old  loss*** tensor(3543.5405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2893.4321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8757901
Old  loss*** tensor(1521.9188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1332.8815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89075184
Old  loss*** tensor(2123.6675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1891.6608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770107
Old  loss*** tensor(1739.5668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1525.6187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87983394
Old  loss*** tensor(512.6365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.0350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8008089
Old  loss*** tensor(3297.5122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2640.6772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7797151
Old  loss*** tensor(3787.7190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2953.3418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8668383
Old  loss*** tensor(785.0077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.4747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9026422
Old  loss*** tensor(576.3558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.2431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89885914
Old  loss*** tensor(230.6536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(207.3251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80424535
Old  loss*** tensor(4110.5469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3305.8882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87596333
Old  loss*** tensor(1612.8958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.8375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84605837
Old  loss*** tensor(1666.2823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1409.7721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89084125
Old  loss*** tensor(643.1663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(572.9590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88453996
Old  loss*** tensor(1031.1205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(912.0673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828198
Old  loss*** tensor(838.7026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(740.4232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7957752
Old  loss*** tensor(4088.7590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3253.7329, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85011256
Old  loss*** tensor(2347.5137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1995.6509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85900694
Old  loss*** tensor(1644.5682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.6956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297901
Old  loss*** tensor(3289.7493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2729.8015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84939915
Old  loss*** tensor(1208.9160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.8523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7941351
Old  loss*** tensor(4117.8184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3270.1040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795395
Old  loss*** tensor(895.0825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(787.2604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8863315
Old  loss*** tensor(1012.8626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(897.7321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86448133
Old  loss*** tensor(3996.6240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3455.0068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82122076
Old  loss*** tensor(2842.5293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2334.3440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90008426
Old  loss*** tensor(1136.2980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.7639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8167412
Old  loss*** tensor(4068.1279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3322.6079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819392
Old  loss*** tensor(1223.2007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1078.7886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80589163
Old  loss*** tensor(2934.3259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2364.7488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8063951
Old  loss*** tensor(2498.2134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2014.5471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7882003
Old  loss*** tensor(5006.1738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3945.8679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87139535
Old  loss*** tensor(1930.3145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1682.0670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500449
Old  loss*** tensor(2757.4272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2343.9370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74517
Old  loss*** tensor(4821.9023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3593.1370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793051
Old  loss*** tensor(2922.2224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2569.5251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86210865
Old  loss*** tensor(588.8027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(507.6119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8737813
Old  loss*** tensor(909.1447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(794.3936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8246009
Old  loss*** tensor(2199.0938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1813.3746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8662798
Old  loss*** tensor(1061.1497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.2525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8899753
Old  loss*** tensor(451.6393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.9479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87281454
Old  loss*** tensor(2256.9961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1969.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87459743
Old  loss*** tensor(1306.5602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.7142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83228683
Old  loss*** tensor(2592.8025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2157.9553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8707769
Old  loss*** tensor(822.2891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(716.0303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426511
Old  loss*** tensor(1513.3944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1275.2635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76958025
Old  loss*** tensor(3726.2549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2867.6521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88167113
Old  loss*** tensor(724.7705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.0092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86107606
Old  loss*** tensor(1419.1726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1222.0155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85396284
Old  loss*** tensor(3419.7310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2920.3232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83171165
Old  loss*** tensor(2021.6228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1681.4072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752487
Old  loss*** tensor(653.3822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.8719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284964
Old  loss*** tensor(2294.9265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1901.3384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785671
Old  loss*** tensor(1522.2864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1337.4308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88880146
Old  loss*** tensor(1285.7460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.7729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744484
Old  loss*** tensor(865.6104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(756.9316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639866
Old  loss*** tensor(2601.4839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2247.6472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9082218
Old  loss*** tensor(637.2020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(578.7207, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8236165
Old  loss*** tensor(1602.7783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1320.0747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86859965
Old  loss*** tensor(1451.6169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.8740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8657882
Old  loss*** tensor(1721.5656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.5112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85117245
Old  loss*** tensor(4215.7510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3588.3311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8173913
Old  loss*** tensor(1285.4103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.6831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8587493
Old  loss*** tensor(1264.1047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.5491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775201
Old  loss*** tensor(354.5547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(311.1288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8328798
Old  loss*** tensor(2606.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2171.0410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8444748
Old  loss*** tensor(2058.1858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1738.0861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775934
Old  loss*** tensor(1398.3167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.1534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89256704
Old  loss*** tensor(482.5658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(430.7223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86942905
Old  loss*** tensor(1156.8423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.7923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8108728
Old  loss*** tensor(2214.2678, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1795.4895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869463
Old  loss*** tensor(473.7998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(420.2350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87498546
Old  loss*** tensor(103.5168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(90.5757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86059666
Old  loss*** tensor(2638.9631, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2271.0828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84070104
Old  loss*** tensor(4274.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3593.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664969
Old  loss*** tensor(1216.1381, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.7799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7889521
Old  loss*** tensor(4177.4775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3295.8298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79032445
Old  loss*** tensor(4112.5894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3250.2800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697232
Old  loss*** tensor(3665.8433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3188.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88253963
Old  loss*** tensor(1328.0382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1172.0464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560451
Old  loss*** tensor(2946.0479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2521.9500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8465907
Old  loss*** tensor(2627.4387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2224.3652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8212676
Old  loss*** tensor(3164.9880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2599.3022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82957906
Old  loss*** tensor(2147.9038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1781.8560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80591965
Old  loss*** tensor(2993.3318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2412.3850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7579851
Old  loss*** tensor(5162.2720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3912.9253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873418
Old  loss*** tensor(1718.9194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1525.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8386318
Old  loss*** tensor(3699.6765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3102.6665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87467086
Old  loss*** tensor(1866.8231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1632.8558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7890182
Old  loss*** tensor(4522.2500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3568.1377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82452625
Old  loss*** tensor(3582.4746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2953.8442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818184
Old  loss*** tensor(1106.5618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.7866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87869096
Old  loss*** tensor(2317.5454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.4062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83790386
Old  loss*** tensor(1971.6462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.0500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77228343
Old  loss*** tensor(4004.4397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3092.5625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9069421
Old  loss*** tensor(965.5226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(875.6732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421577
Old  loss*** tensor(2504.4885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2109.1743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85237944
Old  loss*** tensor(2702.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2303.1799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8751244
Old  loss*** tensor(1374.3948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1202.7664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88464665
Old  loss*** tensor(1148.8917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.3632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80812323
Old  loss*** tensor(2515.1074, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2032.5167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89125955
Old  loss*** tensor(1142.9822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1018.6938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87566054
Old  loss*** tensor(1642.0259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1437.8573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696291
Old  loss*** tensor(765.5156, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.7146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8443682
Old  loss*** tensor(2173.4929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1835.2284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8436413
Old  loss*** tensor(4250.3335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.7568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812608
Old  loss*** tensor(885.8814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(780.6926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89371717
Old  loss*** tensor(723.3409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.4622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88092315
Old  loss*** tensor(997.4634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(878.6886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9017477
Old  loss*** tensor(2274.4241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2050.9568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586803
Old  loss*** tensor(1629.6327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.3335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84122586
Old  loss*** tensor(3952.8020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3325.1992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83705866
Old  loss*** tensor(3252.5781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2722.5986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85050374
Old  loss*** tensor(2633.3611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2239.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671746
Old  loss*** tensor(3860.8921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3348.0676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84200597
Old  loss*** tensor(1614.9175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.7701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9084295
Old  loss*** tensor(583.2734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(529.8627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83998364
Old  loss*** tensor(1021.8954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.3754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8361428
Old  loss*** tensor(3673.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3071.3887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85052365
Old  loss*** tensor(2114.1631, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1798.1458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506124
Old  loss*** tensor(1423.4436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1210.7988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7915151
Old  loss*** tensor(3603.8047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2852.4658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87568676
Old  loss*** tensor(404.4780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(354.1960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.786154
Old  loss*** tensor(4668.9902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3670.5452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88713
Old  loss*** tensor(996.1144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.6830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84631145
Old  loss*** tensor(1305.8029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1105.1160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7385923
Old  loss*** tensor(4144.7358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3061.2700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84956586
Old  loss*** tensor(2903.0647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2466.3447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8702471
Old  loss*** tensor(2181.1880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1898.1726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8971951
Old  loss*** tensor(1036.8199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(930.2298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8435736
Old  loss*** tensor(1797.5750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1516.3867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82690793
Old  loss*** tensor(2875.5198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2377.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79934394
Old  loss*** tensor(4321.4512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3454.3259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8277536
Old  loss*** tensor(3767.7161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.7405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500513
Old  loss*** tensor(1547.2612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1315.2513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87034833
Old  loss*** tensor(1285.1061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1118.4900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86601526
Old  loss*** tensor(1160.8898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.3483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879145
Old  loss*** tensor(137.1768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(120.5983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8068505
Old  loss*** tensor(2175.9910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1755.6993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8970201
Old  loss*** tensor(423.2025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.6211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872319
Old  loss*** tensor(576.4492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(502.8476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8184103
Old  loss*** tensor(3446.0227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2820.2605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88109833
Old  loss*** tensor(1630.0769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.2581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872177
Old  loss*** tensor(1533.7965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1337.7421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86860394
Old  loss*** tensor(1318.4602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1145.2197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87750113
Old  loss*** tensor(644.7812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(565.7962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86878896
Old  loss*** tensor(459.5331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.2372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71373475
Old  loss*** tensor(4595.4580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3279.9380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387965
Old  loss*** tensor(1058.2845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.6854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704839
Old  loss*** tensor(755.0918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.2952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8395605
Old  loss*** tensor(3053.0610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2563.2295, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656172
Old  loss*** tensor(2861.8088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2477.2310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7980197
Old  loss*** tensor(2825.1726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2254.5435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610114
Old  loss*** tensor(444.1304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(382.4013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7912847
Old  loss*** tensor(5064.7417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4007.6526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780004
Old  loss*** tensor(1430.0188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.5570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8447405
Old  loss*** tensor(1589.6338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1342.8280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563343
Old  loss*** tensor(1422.9221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1218.4971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586051
Old  loss*** tensor(1846.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.1276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700605
Old  loss*** tensor(1171.5629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.3306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87772226
Old  loss*** tensor(1949.5585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.1709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87924147
Old  loss*** tensor(3634.6582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3195.7422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8329617
Old  loss*** tensor(3301.5410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2750.0571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88938904
Old  loss*** tensor(769.9070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(684.7468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81907046
Old  loss*** tensor(3276.1470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.3953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7973851
Old  loss*** tensor(5290.3413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4218.4395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857118
Old  loss*** tensor(1755.1697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1504.3876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388624
Old  loss*** tensor(3049.5957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2558.1912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502851
Old  loss*** tensor(1183.1741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.0353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84550136
Old  loss*** tensor(2609.2583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2206.1313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89153755
Old  loss*** tensor(1325.9700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1182.1520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86869746
Old  loss*** tensor(794.4318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.1208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84620595
Old  loss*** tensor(1884.1821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1594.4061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89396226
Old  loss*** tensor(2411.4807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2155.7727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82558644
Old  loss*** tensor(2051.4270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.6304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639188
Old  loss*** tensor(1975.3937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1706.5797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888141
Old  loss*** tensor(823.2643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(731.1747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610497
Old  loss*** tensor(2033.0094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1750.5222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80121696
Old  loss*** tensor(4245.7090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3401.7341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86358684
Old  loss*** tensor(879.9799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8352514
Old  loss*** tensor(4219.0640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3523.9790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808046
Old  loss*** tensor(2429.2141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.6628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860494
Old  loss*** tensor(3879.2253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.1853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659237
Old  loss*** tensor(2251.1445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1949.3195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873003
Old  loss*** tensor(1098.2095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(958.7402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84316385
Old  loss*** tensor(1634.2974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1377.9805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8957055
Old  loss*** tensor(283.8244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(254.2231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819568
Old  loss*** tensor(442.8803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.6013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.851606
Old  loss*** tensor(2119.7224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1805.1683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88499045
Old  loss*** tensor(835.6918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.5792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619902
Old  loss*** tensor(1464.1340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1262.0692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8987862
Old  loss*** tensor(252.3906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(226.8452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82818127
Old  loss*** tensor(2937.2129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2432.5447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78772116
Old  loss*** tensor(2778.7166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2188.8538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675171
Old  loss*** tensor(1020.4854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(885.2885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8113189
Old  loss*** tensor(1814.8521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1472.4237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669989
Old  loss*** tensor(1628.4226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1411.8406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8954338
Old  loss*** tensor(1138.8673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.7803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84107244
Old  loss*** tensor(4627.7251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3892.2520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8555648
Old  loss*** tensor(1613.2960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1380.2793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7468481
Old  loss*** tensor(5139.5771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3838.4834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86212575
Old  loss*** tensor(1165.2603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1004.6009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9087576
Old  loss*** tensor(682.9798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(620.6631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85801655
Old  loss*** tensor(1527.8953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1310.9595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7978498
Old  loss*** tensor(2610.9026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.1082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639314
Old  loss*** tensor(699.3601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(604.1992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87641454
Old  loss*** tensor(153.4503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(134.4861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297143
Old  loss*** tensor(4519.5107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3749.9026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82581306
Old  loss*** tensor(4290.4141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3543.0798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8334602
Old  loss*** tensor(1283.7159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1069.9261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86994594
Old  loss*** tensor(472.2010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(410.7893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336152
Old  loss*** tensor(2931.5847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2443.8135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.761241
Old  loss*** tensor(4266.4399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3247.7891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786734
Old  loss*** tensor(1307.9683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.2769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85089743
Old  loss*** tensor(945.4939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(804.5183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7875022
Old  loss*** tensor(3931.1650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3095.8013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82658404
Old  loss*** tensor(1911.2173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1579.7817, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8225821
Old  loss*** tensor(2962.1443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2436.6069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85994375
Old  loss*** tensor(2143.1506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1842.9890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7797685
Old  loss*** tensor(4342.1890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3385.9023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89010286
Old  loss*** tensor(658.5096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.1412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83313
Old  loss*** tensor(3964.4438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3302.8972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770742
Old  loss*** tensor(1751.4679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.1672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87015676
Old  loss*** tensor(1202.7032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1046.5404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8918894
Old  loss*** tensor(687.1849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.8929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642752
Old  loss*** tensor(2714.7742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2346.3120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746127
Old  loss*** tensor(1014.1412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.9808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87642753
Old  loss*** tensor(712.2042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(624.1953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88008374
Old  loss*** tensor(186.5140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(164.1479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867147
Old  loss*** tensor(573.1011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(508.1772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8204887
Old  loss*** tensor(1455.5261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.2427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.834044
Old  loss*** tensor(2355.9937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1965.0023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7131814
Old  loss*** tensor(4714.3286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.1714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87673324
Old  loss*** tensor(1186.8633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1040.5625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845785
Old  loss*** tensor(1719.7942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1454.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85668766
Old  loss*** tensor(4122.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3531.4585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86852455
Old  loss*** tensor(1602.8241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1392.0920, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8233886
Old  loss*** tensor(2290.3657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.8610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609535
Old  loss*** tensor(2341.0271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2015.5155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88518804
Old  loss*** tensor(1002.2783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.2048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81889814
Old  loss*** tensor(3066.3362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2511.0171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8191959
Old  loss*** tensor(2942.0818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2410.1414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.69808805
Old  loss*** tensor(4308.0244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3007.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869413
Old  loss*** tensor(1402.5326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.3801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618344
Old  loss*** tensor(1398.1158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1204.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8266529
Old  loss*** tensor(2132.3386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1762.7039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8361136
Old  loss*** tensor(1623.5667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.4861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86903125
Old  loss*** tensor(407.0489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(353.7382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8726154
Old  loss*** tensor(1028.0267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(897.0720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83837986
Old  loss*** tensor(2208.9956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1851.9774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83904713
Old  loss*** tensor(2849.9958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.2808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8464133
Old  loss*** tensor(1987.8009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1682.5011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78907245
Old  loss*** tensor(3553.7834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2804.1926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7955482
Old  loss*** tensor(4007.7908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3188.3906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8105968
Old  loss*** tensor(3047.9565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2470.6638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84514797
Old  loss*** tensor(1638.5840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1384.8459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8899983
Old  loss*** tensor(729.3522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.1223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8913232
Old  loss*** tensor(987.5872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(880.2593, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83041894
Old  loss*** tensor(3423.5967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2843.0195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87426245
Old  loss*** tensor(1308.1920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.7031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89022934
Old  loss*** tensor(1679.7428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1495.3563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8470339
Old  loss*** tensor(2707.6951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2293.5095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663403
Old  loss*** tensor(522.1551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(452.3640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83477676
Old  loss*** tensor(2232.7996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1863.8892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8183384
Old  loss*** tensor(3945.4802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3228.7380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851969
Old  loss*** tensor(1214.0353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1074.6603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85877734
Old  loss*** tensor(868.3007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.6770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88308287
Old  loss*** tensor(568.6904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(502.2007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8652852
Old  loss*** tensor(2456.2712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2125.3752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79912424
Old  loss*** tensor(3332.6523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2663.2034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7935155
Old  loss*** tensor(3098.4758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2458.6887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8651443
Old  loss*** tensor(1222.1388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.3264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86585855
Old  loss*** tensor(1274.1829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1103.2621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8434155
Old  loss*** tensor(1098.3856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(926.3954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8120328
Old  loss*** tensor(2412.8376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1959.3033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8595851
Old  loss*** tensor(2938.8186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2526.1648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821938
Old  loss*** tensor(1718.9561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1516.4524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7483787
Old  loss*** tensor(5073.1172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3796.6128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855023
Old  loss*** tensor(2125.7388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1817.5555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83171964
Old  loss*** tensor(1736.7982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1444.5292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7546152
Old  loss*** tensor(5074.4521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3829.2585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848879
Old  loss*** tensor(668.2401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(591.3175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82195085
Old  loss*** tensor(2318.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.0619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8171884
Old  loss*** tensor(3311.4285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2706.0608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81779677
Old  loss*** tensor(1822.8385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.7114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512932
Old  loss*** tensor(1802.1088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1534.1229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89318323
Old  loss*** tensor(224.4046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.4344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7690532
Old  loss*** tensor(4099.6943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3152.8831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8971127
Old  loss*** tensor(413.3268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(370.8008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615768
Old  loss*** tensor(1528.1696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.6354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84063274
Old  loss*** tensor(2369.9639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1992.2692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890025
Old  loss*** tensor(447.5677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(397.8888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8236497
Old  loss*** tensor(1980.7911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1631.4780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8722576
Old  loss*** tensor(1098.5659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(958.2325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885617
Old  loss*** tensor(564.6194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.0366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8287903
Old  loss*** tensor(2268.4705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1880.0863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7983255
Old  loss*** tensor(4358.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3479.4194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79252887
Old  loss*** tensor(2089.5020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.9906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7908473
Old  loss*** tensor(2519.6812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1992.6830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713734
Old  loss*** tensor(4006.7271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3491.3555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87389594
Old  loss*** tensor(1285.6162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1123.4948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87552947
Old  loss*** tensor(934.5947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.2652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816898
Old  loss*** tensor(146.0887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(128.8049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8160094
Old  loss*** tensor(2130.9258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1738.8555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84111047
Old  loss*** tensor(3917.9956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3295.4670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661066
Old  loss*** tensor(1883.5023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1631.3138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88626266
Old  loss*** tensor(959.5699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.4310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512213
Old  loss*** tensor(1457.5291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.6798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8449191
Old  loss*** tensor(2268.6660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1916.8392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7771641
Old  loss*** tensor(3762.2844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2923.9124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8457567
Old  loss*** tensor(3450.5488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2918.3247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88066524
Old  loss*** tensor(589.9872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.5812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86922365
Old  loss*** tensor(1910.2693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1660.4513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8150511
Old  loss*** tensor(2638.8196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2150.7727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82488304
Old  loss*** tensor(1964.8365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1620.7604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88853776
Old  loss*** tensor(816.1808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(725.2075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881392
Old  loss*** tensor(932.3453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(821.7617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874328
Old  loss*** tensor(963.4723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.0169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673365
Old  loss*** tensor(1808.8118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1568.8485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88900244
Old  loss*** tensor(95.2233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(84.6537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7482809
Old  loss*** tensor(3767.4673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2819.1238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78842235
Old  loss*** tensor(3948.7747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3113.3022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87847245
Old  loss*** tensor(1093.6344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(960.7277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84566504
Old  loss*** tensor(4085.4966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3454.9617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663932
Old  loss*** tensor(1619.0510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1402.7349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818809
Old  loss*** tensor(1018.7151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.3854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8003086
Old  loss*** tensor(3014.0928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2412.2043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7655829
Old  loss*** tensor(3619.0886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2770.7124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84078515
Old  loss*** tensor(2461.3994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.5081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.891461
Old  loss*** tensor(460.5924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(410.6002, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84885395
Old  loss*** tensor(2968.3064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2519.6587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050077
Old  loss*** tensor(3276.5166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2637.6211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86356544
Old  loss*** tensor(1644.6998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1420.3059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884094
Old  loss*** tensor(1136.3354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.5311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85144633
Old  loss*** tensor(1750.4531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.4169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8887863
Old  loss*** tensor(1110.4163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(986.9228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7470989
Old  loss*** tensor(5034.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3761.1184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88837767
Old  loss*** tensor(1580.9501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.4807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87271273
Old  loss*** tensor(1200.4058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1047.6094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840274
Old  loss*** tensor(827.2303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(731.2943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81241465
Old  loss*** tensor(4239.8667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3444.5298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8241551
Old  loss*** tensor(3187.8384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2627.2732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88093424
Old  loss*** tensor(2088.9927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1840.2651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647493
Old  loss*** tensor(777.3817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(672.2402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88935626
Old  loss*** tensor(1180.1616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.5841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89377606
Old  loss*** tensor(986.1088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.3604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8954768
Old  loss*** tensor(515.2963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.4359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81026644
Old  loss*** tensor(4038.0679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3271.9109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86671877
Old  loss*** tensor(1718.3932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1489.3636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8329741
Old  loss*** tensor(2152.6294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1793.0845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87145466
Old  loss*** tensor(1086.3379, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(946.6942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460667
Old  loss*** tensor(1924.2817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1628.0707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8312038
Old  loss*** tensor(1685.8860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.3148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78990406
Old  loss*** tensor(2441.9709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1928.9227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85598636
Old  loss*** tensor(1943.1055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1663.2717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90487236
Old  loss*** tensor(303.9287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(275.0167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79533213
Old  loss*** tensor(2793.5244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2221.7798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72762704
Old  loss*** tensor(4205.7324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3060.2046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244335
Old  loss*** tensor(2556.4072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2107.5879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86341333
Old  loss*** tensor(2194.5254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1894.7825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.812554
Old  loss*** tensor(4439.3350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3607.1995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724952
Old  loss*** tensor(1506.0055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1313.9825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804067
Old  loss*** tensor(2094.4453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1843.9636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674166
Old  loss*** tensor(709.8776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(615.7596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85981655
Old  loss*** tensor(1277.2964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.2406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81344306
Old  loss*** tensor(4512.7485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3670.8640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.866844
Old  loss*** tensor(1859.1110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1611.5592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828988
Old  loss*** tensor(708.2805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.3400, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86226547
Old  loss*** tensor(2592.3088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2235.2583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665774
Old  loss*** tensor(1376.2683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1192.6429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8871803
Old  loss*** tensor(685.9283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(608.5421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7199564
Old  loss*** tensor(4774.0659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.1194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88778603
Old  loss*** tensor(693.6866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(615.8453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8425549
Old  loss*** tensor(2559.9446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2156.8938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87012744
Old  loss*** tensor(858.0137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(746.5812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8238689
Old  loss*** tensor(3603.3306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2968.6719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7941716
Old  loss*** tensor(3344.1741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2655.8479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8603195
Old  loss*** tensor(1361.1201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1170.9982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81169736
Old  loss*** tensor(2881.9065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2339.2358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758348
Old  loss*** tensor(531.6572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(465.6439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890445
Old  loss*** tensor(195.7545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(174.3086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76830816
Old  loss*** tensor(5245.2656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4029.9805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8251898
Old  loss*** tensor(3136.5132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2588.2188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8375362
Old  loss*** tensor(2638.4082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2209.7625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89284486
Old  loss*** tensor(1575.4972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1406.6746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76501524
Old  loss*** tensor(4028.0918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3081.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774627
Old  loss*** tensor(475.4328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(417.1746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8253588
Old  loss*** tensor(3215.1265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2653.6331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8589028
Old  loss*** tensor(1651.9664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1418.8787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85356474
Old  loss*** tensor(2136.1462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1823.3391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83906984
Old  loss*** tensor(3056.4375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2564.5645, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7825709
Old  loss*** tensor(1999.6443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1564.8634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7923832
Old  loss*** tensor(3168.5332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2510.6924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8571142
Old  loss*** tensor(1807.5490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1549.2759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86300415
Old  loss*** tensor(1207.6375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1042.1962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88654256
Old  loss*** tensor(384.0273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(340.4565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.790501
Old  loss*** tensor(3813.6726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3014.7119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81148756
Old  loss*** tensor(2298.1536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.9230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165117
Old  loss*** tensor(2430.3208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1984.3854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88311166
Old  loss*** tensor(1277.9655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1128.5862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667762
Old  loss*** tensor(1120.9077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(971.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885051
Old  loss*** tensor(658.3041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(582.6327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8231783
Old  loss*** tensor(2577.5366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2121.7722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573797
Old  loss*** tensor(2120.2644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1817.8716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9074102
Old  loss*** tensor(2607.4417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2366.0190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7997224
Old  loss*** tensor(2522.9268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2017.6410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85622
Old  loss*** tensor(2167.9678, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1856.2573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87269825
Old  loss*** tensor(1194.6069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1042.5314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85882694
Old  loss*** tensor(4066.6738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3492.5691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7672034
Old  loss*** tensor(5223.2861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4007.3228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88869715
Old  loss*** tensor(452.8795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.4727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85884535
Old  loss*** tensor(929.6719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(798.4444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641399
Old  loss*** tensor(2675.8245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2312.2866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8117884
Old  loss*** tensor(1116.4480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(906.3195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849386
Old  loss*** tensor(1314.3903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1163.1547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88071483
Old  loss*** tensor(751.2960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.6776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459308
Old  loss*** tensor(1986.9683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.8376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7950308
Old  loss*** tensor(3548.0479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2820.8071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8309492
Old  loss*** tensor(1900.1072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1578.8925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8998233
Old  loss*** tensor(190.2144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(171.1594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79198503
Old  loss*** tensor(4119.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3262.5635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880347
Old  loss*** tensor(1180.9846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.7554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8097285
Old  loss*** tensor(3796.8098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3074.3850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809029
Old  loss*** tensor(978.9011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(862.3168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823276
Old  loss*** tensor(1334.1162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1177.1276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8963191
Old  loss*** tensor(553.3394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(495.9687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823993
Old  loss*** tensor(1155.5210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.6309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460814
Old  loss*** tensor(4195.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3550.0398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818404
Old  loss*** tensor(1710.5881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1508.4657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862738
Old  loss*** tensor(1011.5781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.7269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710288
Old  loss*** tensor(1421.0304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1237.7584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698245
Old  loss*** tensor(1492.5948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.2957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8422654
Old  loss*** tensor(1682.9677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1417.5055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8058356
Old  loss*** tensor(3866.6912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3115.9175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.930835
Old  loss*** tensor(794.6229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.6628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82959694
Old  loss*** tensor(3183.2559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2640.8193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8550367
Old  loss*** tensor(924.2727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(790.2870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8567053
Old  loss*** tensor(2785.3989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2386.2661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8469918
Old  loss*** tensor(2513.7266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2129.1057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8705128
Old  loss*** tensor(153.7256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(133.8201, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87833965
Old  loss*** tensor(936.9405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.9520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8975079
Old  loss*** tensor(1310.7357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1176.3956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82638913
Old  loss*** tensor(2880.9580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2380.7925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82886326
Old  loss*** tensor(3072.0200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2546.2844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451796
Old  loss*** tensor(1822.9800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1540.7455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783994
Old  loss*** tensor(649.4387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(570.4666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454174
Old  loss*** tensor(2750.0283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2324.9216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8371781
Old  loss*** tensor(2801.5540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2345.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87605757
Old  loss*** tensor(456.0225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.5020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83682084
Old  loss*** tensor(3943.3958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3299.9158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7794267
Old  loss*** tensor(4715.4512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3675.3486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7966411
Old  loss*** tensor(4080.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3250.3669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.740522
Old  loss*** tensor(3403.1455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2520.1042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87307644
Old  loss*** tensor(783.7294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(684.2557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446748
Old  loss*** tensor(3228.6931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2727.1958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8633867
Old  loss*** tensor(1653.5366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1427.6415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90334046
Old  loss*** tensor(1143.3011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1032.7902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771603
Old  loss*** tensor(1500.0281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1315.7651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8718875
Old  loss*** tensor(1136.4779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(990.8809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660298
Old  loss*** tensor(3053.5840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2644.4946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83882725
Old  loss*** tensor(1994.4175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1672.9717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669457
Old  loss*** tensor(1605.6863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1392.0428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8955319
Old  loss*** tensor(803.4267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.4942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84058595
Old  loss*** tensor(2905.6619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2442.4585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82444257
Old  loss*** tensor(4049.5938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3338.6575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84697485
Old  loss*** tensor(1415.3557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1198.7708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9126668
Old  loss*** tensor(874.5045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(798.1312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8411893
Old  loss*** tensor(2410.8267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2027.9617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8313167
Old  loss*** tensor(3872.4143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3219.2026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.756784
Old  loss*** tensor(3297.4485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2495.4563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556132
Old  loss*** tensor(1326.8212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1135.2457, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8283279
Old  loss*** tensor(1672.7976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.6249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727451
Old  loss*** tensor(556.0019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(485.2479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8270519
Old  loss*** tensor(3317.0649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2743.3848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621867
Old  loss*** tensor(1733.3358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1494.4590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914423
Old  loss*** tensor(224.7128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.3185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8977702
Old  loss*** tensor(514.9058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.2671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8270572
Old  loss*** tensor(2891.4219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.3713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7524952
Old  loss*** tensor(4748.5024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3573.2253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7524111
Old  loss*** tensor(4849.1484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3648.5532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573612
Old  loss*** tensor(1103.8813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(946.4250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85809916
Old  loss*** tensor(776.7267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.5085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85514426
Old  loss*** tensor(2103.5081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1798.8029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85471857
Old  loss*** tensor(1912.7004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1634.8206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84816164
Old  loss*** tensor(3171.8613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2690.2512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873865
Old  loss*** tensor(2182.1228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.8807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717032
Old  loss*** tensor(1483.6057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1293.2639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75962126
Old  loss*** tensor(4804.4062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3649.5291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540085
Old  loss*** tensor(1715.7714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.2833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89956117
Old  loss*** tensor(251.5351, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(226.2712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86396587
Old  loss*** tensor(1144.4352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(988.7529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86101633
Old  loss*** tensor(1018.3024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(876.7750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8954021
Old  loss*** tensor(686.7390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(614.9075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82551146
Old  loss*** tensor(3730.4353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3079.5171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855683
Old  loss*** tensor(1234.4381, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.1793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86266273
Old  loss*** tensor(1908.6821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1646.5490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88636684
Old  loss*** tensor(1376.3402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.9424, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8486725
Old  loss*** tensor(2094.0879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1777.1948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78385645
Old  loss*** tensor(3409.1870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2672.3132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81089765
Old  loss*** tensor(3023.9502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2452.1140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8858667
Old  loss*** tensor(539.7268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.1260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88540584
Old  loss*** tensor(239.1639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(211.7571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83919483
Old  loss*** tensor(4430.1011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3717.7180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8962414
Old  loss*** tensor(2881.7559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2582.7490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877911
Old  loss*** tensor(1566.1591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.9482, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84011793
Old  loss*** tensor(2240.8115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1882.5459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8477117
Old  loss*** tensor(1439.9570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.6685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82945716
Old  loss*** tensor(2714.3462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2251.4338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8381307
Old  loss*** tensor(2765.4482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2317.8071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7683889
Old  loss*** tensor(4342.2266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3336.5188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928739
Old  loss*** tensor(503.6848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(449.7271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86198163
Old  loss*** tensor(1657.9768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.1455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8949102
Old  loss*** tensor(668.1556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(597.9393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8134705
Old  loss*** tensor(3153.1199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2564.9700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8566133
Old  loss*** tensor(2849.4338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2440.8628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869069
Old  loss*** tensor(536.8677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(466.5750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610158
Old  loss*** tensor(1334.8622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.3374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8060054
Old  loss*** tensor(2925.5889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2358.0405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7564671
Old  loss*** tensor(3511.7195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2656.5002, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711465
Old  loss*** tensor(1936.1821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1686.6982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85239965
Old  loss*** tensor(1918.3679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1635.2162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8948936
Old  loss*** tensor(555.2479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.8878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534773
Old  loss*** tensor(1382.2522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1179.7208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81635034
Old  loss*** tensor(3417.6282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2789.9819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061053
Old  loss*** tensor(3374.3386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2720.0723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89612454
Old  loss*** tensor(1173.5199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1051.6200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84814215
Old  loss*** tensor(1680.4193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.2345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7513861
Old  loss*** tensor(5285.9688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3971.8035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8870515
Old  loss*** tensor(885.3589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(785.3590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7826096
Old  loss*** tensor(4803.7480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3759.4592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875975
Old  loss*** tensor(950.2229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(843.4155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8274871
Old  loss*** tensor(1635.4392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1353.3048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85394776
Old  loss*** tensor(2518.5134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2150.6790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83370256
Old  loss*** tensor(3090.5039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2576.5610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8935331
Old  loss*** tensor(755.1165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.7216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8599388
Old  loss*** tensor(1304.8074, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1122.0544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7566716
Old  loss*** tensor(4227.7153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3198.9922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8946148
Old  loss*** tensor(1199.1407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1072.7690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81321096
Old  loss*** tensor(2743.0977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2230.7170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786247
Old  loss*** tensor(542.9308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(477.0324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8251991
Old  loss*** tensor(1978.2811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1632.4758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87451184
Old  loss*** tensor(2146.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1876.8984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8633975
Old  loss*** tensor(1121.4135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(968.2255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83157086
Old  loss*** tensor(3481.8364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2895.3938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8098867
Old  loss*** tensor(2384.8699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1931.4744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616929
Old  loss*** tensor(1447.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.6653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83562124
Old  loss*** tensor(4603.7114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3846.9590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78086674
Old  loss*** tensor(3675.5005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2870.0762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89793414
Old  loss*** tensor(990.0604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(889.0090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745126
Old  loss*** tensor(1402.5647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.5605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8526715
Old  loss*** tensor(1975.0619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1684.0790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8484926
Old  loss*** tensor(1632.4880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.1541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88806087
Old  loss*** tensor(199.0087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(176.7318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8445394
Old  loss*** tensor(2211.1030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1867.3636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8581606
Old  loss*** tensor(3077.5674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2641.0471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8591105
Old  loss*** tensor(1174.6385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.1443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888323
Old  loss*** tensor(1298.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1153.8021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8222277
Old  loss*** tensor(3632.4192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2986.6758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86014175
Old  loss*** tensor(2143.8855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1844.0454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8431766
Old  loss*** tensor(3860.2339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3254.8589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74288154
Old  loss*** tensor(1671.8198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1241.9641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86857104
Old  loss*** tensor(791.4937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(687.4685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660489
Old  loss*** tensor(1073.8977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(930.0479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88661766
Old  loss*** tensor(149.0707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(132.1687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826678
Old  loss*** tensor(706.0641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.2200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87275743
Old  loss*** tensor(1151.8654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.2991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778814
Old  loss*** tensor(723.5817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.2189, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830322
Old  loss*** tensor(560.7148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(495.1293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8305187
Old  loss*** tensor(4272.5811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3548.4585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86195236
Old  loss*** tensor(1800.0941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1551.5953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84736484
Old  loss*** tensor(2093.6748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1774.1064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760363
Old  loss*** tensor(781.1700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(684.3333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8470353
Old  loss*** tensor(1615.7047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1368.5590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713505
Old  loss*** tensor(1524.1906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.1042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7497041
Old  loss*** tensor(3659.0068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2743.1726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8554536
Old  loss*** tensor(2266.1116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1938.5533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8232857
Old  loss*** tensor(4654.2153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3831.7490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88538885
Old  loss*** tensor(443.4798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(392.6521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428135
Old  loss*** tensor(2184.5889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1841.2009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635383
Old  loss*** tensor(4007.1372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3460.3167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778342
Old  loss*** tensor(992.8820, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(871.5858, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698876
Old  loss*** tensor(2366.2188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.3442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80237633
Old  loss*** tensor(2862.5112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2296.8113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.775202
Old  loss*** tensor(4135.8267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3206.1011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84496033
Old  loss*** tensor(2932.6018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2477.9321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7877677
Old  loss*** tensor(4559.1934, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3591.5852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.825069
Old  loss*** tensor(3185.5154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2628.2700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624567
Old  loss*** tensor(995.4056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.4942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89068246
Old  loss*** tensor(1135.4390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1011.3156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87183255
Old  loss*** tensor(1223.5009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1066.6879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763242
Old  loss*** tensor(853.9727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(748.3569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86480343
Old  loss*** tensor(1131.9393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.9050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.823866
Old  loss*** tensor(2121.1794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1747.5676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78917885
Old  loss*** tensor(2445.1543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.6641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520983
Old  loss*** tensor(1595.5756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.5872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84301865
Old  loss*** tensor(1862.7927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1570.3690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895502
Old  loss*** tensor(463.9158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.6764, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90104043
Old  loss*** tensor(1362.9988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1228.1171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880719
Old  loss*** tensor(965.9780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.8579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809092
Old  loss*** tensor(1330.8755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1172.3805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742663
Old  loss*** tensor(2372.6721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2074.3474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083364
Old  loss*** tensor(2958.9326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.8130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739344
Old  loss*** tensor(1907.2128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1666.7788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8725998
Old  loss*** tensor(434.3614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.0237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86426336
Old  loss*** tensor(1154.6243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(997.8994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80218387
Old  loss*** tensor(2982.7529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2392.7163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762084
Old  loss*** tensor(1766.5916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1547.9023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742896
Old  loss*** tensor(658.9123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(576.0801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84655136
Old  loss*** tensor(2145.8630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1816.5833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8348811
Old  loss*** tensor(3327.4863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2778.0554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89761883
Old  loss*** tensor(1134.5115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1018.3589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8445334
Old  loss*** tensor(1289.7321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1089.2218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8396565
Old  loss*** tensor(3464.5952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2909.0698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660949
Old  loss*** tensor(1558.4009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1349.7230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77554154
Old  loss*** tensor(4320.1865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3350.4841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9081717
Old  loss*** tensor(1280.5413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1162.9513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88286173
Old  loss*** tensor(141.8460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(125.2304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570699
Old  loss*** tensor(3979.1714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3410.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8946345
Old  loss*** tensor(376.4476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(336.7830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81229895
Old  loss*** tensor(2289.2310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1859.5399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529613
Old  loss*** tensor(1822.6216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1554.6257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8321477
Old  loss*** tensor(2284.1187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1900.7241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89217234
Old  loss*** tensor(1165.2361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1039.5914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87974703
Old  loss*** tensor(1031.2579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(907.2461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8043573
Old  loss*** tensor(3532.2610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2841.2000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8723311
Old  loss*** tensor(978.3854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(853.4760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347217
Old  loss*** tensor(2672.4871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2230.7830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887323
Old  loss*** tensor(170.5628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(151.3443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86560166
Old  loss*** tensor(741.7094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.0248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.812973
Old  loss*** tensor(2350.2002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1910.6494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8474626
Old  loss*** tensor(3208.7883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2719.3281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7653808
Old  loss*** tensor(4740.5693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3628.3408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8192307
Old  loss*** tensor(2162.2151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1771.3529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83264035
Old  loss*** tensor(3509.7715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2922.3774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759737
Old  loss*** tensor(1759.1561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1540.9745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848027
Old  loss*** tensor(697.3779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(617.0419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87265694
Old  loss*** tensor(1432.4966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1250.0781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826448
Old  loss*** tensor(565.2077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(498.8776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87972534
Old  loss*** tensor(1258.2533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1106.9174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704765
Old  loss*** tensor(1104.9724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.8525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8985849
Old  loss*** tensor(583.2049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(524.0591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81199855
Old  loss*** tensor(2725.2461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2212.8958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8688499
Old  loss*** tensor(980.0842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(851.5461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81871414
Old  loss*** tensor(3704.5789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3032.9912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87888014
Old  loss*** tensor(1665.3953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1463.6829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8279804
Old  loss*** tensor(3923.7825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3248.8149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86236537
Old  loss*** tensor(1795.2877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.1940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708874
Old  loss*** tensor(790.6818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(688.5948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78441817
Old  loss*** tensor(4525.1069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3549.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7376884
Old  loss*** tensor(3553.3943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2621.2979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.803346
Old  loss*** tensor(2956.5837, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.1597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885199
Old  loss*** tensor(1892.6165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1675.3422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8394338
Old  loss*** tensor(1747.2640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.7125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492907
Old  loss*** tensor(2150.3242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1826.2504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178516
Old  loss*** tensor(2846.6226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2328.1147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78896165
Old  loss*** tensor(3381.6172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2667.9663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75149965
Old  loss*** tensor(4065.7554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3055.4138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84065044
Old  loss*** tensor(4513.4585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3794.2410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9148191
Old  loss*** tensor(712.2046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(651.5384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90048945
Old  loss*** tensor(1053.2452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(948.4362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680192
Old  loss*** tensor(2985.3752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2591.3630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87271845
Old  loss*** tensor(1779.9587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1553.4028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8834719
Old  loss*** tensor(1012.9751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(894.9351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775685
Old  loss*** tensor(1282.8832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1125.8179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8197407
Old  loss*** tensor(3199.5046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2622.7642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84307456
Old  loss*** tensor(3483.6924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2937.0125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895016
Old  loss*** tensor(193.8591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(172.4380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83980286
Old  loss*** tensor(4949.7168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4156.7861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8039583
Old  loss*** tensor(2356.2556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1894.3313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7498647
Old  loss*** tensor(4881.1064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3660.1694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88169837
Old  loss*** tensor(501.8086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(442.4438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8976636
Old  loss*** tensor(472.1050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(423.7915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90450215
Old  loss*** tensor(726.5109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.1307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80451375
Old  loss*** tensor(2803.9722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.8342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636781
Old  loss*** tensor(1677.8806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.1487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79260945
Old  loss*** tensor(3583.0283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2839.9421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928882
Old  loss*** tensor(1530.5671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1366.6254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8797947
Old  loss*** tensor(3854.6287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3391.2820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84070826
Old  loss*** tensor(2361.9937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1985.7476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87631595
Old  loss*** tensor(816.2545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(715.2968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779998
Old  loss*** tensor(1111.1879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.6227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8036007
Old  loss*** tensor(2516.8142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2022.5137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87236685
Old  loss*** tensor(2065.7649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1802.1049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85101163
Old  loss*** tensor(2950.6746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2511.0583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847036
Old  loss*** tensor(4252.6758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3602.1694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798846
Old  loss*** tensor(515.5101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(453.5894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74394304
Old  loss*** tensor(4845.9360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3605.1003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442664
Old  loss*** tensor(4211.0527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3555.2505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359332
Old  loss*** tensor(2142.6309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1791.0963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671847
Old  loss*** tensor(2009.7935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1742.8622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850482
Old  loss*** tensor(1186.4534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.0685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86815286
Old  loss*** tensor(1232.3562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1069.8735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8842534
Old  loss*** tensor(1043.5422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(922.7557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7691375
Old  loss*** tensor(3867.3357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2974.5129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500161
Old  loss*** tensor(2166.3994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1841.4744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85411835
Old  loss*** tensor(1277.5013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.1373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819113
Old  loss*** tensor(1224.0354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.4906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8640709
Old  loss*** tensor(553.9874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.6844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9042996
Old  loss*** tensor(932.0623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(842.8635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.867247
Old  loss*** tensor(242.3279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(210.1582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858516
Old  loss*** tensor(1235.9121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.0503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87466717
Old  loss*** tensor(537.5082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(470.1408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8471599
Old  loss*** tensor(3050.6406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2584.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534007
Old  loss*** tensor(2243.6042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1914.6935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.762465
Old  loss*** tensor(4621.9336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3524.0625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634206
Old  loss*** tensor(1888.5253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1630.5917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81146485
Old  loss*** tensor(4405.9805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3575.2983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78924435
Old  loss*** tensor(3307.8357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2610.6907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76992923
Old  loss*** tensor(3000.0923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2309.8586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549777
Old  loss*** tensor(1449.5895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1239.3667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438508
Old  loss*** tensor(1334.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1125.8597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8723531
Old  loss*** tensor(1741.9430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1519.5894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80352867
Old  loss*** tensor(3765.2371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3025.4758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86996794
Old  loss*** tensor(3552.7700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3090.7959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7322149
Old  loss*** tensor(4201.9478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3076.7288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7762932
Old  loss*** tensor(3166.7273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2458.3088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7647739
Old  loss*** tensor(4110.9907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3143.9785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.786511
Old  loss*** tensor(4407.6924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3466.6985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8574673
Old  loss*** tensor(1335.8928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1145.4844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79830843
Old  loss*** tensor(4741.0923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3784.8540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83422893
Old  loss*** tensor(2385.4019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1989.9712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8565917
Old  loss*** tensor(1821.1699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1559.9990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8870851
Old  loss*** tensor(741.5712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.8368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859855
Old  loss*** tensor(1479.8492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1311.1250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88986546
Old  loss*** tensor(1030.9371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(917.3953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792908
Old  loss*** tensor(1782.3563, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1567.2096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85205865
Old  loss*** tensor(2147.8882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1830.1267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869108
Old  loss*** tensor(868.7834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(755.0666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8386084
Old  loss*** tensor(2653.4170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2225.1777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8844903
Old  loss*** tensor(749.6982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(663.1008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8301071
Old  loss*** tensor(2909.3452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2415.0681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8047625
Old  loss*** tensor(3591.6875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2890.4553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83729315
Old  loss*** tensor(2514.3618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2105.2578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8292027
Old  loss*** tensor(2274.8088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.2777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87063944
Old  loss*** tensor(1753.2737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1526.4692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8302442
Old  loss*** tensor(2193.8169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1821.4037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8180863
Old  loss*** tensor(3981.2383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3256.9966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89084846
Old  loss*** tensor(829.7228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.1573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495627
Old  loss*** tensor(2390.8870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2031.2084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8553741
Old  loss*** tensor(1162.7638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(994.5980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89486855
Old  loss*** tensor(1586.0059, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1419.2667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85857403
Old  loss*** tensor(1393.2869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1196.2399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7889303
Old  loss*** tensor(4425.3237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3491.2720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8761704
Old  loss*** tensor(461.5710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.4148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84988123
Old  loss*** tensor(3178.2759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2701.1570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539293
Old  loss*** tensor(1387.5630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1184.8806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90422463
Old  loss*** tensor(898.7613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.6821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7569477
Old  loss*** tensor(4327.1118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3275.3972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87910104
Old  loss*** tensor(444.9637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(391.1680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86882246
Old  loss*** tensor(1091.6735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(948.4704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83468425
Old  loss*** tensor(2545.1221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2124.3733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9009224
Old  loss*** tensor(709.7812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.4578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650653
Old  loss*** tensor(1474.1862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1275.2672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8842907
Old  loss*** tensor(696.0458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(615.5068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91490555
Old  loss*** tensor(1340.5410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.4684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8868019
Old  loss*** tensor(980.4608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.4745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85568607
Old  loss*** tensor(2635.4214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.0933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81454194
Old  loss*** tensor(3595.4473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2928.6426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86273587
Old  loss*** tensor(634.6548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(547.5395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438879
Old  loss*** tensor(1925.4170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1624.8362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86005306
Old  loss*** tensor(560.9684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(482.4626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8844304
Old  loss*** tensor(1432.6097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.0436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634582
Old  loss*** tensor(1036.5417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.0105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8273294
Old  loss*** tensor(947.6851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(784.0477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8201532
Old  loss*** tensor(1755.8911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1440.0997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8082514
Old  loss*** tensor(2811.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2271.9971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89988035
Old  loss*** tensor(1596.7465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.8807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85034275
Old  loss*** tensor(3345.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2844.9646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8030123
Old  loss*** tensor(3193.3650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2564.3115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634728
Old  loss*** tensor(1516.6431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1309.5801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454499
Old  loss*** tensor(3247.9080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2745.9436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900311
Old  loss*** tensor(906.1950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(806.5417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8817038
Old  loss*** tensor(589.8479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.0711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.6968293
Old  loss*** tensor(4672.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3255.9949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115418
Old  loss*** tensor(2528.3872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2051.8918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7863783
Old  loss*** tensor(3151.8999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572266
Old  loss*** tensor(870.0908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.8649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9032905
Old  loss*** tensor(326.8889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(295.2756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85938567
Old  loss*** tensor(3930.3254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3377.6653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84395057
Old  loss*** tensor(1543.1823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1302.3695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790865
Old  loss*** tensor(968.8900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(851.7381, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82877755
Old  loss*** tensor(2688.9707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2228.5586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830135
Old  loss*** tensor(122.2722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(107.9680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84966433
Old  loss*** tensor(1470.1757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.1558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8365935
Old  loss*** tensor(2944.1040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2463.0183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85933745
Old  loss*** tensor(2011.6647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1728.6987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697895
Old  loss*** tensor(852.8774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(741.8239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7370773
Old  loss*** tensor(3362.2070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.2065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83449376
Old  loss*** tensor(3649.7061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3045.6570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82900465
Old  loss*** tensor(2206.9373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1829.5613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86022234
Old  loss*** tensor(4111.7617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3537.0293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347583
Old  loss*** tensor(4104.3042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3426.1018, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762243
Old  loss*** tensor(1109.6245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.2800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659201
Old  loss*** tensor(1628.2520, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1409.9362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922417
Old  loss*** tensor(476.8208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(425.4394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415028
Old  loss*** tensor(1586.9597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.4310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8668071
Old  loss*** tensor(2488.2458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2156.8291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7993068
Old  loss*** tensor(2682.4163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2144.0735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8605417
Old  loss*** tensor(2114.8762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1819.9392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7596724
Old  loss*** tensor(5043.4956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3831.4045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87848544
Old  loss*** tensor(629.7342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(553.2123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8458101
Old  loss*** tensor(1030.1967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(871.3508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7723307
Old  loss*** tensor(4573.2637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3532.0720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84435
Old  loss*** tensor(1246.9346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1052.8491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84326947
Old  loss*** tensor(2654.2485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2238.2468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7864901
Old  loss*** tensor(3833.9329, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3015.3501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81334615
Old  loss*** tensor(3566.8606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2901.0923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87187696
Old  loss*** tensor(1668.1113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1454.3878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807919
Old  loss*** tensor(164.4730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(144.8665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862843
Old  loss*** tensor(1407.7032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.6268, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756379
Old  loss*** tensor(1077.0154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(943.0755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81882524
Old  loss*** tensor(3308.8501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2709.3699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8305435
Old  loss*** tensor(1512.1813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.9324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8230893
Old  loss*** tensor(3506.0181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2885.7659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7442477
Old  loss*** tensor(4420.6138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3290.0315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84789526
Old  loss*** tensor(2798.8860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2373.1621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8657819
Old  loss*** tensor(1429.5193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1237.6520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8551234
Old  loss*** tensor(2538.8096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2170.9954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88309646
Old  loss*** tensor(1222.3488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.4519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86469054
Old  loss*** tensor(624.0742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(539.6310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84272295
Old  loss*** tensor(3419.5010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2881.6919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8957499
Old  loss*** tensor(273.5327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(245.0169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719675
Old  loss*** tensor(1175.5125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.0087, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399256
Old  loss*** tensor(2068.3606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1737.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7580956
Old  loss*** tensor(4266.4219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3234.3557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80384386
Old  loss*** tensor(2149.1926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.6152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87908304
Old  loss*** tensor(4247.7197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3734.0984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8079458
Old  loss*** tensor(2722.4468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2199.5894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9046986
Old  loss*** tensor(1111.6726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.7286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773793
Old  loss*** tensor(1338.7314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1174.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8497441
Old  loss*** tensor(2541.7629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2159.8479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87301785
Old  loss*** tensor(748.3583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(653.3302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83180296
Old  loss*** tensor(1948.5555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1620.8143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675708
Old  loss*** tensor(1545.7686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1341.0637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814452
Old  loss*** tensor(1762.6476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1553.6772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8441724
Old  loss*** tensor(1810.1742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.0991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7757813
Old  loss*** tensor(3225.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2502.1138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85689807
Old  loss*** tensor(1550.4579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.5844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7973119
Old  loss*** tensor(3583.8159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.4192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8522918
Old  loss*** tensor(2247.4373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1915.4724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8173304
Old  loss*** tensor(4058.1394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3316.8408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415505
Old  loss*** tensor(3207.6069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2699.3633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87396127
Old  loss*** tensor(1157.6844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1011.7714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790631
Old  loss*** tensor(279.4590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(245.6621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8409363
Old  loss*** tensor(1804.3561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1517.3485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8581703
Old  loss*** tensor(2958.9175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2539.2551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80738306
Old  loss*** tensor(2951.1497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2382.7083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84691656
Old  loss*** tensor(1655.7487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1402.2810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8913044
Old  loss*** tensor(763.4289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.4475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7672293
Old  loss*** tensor(4341.1841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3330.6836, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7446307
Old  loss*** tensor(2236.1670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1665.1185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809313
Old  loss*** tensor(965.6915, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.7079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80908024
Old  loss*** tensor(2140.4456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1731.7922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827039
Old  loss*** tensor(857.5963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(757.0036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83097535
Old  loss*** tensor(2348.0852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1951.2009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84263945
Old  loss*** tensor(2259.8455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.2350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86304414
Old  loss*** tensor(2825.6179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2438.6331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7899685
Old  loss*** tensor(4173.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3297.0662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87965333
Old  loss*** tensor(888.6538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.7073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87067676
Old  loss*** tensor(1193.8785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1039.4823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85947794
Old  loss*** tensor(1422.1060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1222.2687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8435447
Old  loss*** tensor(3206.6543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2704.9563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428004
Old  loss*** tensor(2955.3145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2490.7402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8904025
Old  loss*** tensor(492.0694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(438.1398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727673
Old  loss*** tensor(781.5573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(682.1176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86262184
Old  loss*** tensor(2158.8267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1862.2510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840816
Old  loss*** tensor(3703.6860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3274.3606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7515994
Old  loss*** tensor(4048.4492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3042.8118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83895844
Old  loss*** tensor(2115.7117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1774.9941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81325316
Old  loss*** tensor(2130.0286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1732.2524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8393097
Old  loss*** tensor(1855.4884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1557.3293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815315
Old  loss*** tensor(974.9901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(859.4845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8511224
Old  loss*** tensor(2329.6660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.8309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690835
Old  loss*** tensor(529.7600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(460.4057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8993393
Old  loss*** tensor(910.4457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.7996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8037605
Old  loss*** tensor(3275.7791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2632.9419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7863103
Old  loss*** tensor(2509.2542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1973.0524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631632
Old  loss*** tensor(1452.9917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1254.1689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9103602
Old  loss*** tensor(1171.0737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1066.0989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808887
Old  loss*** tensor(1201.9550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1058.7886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9043975
Old  loss*** tensor(572.3631, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(517.6437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8589361
Old  loss*** tensor(1047.7111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.9168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8892067
Old  loss*** tensor(172.8007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(153.6556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796783
Old  loss*** tensor(718.6717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.1999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89711237
Old  loss*** tensor(506.6532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(454.5249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87921214
Old  loss*** tensor(373.9096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(328.7459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81322134
Old  loss*** tensor(5049.3975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4106.2778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887679
Old  loss*** tensor(823.4776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(730.9838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88020486
Old  loss*** tensor(884.9011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(778.8943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87834334
Old  loss*** tensor(1829.3260, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1606.7764, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8676232
Old  loss*** tensor(2630.2637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2282.0779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7410581
Old  loss*** tensor(5139.6597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3808.7864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79742944
Old  loss*** tensor(3544.3838, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2826.3960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.896345
Old  loss*** tensor(191.8976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(172.0064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88142335
Old  loss*** tensor(970.3282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.2699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8420781
Old  loss*** tensor(2076.4749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1748.5540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839214
Old  loss*** tensor(892.5526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(788.9464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85871136
Old  loss*** tensor(1386.0225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.1932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8400681
Old  loss*** tensor(2450.1003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.2512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90840507
Old  loss*** tensor(724.7214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.3406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8910854
Old  loss*** tensor(755.4023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(673.1280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84865713
Old  loss*** tensor(2520.6504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.1680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89127016
Old  loss*** tensor(693.2614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(617.8832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84006417
Old  loss*** tensor(3270.1438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2747.1306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824877
Old  loss*** tensor(1109.1716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.8303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523538
Old  loss*** tensor(2443.4197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2082.6580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78713816
Old  loss*** tensor(3774.7041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2971.2136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.799791
Old  loss*** tensor(2695.7644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2156.0481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.871497
Old  loss*** tensor(1530.0500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.4340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89597774
Old  loss*** tensor(1117.2937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.0703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877363
Old  loss*** tensor(154.7330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(135.7570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89206105
Old  loss*** tensor(1355.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.9139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85785604
Old  loss*** tensor(2008.2720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1722.8082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8607383
Old  loss*** tensor(3912.4185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3367.5684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585892
Old  loss*** tensor(2249.6760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1931.5475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752423
Old  loss*** tensor(1167.7928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.1017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82918346
Old  loss*** tensor(2702.9695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2241.2576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8461431
Old  loss*** tensor(991.7781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.1863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90844786
Old  loss*** tensor(954.9169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(867.4922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86314523
Old  loss*** tensor(1579.4205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1363.2693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86312866
Old  loss*** tensor(3014.0857, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2601.5437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314718
Old  loss*** tensor(3803.0093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3162.0950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8994491
Old  loss*** tensor(377.1470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(339.2245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8882608
Old  loss*** tensor(538.4910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.3205, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8106077
Old  loss*** tensor(2792.7507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2263.8252, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8854492
Old  loss*** tensor(757.4075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(670.6459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8920075
Old  loss*** tensor(1231.4595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.4711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87180185
Old  loss*** tensor(1421.0504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.8744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8411452
Old  loss*** tensor(1676.3969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.0931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80191576
Old  loss*** tensor(4078.2759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3270.4338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646176
Old  loss*** tensor(1035.7214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.5030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85245323
Old  loss*** tensor(2857.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2435.4614, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88789946
Old  loss*** tensor(741.4199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.3063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87538344
Old  loss*** tensor(1113.9763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.1564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87088287
Old  loss*** tensor(451.6829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(393.3629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8243101
Old  loss*** tensor(4763.0239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3926.2087, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390429
Old  loss*** tensor(2573.0100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2158.8657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80704963
Old  loss*** tensor(3124.7026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2521.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86830646
Old  loss*** tensor(4241.7568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3683.1448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8466089
Old  loss*** tensor(1788.9313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1514.5251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89714026
Old  loss*** tensor(687.7225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(616.9835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855104
Old  loss*** tensor(263.9623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(233.7414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428624
Old  loss*** tensor(1461.1272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.5292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7599567
Old  loss*** tensor(4598.4370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3494.6130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675512
Old  loss*** tensor(1449.9517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1257.9073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7904156
Old  loss*** tensor(4832.3584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3819.5713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852109
Old  loss*** tensor(2062.4985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1757.4736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.831076
Old  loss*** tensor(3736.3594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3105.1987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281955
Old  loss*** tensor(2125.0525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.9590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8324988
Old  loss*** tensor(4866.3262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4051.2107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83133
Old  loss*** tensor(1909.8551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.7198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586607
Old  loss*** tensor(1794.4384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1540.8137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696955
Old  loss*** tensor(1256.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1092.4819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81750286
Old  loss*** tensor(3658.7983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2991.0781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8405389
Old  loss*** tensor(2332.3528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1960.4332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613869
Old  loss*** tensor(2094.2922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1803.9958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738537
Old  loss*** tensor(1110.7487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(970.6318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7898159
Old  loss*** tensor(3526.2632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2785.0986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7721505
Old  loss*** tensor(3803.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2936.6951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8872335
Old  loss*** tensor(460.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.8543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671021
Old  loss*** tensor(2350.7056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.3018, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8408303
Old  loss*** tensor(1552.3019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1305.2225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86228216
Old  loss*** tensor(1690.6566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1457.8230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90057975
Old  loss*** tensor(691.4522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(622.7079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852403
Old  loss*** tensor(599.3696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(530.5862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7224239
Old  loss*** tensor(4493.4385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3246.1675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8345218
Old  loss*** tensor(2865.8823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.6411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82214195
Old  loss*** tensor(156.6961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(128.8264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84443784
Old  loss*** tensor(2169.0120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1831.5958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849502
Old  loss*** tensor(932.6866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(825.3812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.798786
Old  loss*** tensor(3330.8828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2660.6626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86806846
Old  loss*** tensor(1322.8367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1148.3127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8369752
Old  loss*** tensor(2490.6460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2084.6089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716886
Old  loss*** tensor(1199.5603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1045.6431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7932401
Old  loss*** tensor(2940.7012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2332.6819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84591436
Old  loss*** tensor(3105.4873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2626.9763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88758254
Old  loss*** tensor(4111.7671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3649.5327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8530966
Old  loss*** tensor(1540.4954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1314.1914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88394296
Old  loss*** tensor(708.5468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(626.3149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85169387
Old  loss*** tensor(2727.1509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2322.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784234
Old  loss*** tensor(976.2568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.5668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87489396
Old  loss*** tensor(635.6221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(556.1019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85476154
Old  loss*** tensor(1838.8079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1571.7422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080945
Old  loss*** tensor(3926.7336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3173.1719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81148994
Old  loss*** tensor(1477.3303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1198.8387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82598794
Old  loss*** tensor(1839.9913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1519.8107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80802035
Old  loss*** tensor(2526.1819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2041.2064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83023727
Old  loss*** tensor(3060.7549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2541.1528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85567737
Old  loss*** tensor(1652.1484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1413.7061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85006964
Old  loss*** tensor(1822.2614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1549.0491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86940086
Old  loss*** tensor(1002.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(871.2174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86565936
Old  loss*** tensor(1781.0591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1541.7904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741193
Old  loss*** tensor(1507.2069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.4786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8514333
Old  loss*** tensor(3255.8296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2772.1216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8270586
Old  loss*** tensor(2087.6074, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1726.5737, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7693485
Old  loss*** tensor(2927.4202, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2252.2063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387158
Old  loss*** tensor(1647.0818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1381.4335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82371426
Old  loss*** tensor(2686.3994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2212.8254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79718804
Old  loss*** tensor(4313.5864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3438.7395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88480514
Old  loss*** tensor(1156.1277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.9477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86936533
Old  loss*** tensor(653.4297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(568.0691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800078
Old  loss*** tensor(1022.7023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.9860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8561219
Old  loss*** tensor(1514.2362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1296.3707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8448051
Old  loss*** tensor(1837.1288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1552.0157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84583986
Old  loss*** tensor(3135.0522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2651.7522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7950196
Old  loss*** tensor(3456.1226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2747.6853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85399693
Old  loss*** tensor(1227.7985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.5361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86422765
Old  loss*** tensor(1224.4349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1058.1906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685932
Old  loss*** tensor(824.1781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(715.8755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8113645
Old  loss*** tensor(2292.4014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1859.9730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547993
Old  loss*** tensor(1923.4309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1644.1473, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729403
Old  loss*** tensor(2871.1226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2506.3186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8235179
Old  loss*** tensor(2620.6355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2158.1404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8845358
Old  loss*** tensor(457.6352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.7947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89034194
Old  loss*** tensor(510.5062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(454.5251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.781598
Old  loss*** tensor(3194.6790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2496.9546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76240563
Old  loss*** tensor(3343.5308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2549.1267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82242334
Old  loss*** tensor(3926.7014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3229.4109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8357922
Old  loss*** tensor(3838.9775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3208.5874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87351537
Old  loss*** tensor(2030.5638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1773.7288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8149322
Old  loss*** tensor(2516.9478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2051.1418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.69903386
Old  loss*** tensor(4088.0776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.7046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298012
Old  loss*** tensor(4017.5691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3333.7837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8449662
Old  loss*** tensor(3414.3896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2885.0437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87963104
Old  loss*** tensor(811.1508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(713.5134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88831973
Old  loss*** tensor(891.9128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.3037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9006154
Old  loss*** tensor(518.1152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(466.6226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87704325
Old  loss*** tensor(1633.8811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1432.9844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89622504
Old  loss*** tensor(793.9716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(711.5772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86351585
Old  loss*** tensor(1663.0966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.1102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7764032
Old  loss*** tensor(3406.5706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2644.8723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8472532
Old  loss*** tensor(2091.6494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1772.1566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741204
Old  loss*** tensor(1525.4720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.4463, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8331559
Old  loss*** tensor(3098.9790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2581.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86084324
Old  loss*** tensor(1270.4369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.6470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8039938
Old  loss*** tensor(4310.6050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3465.6997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8423629
Old  loss*** tensor(2063.4319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1738.1584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7946719
Old  loss*** tensor(3025.5369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.3091, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337426
Old  loss*** tensor(1254.8348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1046.2092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7869923
Old  loss*** tensor(3173.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2497.3611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83049506
Old  loss*** tensor(2358.8547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1959.0172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8287052
Old  loss*** tensor(1909.4237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1582.3494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88321996
Old  loss*** tensor(935.9294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.6316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7682694
Old  loss*** tensor(3606.2937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2770.6052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76979566
Old  loss*** tensor(4846.0503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3730.4685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88356173
Old  loss*** tensor(96.8842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(85.6032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776119
Old  loss*** tensor(157.9396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(138.6097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8950399
Old  loss*** tensor(406.3819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(363.7281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9126119
Old  loss*** tensor(1057.7645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(965.3285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85486484
Old  loss*** tensor(1869.8174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.4412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88139254
Old  loss*** tensor(564.0905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(497.1852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88827175
Old  loss*** tensor(1272.4211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1130.2557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8000896
Old  loss*** tensor(3586.1743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2869.2607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824445
Old  loss*** tensor(886.6371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(782.4081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780229
Old  loss*** tensor(186.3015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(163.5770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926703
Old  loss*** tensor(409.5892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(365.6281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8133981
Old  loss*** tensor(2602.5918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.9434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929812
Old  loss*** tensor(1596.0316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.2262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86820996
Old  loss*** tensor(2222.3081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.4301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84239465
Old  loss*** tensor(1825.9866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1538.2013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9007976
Old  loss*** tensor(885.6617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.8019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8599025
Old  loss*** tensor(1459.5300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.0535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8125695
Old  loss*** tensor(2688.3723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2184.4893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8320359
Old  loss*** tensor(2212.6360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1840.9926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75191903
Old  loss*** tensor(3813.4607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2867.4136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790424
Old  loss*** tensor(2751.5188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2418.7017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907604
Old  loss*** tensor(879.6614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(783.5676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84640074
Old  loss*** tensor(1288.0786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1090.2307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84834266
Old  loss*** tensor(3717.7502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.9260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86025566
Old  loss*** tensor(1953.4413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.4589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8374391
Old  loss*** tensor(1641.1870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.3942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7552777
Old  loss*** tensor(3882.5498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2932.4033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84648687
Old  loss*** tensor(1277.0643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1081.0182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74701893
Old  loss*** tensor(4559.9458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3406.3660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79206663
Old  loss*** tensor(3422.8164, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2711.0986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7796178
Old  loss*** tensor(2577.7002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2009.6210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77288735
Old  loss*** tensor(4680.2949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3617.3408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903943
Old  loss*** tensor(1710.1854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.7393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890496
Old  loss*** tensor(454.7356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.2825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87871003
Old  loss*** tensor(742.8185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.7221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839874
Old  loss*** tensor(3998.3352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3358.0979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780403
Old  loss*** tensor(1091.7844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(958.6307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559545
Old  loss*** tensor(2751.4585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2355.1233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8626465
Old  loss*** tensor(3928.4150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3388.8335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615612
Old  loss*** tensor(922.0848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(794.4324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88516384
Old  loss*** tensor(1076.8979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(953.2311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244779
Old  loss*** tensor(2234.4141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1842.2251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86215574
Old  loss*** tensor(1355.4332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1168.5945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594185
Old  loss*** tensor(600.0407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(515.6861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820058
Old  loss*** tensor(750.2056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.6857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8718027
Old  loss*** tensor(1212.0989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.7111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82578146
Old  loss*** tensor(2838.3259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2343.8369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452134
Old  loss*** tensor(1553.2469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1312.8252, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8381889
Old  loss*** tensor(3616.2864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3031.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076774
Old  loss*** tensor(2585.0232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2087.8647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786599
Old  loss*** tensor(271.3636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(238.4363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874601
Old  loss*** tensor(787.8730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.0746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8377489
Old  loss*** tensor(2296.5962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1923.9709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446736
Old  loss*** tensor(1625.1951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1372.7593, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7956691
Old  loss*** tensor(2918.5339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2322.1873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7997524
Old  loss*** tensor(4546.3882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3635.9849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8427768
Old  loss*** tensor(2677.2654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2256.3372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8835903
Old  loss*** tensor(459.7953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(406.2707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8436237
Old  loss*** tensor(1583.3365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.7402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8173141
Old  loss*** tensor(4191.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3425.6877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89674664
Old  loss*** tensor(1375.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.8774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82328117
Old  loss*** tensor(3392.2849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2792.8042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87079495
Old  loss*** tensor(595.7206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.7505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8356118
Old  loss*** tensor(2484.7949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2076.3240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8215624
Old  loss*** tensor(1902.9362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.3809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8368622
Old  loss*** tensor(3011.4128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2520.1377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84259236
Old  loss*** tensor(1371.8390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1155.9010, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84576106
Old  loss*** tensor(2071.3562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1751.8724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852514
Old  loss*** tensor(1226.5464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.8019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88369954
Old  loss*** tensor(1260.6267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1114.0153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84973115
Old  loss*** tensor(1861.4412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.7245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88842267
Old  loss*** tensor(1251.1372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.5387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865808
Old  loss*** tensor(1150.9761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.4333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90076196
Old  loss*** tensor(2012.5287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1812.8093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87379867
Old  loss*** tensor(582.3849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(508.8872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785587
Old  loss*** tensor(2132.5544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1873.5742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89316744
Old  loss*** tensor(656.3520, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.2322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86409825
Old  loss*** tensor(1137.2695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(982.7126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8551047
Old  loss*** tensor(3943.0476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3371.7185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83969355
Old  loss*** tensor(2269.4924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1905.6781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717262
Old  loss*** tensor(1427.6041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1244.4800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8580052
Old  loss*** tensor(1162.0173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(997.0170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9042332
Old  loss*** tensor(906.8096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(819.9674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7680522
Old  loss*** tensor(4060.8528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.9470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178022
Old  loss*** tensor(3298.5281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2697.5435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83794135
Old  loss*** tensor(2026.4343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1698.0331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8008914
Old  loss*** tensor(4654.0752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3727.4087, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8918675
Old  loss*** tensor(211.3783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(188.5214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813442
Old  loss*** tensor(457.4781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(403.1956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84260035
Old  loss*** tensor(3217.0781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2710.7112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907105
Old  loss*** tensor(453.5786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.0073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.883016
Old  loss*** tensor(890.6048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.4183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89967537
Old  loss*** tensor(787.7745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.7413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717072
Old  loss*** tensor(1065.8137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.0775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78930396
Old  loss*** tensor(2990.2009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2360.1775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8595191
Old  loss*** tensor(1596.0640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1371.8475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80774057
Old  loss*** tensor(4740.1597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3828.8193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8643042
Old  loss*** tensor(1138.0696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(983.6383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863866
Old  loss*** tensor(3351.6179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2895.3486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641662
Old  loss*** tensor(2127.0950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1838.1636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756105
Old  loss*** tensor(800.4361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(700.8702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314753
Old  loss*** tensor(2122.8401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1765.0891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903284
Old  loss*** tensor(601.1684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(535.2373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816633
Old  loss*** tensor(811.4928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(715.4634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8319428
Old  loss*** tensor(2351.8569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1956.6105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7566535
Old  loss*** tensor(4171.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3156.1235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82960796
Old  loss*** tensor(809.3009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(671.4025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873634
Old  loss*** tensor(1762.3326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1539.6337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8688985
Old  loss*** tensor(1520.4054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1321.0780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78971934
Old  loss*** tensor(3050.3440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2408.9158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8338224
Old  loss*** tensor(1295.7720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.4437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855575
Old  loss*** tensor(1363.1086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.1111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8782823
Old  loss*** tensor(151.4303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(132.9985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71816623
Old  loss*** tensor(4468.5308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3209.1479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85539633
Old  loss*** tensor(1835.4442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1570.0322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78068566
Old  loss*** tensor(3785.2935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2955.1243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7914599
Old  loss*** tensor(3279.7175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2595.7649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756998
Old  loss*** tensor(1433.4847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.3024, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8363522
Old  loss*** tensor(2151.2905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1799.2366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8156197
Old  loss*** tensor(2871.2405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2341.8403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86360174
Old  loss*** tensor(983.6495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.4814, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81085145
Old  loss*** tensor(3808.4807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3088.1121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7630938
Old  loss*** tensor(3305.5281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2522.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8404919
Old  loss*** tensor(2207.2451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1855.1716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764522
Old  loss*** tensor(2933.9717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2571.4858, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7165984
Old  loss*** tensor(5101.7656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3655.9170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79208773
Old  loss*** tensor(3594.8320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2847.4224, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8416244
Old  loss*** tensor(1456.3621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1225.7098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87545514
Old  loss*** tensor(1427.5931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.7937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89566785
Old  loss*** tensor(314.3760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(281.5765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8074361
Old  loss*** tensor(3618.5745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2921.7676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84156406
Old  loss*** tensor(1800.2982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.0663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847242
Old  loss*** tensor(983.9719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.5437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87923825
Old  loss*** tensor(685.1084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.3735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78506434
Old  loss*** tensor(5028.7778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3947.9141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617441
Old  loss*** tensor(1186.6968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.6290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886325
Old  loss*** tensor(676.1266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(599.2679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8409991
Old  loss*** tensor(3730.2996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3137.1787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7671603
Old  loss*** tensor(4518.4263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3466.3572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8521343
Old  loss*** tensor(1095.9635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(933.9081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8241565
Old  loss*** tensor(2345.5427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1933.0944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8379928
Old  loss*** tensor(2456.4517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.4888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89768004
Old  loss*** tensor(890.3849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.2808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8056747
Old  loss*** tensor(4026.0496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3243.6863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79141796
Old  loss*** tensor(3822.3965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3025.1133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82083964
Old  loss*** tensor(1878.2528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1541.7444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808577
Old  loss*** tensor(817.8751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(720.4316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9101603
Old  loss*** tensor(894.0455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(813.7247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86278164
Old  loss*** tensor(1799.6622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1552.7156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7434349
Old  loss*** tensor(3296.5474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2450.7683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8120962
Old  loss*** tensor(2381.2310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1933.7886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88189447
Old  loss*** tensor(1549.5604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1366.5488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86066115
Old  loss*** tensor(1005.3411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(865.2581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84643817
Old  loss*** tensor(2032.1090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.0547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91231525
Old  loss*** tensor(597.7849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(545.3683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81998616
Old  loss*** tensor(2063.0420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.6659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88245237
Old  loss*** tensor(887.4368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(783.1207, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769934
Old  loss*** tensor(465.7865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.4917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8088216
Old  loss*** tensor(1603.4696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1296.9209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76681685
Old  loss*** tensor(4193.4580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3215.6143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84830666
Old  loss*** tensor(1679.6421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1424.8516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8983418
Old  loss*** tensor(477.7021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(429.1397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410102
Old  loss*** tensor(3405.6228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2864.1636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8952942
Old  loss*** tensor(1139.6033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.2802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8177739
Old  loss*** tensor(3247.5117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2655.7302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81913364
Old  loss*** tensor(2764.2065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2264.2546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82084334
Old  loss*** tensor(2457.3206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2017.0752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493926
Old  loss*** tensor(1551.4948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.8281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8157771
Old  loss*** tensor(3773.2600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3078.1392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84177065
Old  loss*** tensor(3204.5112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2697.4634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613039
Old  loss*** tensor(803.8788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.3840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78775537
Old  loss*** tensor(937.3625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(738.4124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8282987
Old  loss*** tensor(3284.2961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2720.3782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8765736
Old  loss*** tensor(1136.8468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(996.5299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7523085
Old  loss*** tensor(3941.1995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2964.9978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832079
Old  loss*** tensor(169.7561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(149.9299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88599956
Old  loss*** tensor(750.7827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.1932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480089
Old  loss*** tensor(2844.6394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2412.2795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7899072
Old  loss*** tensor(4205.6196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3322.0493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7775566
Old  loss*** tensor(2625.7070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2041.6359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799901
Old  loss*** tensor(544.2591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.9426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.897464
Old  loss*** tensor(762.0876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(683.9462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89218795
Old  loss*** tensor(468.0995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(417.6328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84766716
Old  loss*** tensor(2395.3967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2030.4991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8525839
Old  loss*** tensor(1401.5021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.8981, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82259536
Old  loss*** tensor(4076.7661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3353.5288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79112005
Old  loss*** tensor(2773.1462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2193.8916, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719971
Old  loss*** tensor(1095.7682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(955.5067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719295
Old  loss*** tensor(1357.0624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.2628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88553953
Old  loss*** tensor(299.6824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(265.3806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88716805
Old  loss*** tensor(1666.3737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1478.3535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8260813
Old  loss*** tensor(1781.9645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1472.0475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.809618
Old  loss*** tensor(3324.2483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2691.3713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.875406
Old  loss*** tensor(1331.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1165.5822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84880495
Old  loss*** tensor(863.5687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(733.0013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8576247
Old  loss*** tensor(1715.0144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1470.8387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87773025
Old  loss*** tensor(1309.3291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.2378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7948469
Old  loss*** tensor(4941.1836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3927.4844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84879315
Old  loss*** tensor(1996.0574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.2399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7606789
Old  loss*** tensor(4137.4980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3147.3074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8837289
Old  loss*** tensor(561.4063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.1310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88565683
Old  loss*** tensor(1243.6824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1101.4758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87392527
Old  loss*** tensor(1151.3477, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.1918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81679755
Old  loss*** tensor(2504.4758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2045.6498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8275959
Old  loss*** tensor(2645.5354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2189.4343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7722093
Old  loss*** tensor(4906.4199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3788.7830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7285589
Old  loss*** tensor(3853.8518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2807.7581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90774226
Old  loss*** tensor(710.8657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(645.2828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869132
Old  loss*** tensor(951.8562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.2138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562516
Old  loss*** tensor(1300.9391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1113.9312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84688574
Old  loss*** tensor(2610.8318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2211.0762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85157454
Old  loss*** tensor(2301.2097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1959.6516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8294882
Old  loss*** tensor(2656.2107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2203.2954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8856224
Old  loss*** tensor(242.5971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(214.8494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84218884
Old  loss*** tensor(2469.9343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2080.1511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84081864
Old  loss*** tensor(2806.0803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2359.4045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7932965
Old  loss*** tensor(4274.4175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3390.8806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8292336
Old  loss*** tensor(2076.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1721.5031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647976
Old  loss*** tensor(1466.1689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.9393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88837934
Old  loss*** tensor(655.7460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(582.5511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87022716
Old  loss*** tensor(547.7253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(476.6454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7942149
Old  loss*** tensor(3355.9661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2665.3582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8212353
Old  loss*** tensor(4158.6138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3415.2004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79236007
Old  loss*** tensor(3307.2244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2620.5125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84626913
Old  loss*** tensor(2976.9521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2519.3027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86049765
Old  loss*** tensor(3401.4287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2926.9214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798245
Old  loss*** tensor(1079.3174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(949.6099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559197
Old  loss*** tensor(4205.9429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3599.9495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81759614
Old  loss*** tensor(2782.9565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2275.3345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579028
Old  loss*** tensor(1025.2561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.5701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535986
Old  loss*** tensor(1531.1306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.9709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87601775
Old  loss*** tensor(732.0680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(641.3046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729358
Old  loss*** tensor(1535.8008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1340.6554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75569534
Old  loss*** tensor(4265.3745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3223.3237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8835454
Old  loss*** tensor(251.9324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(222.5937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8637719
Old  loss*** tensor(4202.7798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3630.2432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81653595
Old  loss*** tensor(1823.4425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1488.9064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.846719
Old  loss*** tensor(3195.7627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2705.9131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588089
Old  loss*** tensor(2057.3240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1766.8481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8645674
Old  loss*** tensor(1054.3530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.5593, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7929317
Old  loss*** tensor(4809.6880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3813.7539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8470288
Old  loss*** tensor(2550.9688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2160.7439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86352164
Old  loss*** tensor(1651.2188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.8632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8571345
Old  loss*** tensor(1505.8539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1290.7194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784499
Old  loss*** tensor(643.0181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(564.8592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7554709
Old  loss*** tensor(4371.7939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3302.7629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7709521
Old  loss*** tensor(2938.4810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89832073
Old  loss*** tensor(974.5225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(875.4338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656885
Old  loss*** tensor(550.3414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(476.4243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7700948
Old  loss*** tensor(4210.4619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3242.4548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8107683
Old  loss*** tensor(3033.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.1948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8733803
Old  loss*** tensor(1878.2672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1640.4415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88186693
Old  loss*** tensor(524.3439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.4015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9107601
Old  loss*** tensor(512.5545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(466.8142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89203405
Old  loss*** tensor(656.6628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(585.7656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857429
Old  loss*** tensor(1155.2716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(990.5634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808361
Old  loss*** tensor(409.7838, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(360.9524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84195226
Old  loss*** tensor(1439.9332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1212.3550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776766
Old  loss*** tensor(603.1647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(529.3835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895723
Old  loss*** tensor(637.2812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(566.9077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7752292
Old  loss*** tensor(3573.5747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2770.3396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539958
Old  loss*** tensor(2098.8762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1792.4315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82488894
Old  loss*** tensor(1966.7552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1622.3546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84963554
Old  loss*** tensor(2515.4722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2137.2346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310315
Old  loss*** tensor(1880.8806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8022703
Old  loss*** tensor(2962.5774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2376.7878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512558
Old  loss*** tensor(1559.6858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1327.6915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85709155
Old  loss*** tensor(3046.3242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2610.9788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8054261
Old  loss*** tensor(2429.7444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1956.9796, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7403288
Old  loss*** tensor(4759.2744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3523.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401723
Old  loss*** tensor(2203.8521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1851.6155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89396197
Old  loss*** tensor(805.9741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(720.5102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857982
Old  loss*** tensor(1585.3058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.2610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762913
Old  loss*** tensor(760.7424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.6319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89073384
Old  loss*** tensor(1376.5574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.1462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8444619
Old  loss*** tensor(1109.7545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(937.1454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8864956
Old  loss*** tensor(198.3666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(175.8511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8544261
Old  loss*** tensor(2431.3354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2077.3965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84554935
Old  loss*** tensor(2406.9380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2035.1848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661469
Old  loss*** tensor(2005.3320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1736.9121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7914393
Old  loss*** tensor(3986.6572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3155.1973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739935
Old  loss*** tensor(1097.8848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(959.5442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86178875
Old  loss*** tensor(1229.1215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.2430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8022563
Old  loss*** tensor(3677.5713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2950.3547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86102176
Old  loss*** tensor(1966.3853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.1005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115659
Old  loss*** tensor(2494.5657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2024.5044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86367285
Old  loss*** tensor(1058.0751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.8307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809043
Old  loss*** tensor(770.1622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.4392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523613
Old  loss*** tensor(2658.3315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.8589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85600543
Old  loss*** tensor(1716.2251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1469.0980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88132274
Old  loss*** tensor(3893.9185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3431.7988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874155
Old  loss*** tensor(1269.6975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1126.7493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8810903
Old  loss*** tensor(749.8502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(660.6857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8028208
Old  loss*** tensor(3657.1169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2936.0095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8394679
Old  loss*** tensor(3062.4846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2570.8574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7641189
Old  loss*** tensor(5074.6152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3877.6094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752352
Old  loss*** tensor(1143.7305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.0331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82401025
Old  loss*** tensor(1503.0038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.4905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778684
Old  loss*** tensor(973.1603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.3066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86005104
Old  loss*** tensor(791.0920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.3795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87169164
Old  loss*** tensor(997.5657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.5696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85361564
Old  loss*** tensor(2204.3403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1881.6594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703259
Old  loss*** tensor(1151.9493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.5714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218211
Old  loss*** tensor(3599.8721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2958.4507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562818
Old  loss*** tensor(1439.2173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1232.3756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8326043
Old  loss*** tensor(2705.4180, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2252.5427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8484118
Old  loss*** tensor(3163.4473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.9060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8372344
Old  loss*** tensor(2318.6743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1941.2738, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7707926
Old  loss*** tensor(5484.7114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4227.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89360315
Old  loss*** tensor(773.7795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(691.4518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8971199
Old  loss*** tensor(2875.4084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2579.5862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.776364
Old  loss*** tensor(4367.6406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3390.8792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87189007
Old  loss*** tensor(1134.6609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.2996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78470284
Old  loss*** tensor(4905.0547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3849.0103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82864654
Old  loss*** tensor(3893.7742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3226.5625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87773806
Old  loss*** tensor(952.1257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.7170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803873
Old  loss*** tensor(1440.7683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.4341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922757
Old  loss*** tensor(1687.2343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.4781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7952651
Old  loss*** tensor(3072.5981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2443.5300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86832875
Old  loss*** tensor(1184.4880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1028.5250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88889915
Old  loss*** tensor(116.5829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(103.6304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88704175
Old  loss*** tensor(324.2201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(287.5968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895257
Old  loss*** tensor(334.2362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(297.3117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81494725
Old  loss*** tensor(4631.3657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3774.3188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738055
Old  loss*** tensor(1144.6527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1000.2039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84230196
Old  loss*** tensor(3899.8018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3284.8108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8110784
Old  loss*** tensor(4161.4917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3375.2961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8797202
Old  loss*** tensor(1713.5907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.4803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8715087
Old  loss*** tensor(2200.4751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1917.7333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86308265
Old  loss*** tensor(1996.3593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1723.0231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84287167
Old  loss*** tensor(1532.2885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1291.5225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87845796
Old  loss*** tensor(1248.0811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1096.3867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8494842
Old  loss*** tensor(1690.5236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.0731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81454647
Old  loss*** tensor(3441.3159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2803.1118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85221064
Old  loss*** tensor(2491.2319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2123.0544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8599842
Old  loss*** tensor(1356.1422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.2609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731104
Old  loss*** tensor(1569.5175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1370.3621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8015661
Old  loss*** tensor(4291.5571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3439.9668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89592427
Old  loss*** tensor(1486.7546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1332.0195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727957
Old  loss*** tensor(1314.9932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1147.7203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208245
Old  loss*** tensor(2551.3718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.2285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80682254
Old  loss*** tensor(2888.0186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2330.1184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83133936
Old  loss*** tensor(4081.9312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3393.4700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8707067
Old  loss*** tensor(1035.2550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(901.4034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74693763
Old  loss*** tensor(4526.6245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3381.1062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7857245
Old  loss*** tensor(3181.9897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2500.1675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648428
Old  loss*** tensor(2676.1013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2314.4070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8496543
Old  loss*** tensor(643.7562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(546.9703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8425931
Old  loss*** tensor(2581.0854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2174.8047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84244657
Old  loss*** tensor(2937.3459, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2474.5569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8591801
Old  loss*** tensor(2741.8621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2355.7534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7996686
Old  loss*** tensor(2208.0359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1765.6970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87970567
Old  loss*** tensor(1008.9300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.5615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7918843
Old  loss*** tensor(3319.2390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2628.4534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771968
Old  loss*** tensor(81.2896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(71.3070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8107009
Old  loss*** tensor(4518.7456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3663.3511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78387064
Old  loss*** tensor(4899.2710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3840.3948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72468674
Old  loss*** tensor(4195.7603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3040.6118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87424934
Old  loss*** tensor(952.8002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(832.9850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7973374
Old  loss*** tensor(4481.4277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3573.2100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87894833
Old  loss*** tensor(1453.3599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1277.4282, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8271386
Old  loss*** tensor(1843.2338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1524.6097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80237687
Old  loss*** tensor(1929.9204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.5234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8247283
Old  loss*** tensor(3457.8093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2851.7532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8466725
Old  loss*** tensor(1990.8372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1685.5870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8338666
Old  loss*** tensor(1057.7207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.9980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731685
Old  loss*** tensor(1165.4429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.6281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85469574
Old  loss*** tensor(2710.9380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2317.0271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88466686
Old  loss*** tensor(792.2061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(700.8385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83245194
Old  loss*** tensor(2806.0552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2335.9060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8662445
Old  loss*** tensor(1490.2904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1290.9558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86535406
Old  loss*** tensor(1632.8717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1413.0122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784257
Old  loss*** tensor(1462.6764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1284.8525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84549433
Old  loss*** tensor(2291.3025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1937.2832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86123407
Old  loss*** tensor(4157.7539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3580.7993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89378107
Old  loss*** tensor(620.8637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.9162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781494
Old  loss*** tensor(902.6738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.6824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8695882
Old  loss*** tensor(569.4016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(495.1449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8581841
Old  loss*** tensor(1581.9393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.5952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85811794
Old  loss*** tensor(2013.1208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.4951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89969075
Old  loss*** tensor(803.2656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(722.6907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88567543
Old  loss*** tensor(888.4277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.8586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545735
Old  loss*** tensor(3361.6382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2872.7668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87664676
Old  loss*** tensor(786.2438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.2581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8040339
Old  loss*** tensor(2786.4844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2240.4277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86742866
Old  loss*** tensor(1165.1018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1010.6427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85951716
Old  loss*** tensor(812.5687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(698.4167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8189476
Old  loss*** tensor(4746.2686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3886.9453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745629
Old  loss*** tensor(1920.9532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1679.9945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700321
Old  loss*** tensor(439.6082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(382.4732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.800404
Old  loss*** tensor(3477.2949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2783.2407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84705424
Old  loss*** tensor(1599.3114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1354.7035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78837895
Old  loss*** tensor(3480.6272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2744.0532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8220463
Old  loss*** tensor(2967.9192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2439.7668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8944526
Old  loss*** tensor(699.2184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.4177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89304006
Old  loss*** tensor(248.9848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(222.3534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8959794
Old  loss*** tensor(463.0315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(414.8667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8371233
Old  loss*** tensor(2097.7439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1756.0702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8517501
Old  loss*** tensor(3583.7590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3052.4670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9085076
Old  loss*** tensor(716.2174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.6890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87381184
Old  loss*** tensor(3172.6248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2772.2771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78085774
Old  loss*** tensor(2770.0193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2162.9910, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415098
Old  loss*** tensor(1112.9290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(936.5406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815008
Old  loss*** tensor(254.0810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(223.9726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90378034
Old  loss*** tensor(1389.7683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1256.0453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8378018
Old  loss*** tensor(1219.6194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.7993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8465215
Old  loss*** tensor(1707.5304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1445.4612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85845286
Old  loss*** tensor(1732.0985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1486.9249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87496513
Old  loss*** tensor(1221.5546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1068.8176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85544145
Old  loss*** tensor(1733.1466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1482.6055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8614112
Old  loss*** tensor(2382.4595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2052.2773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024334
Old  loss*** tensor(2874.9414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2306.9490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89776117
Old  loss*** tensor(459.4632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.4882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7803036
Old  loss*** tensor(4166.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3251.1655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84234154
Old  loss*** tensor(2298.7012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1936.2915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398562
Old  loss*** tensor(1375.3641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1155.1082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75328726
Old  loss*** tensor(4191.8428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3157.6616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708669
Old  loss*** tensor(3849.9309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3352.7773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8079374
Old  loss*** tensor(3065.2073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2476.4956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84458417
Old  loss*** tensor(3875.0076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3272.7700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685781
Old  loss*** tensor(1420.1174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.4829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79805547
Old  loss*** tensor(1990.3071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.3755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84007525
Old  loss*** tensor(2220.2070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1865.1410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.880708
Old  loss*** tensor(1098.9293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(967.8358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88110185
Old  loss*** tensor(679.6880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(598.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8276472
Old  loss*** tensor(2476.5369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2049.6987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620538
Old  loss*** tensor(1570.5389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1353.8890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8195721
Old  loss*** tensor(4092.5266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3354.1206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399545
Old  loss*** tensor(2966.7354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2491.9226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7950139
Old  loss*** tensor(4806.2905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3821.0679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80172986
Old  loss*** tensor(4088.3601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3277.7603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8548108
Old  loss*** tensor(1277.2247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.7855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8293959
Old  loss*** tensor(2083.2729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.8580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91024965
Old  loss*** tensor(1221.4290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.8053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86763686
Old  loss*** tensor(1266.9342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1099.2388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84887373
Old  loss*** tensor(1821.9595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1546.6135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.844668
Old  loss*** tensor(2430.9414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2053.3384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675427
Old  loss*** tensor(1133.3199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(983.2034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885443
Old  loss*** tensor(1280.3892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1137.6825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81545806
Old  loss*** tensor(3949.3286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3220.5120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696891
Old  loss*** tensor(782.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.2413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8927989
Old  loss*** tensor(531.9667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(474.9393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655013
Old  loss*** tensor(1740.3464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1506.2721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9156908
Old  loss*** tensor(778.3733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.7493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81473076
Old  loss*** tensor(1986.3236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1618.3190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80207735
Old  loss*** tensor(4424.3086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3548.6377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658162
Old  loss*** tensor(1342.5939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1162.4395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8485893
Old  loss*** tensor(2110.0781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1790.5897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87709963
Old  loss*** tensor(2407.9014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2111.9695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80407
Old  loss*** tensor(2548.9797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2049.5581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88892066
Old  loss*** tensor(4233.3584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3763.1199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88519835
Old  loss*** tensor(1102.6141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(976.0322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91994023
Old  loss*** tensor(1157.3743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.7152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446804
Old  loss*** tensor(4539.6758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3834.5752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7733228
Old  loss*** tensor(4107.6558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3176.5439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8200782
Old  loss*** tensor(3566.4946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2924.8044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89393723
Old  loss*** tensor(352.6941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(315.2863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749509
Old  loss*** tensor(362.6494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(317.3004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88660216
Old  loss*** tensor(858.8506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.4588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610033
Old  loss*** tensor(1684.2339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.1309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84010327
Old  loss*** tensor(4149.3179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3485.8555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86807287
Old  loss*** tensor(1020.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.1455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.861349
Old  loss*** tensor(1343.9287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1157.5917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8936417
Old  loss*** tensor(185.4584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(165.7334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7858089
Old  loss*** tensor(4555.2920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3579.5891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773202
Old  loss*** tensor(158.3366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(138.9119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7979479
Old  loss*** tensor(4058.2271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3238.2537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86059844
Old  loss*** tensor(1391.4673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.4946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536376
Old  loss*** tensor(2355.9050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2011.0891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8494179
Old  loss*** tensor(1312.9873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1115.2749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84493625
Old  loss*** tensor(1600.5532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1352.3655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7898389
Old  loss*** tensor(2895.5122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2286.9883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439119
Old  loss*** tensor(2212.5059, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1867.1600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8292725
Old  loss*** tensor(1992.1449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.0310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8226713
Old  loss*** tensor(4487.4248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3691.6755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8265674
Old  loss*** tensor(2804.4346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2318.0542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85046226
Old  loss*** tensor(894.5341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(760.7675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88113344
Old  loss*** tensor(885.3294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(780.0933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8833089
Old  loss*** tensor(2393.4771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2114.1794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85184854
Old  loss*** tensor(1065.5930, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(907.7239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426307
Old  loss*** tensor(2715.6165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2288.2617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77209806
Old  loss*** tensor(4518.7368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3488.9080, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8835336
Old  loss*** tensor(1459.7388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1289.7283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86154795
Old  loss*** tensor(1443.1218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.3186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8993294
Old  loss*** tensor(580.2654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(521.8498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.744007
Old  loss*** tensor(3044.3975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.0530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78774023
Old  loss*** tensor(3496.5325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2754.3594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88910615
Old  loss*** tensor(1771.8430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1575.3566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.812281
Old  loss*** tensor(3318.4316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2695.4990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778348
Old  loss*** tensor(1178.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.5626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678419
Old  loss*** tensor(176.4726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(153.1503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88753456
Old  loss*** tensor(425.0382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(377.2361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.859548
Old  loss*** tensor(949.3154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(815.9822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9035785
Old  loss*** tensor(399.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(360.5289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8038817
Old  loss*** tensor(3058.3984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2458.5906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91418153
Old  loss*** tensor(1149.4768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.8304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.902597
Old  loss*** tensor(1260.1328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1137.3921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90654075
Old  loss*** tensor(1660.6115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.4120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8568649
Old  loss*** tensor(1398.1149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.9956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89087236
Old  loss*** tensor(1784.9751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1590.1849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502117
Old  loss*** tensor(1481.2860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1259.4066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7735487
Old  loss*** tensor(3439.8335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2660.8789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82374233
Old  loss*** tensor(2574.1902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2120.4695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87170327
Old  loss*** tensor(718.5875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(626.3951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88170016
Old  loss*** tensor(636.5667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(561.2609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8582691
Old  loss*** tensor(1892.2427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1624.0535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77448815
Old  loss*** tensor(2281.3767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1766.8992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9172465
Old  loss*** tensor(932.2605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.1127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79922473
Old  loss*** tensor(3393.2417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2711.9626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84791446
Old  loss*** tensor(3841.0352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3256.8691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88124985
Old  loss*** tensor(519.1879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(457.5343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8935801
Old  loss*** tensor(559.5033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(499.9610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86347115
Old  loss*** tensor(759.4919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(655.7994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8391165
Old  loss*** tensor(572.6625, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.5305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642413
Old  loss*** tensor(1370.7800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1184.6847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89985025
Old  loss*** tensor(982.3062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.9284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8972924
Old  loss*** tensor(917.1594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.9601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8367939
Old  loss*** tensor(2203.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1844.2296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76269394
Old  loss*** tensor(4803.2275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3663.3926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659055
Old  loss*** tensor(1953.0685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.1727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9026401
Old  loss*** tensor(621.2652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(560.7789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781886
Old  loss*** tensor(1039.8367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.1727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7742234
Old  loss*** tensor(4826.4512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3736.7515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79730487
Old  loss*** tensor(2910.0125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2320.1670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80690837
Old  loss*** tensor(3930.4138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3171.4839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.849927
Old  loss*** tensor(1783.0203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.4371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77054936
Old  loss*** tensor(3483.1135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.9109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084814
Old  loss*** tensor(3260.0544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2635.6934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8096609
Old  loss*** tensor(2395.2559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1939.3451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573346
Old  loss*** tensor(2094.9810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1796.0997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8348284
Old  loss*** tensor(2091.4202, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1745.9769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81507826
Old  loss*** tensor(3119.2092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2542.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82857513
Old  loss*** tensor(2792.1003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2313.4648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89057934
Old  loss*** tensor(2803.8569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2497.0571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8265918
Old  loss*** tensor(2429.2957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2008.0359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8951901
Old  loss*** tensor(744.2758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.2683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7993895
Old  loss*** tensor(4037.9683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3227.9094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75148535
Old  loss*** tensor(3761.7358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2826.8894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.901006
Old  loss*** tensor(716.7867, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(645.8292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85403836
Old  loss*** tensor(1591.1663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1358.9170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801458
Old  loss*** tensor(1692.5815, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1489.7185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.871264
Old  loss*** tensor(1997.9960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1740.7820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771918
Old  loss*** tensor(725.7482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(636.6203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908389
Old  loss*** tensor(1132.7383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.0873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85284746
Old  loss*** tensor(3103.9282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2647.1772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88248813
Old  loss*** tensor(906.4199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.9048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639459
Old  loss*** tensor(1089.4451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(941.2216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9322138
Old  loss*** tensor(1025.0853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(955.5987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8246822
Old  loss*** tensor(2270.5417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1872.4753, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87702596
Old  loss*** tensor(1290.2687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1131.5991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8878454
Old  loss*** tensor(4420.2417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3924.4912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89669657
Old  loss*** tensor(580.6790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.6929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7867961
Old  loss*** tensor(4701.3066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3698.9697, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88496995
Old  loss*** tensor(378.6757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(335.1166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8304058
Old  loss*** tensor(4567.4937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3792.8730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8887818
Old  loss*** tensor(627.6556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(557.8489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616442
Old  loss*** tensor(1221.9417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1052.8789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7826314
Old  loss*** tensor(3248.3076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2542.2275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.848261
Old  loss*** tensor(1729.3197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.9144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90283555
Old  loss*** tensor(555.3426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(501.3830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.797871
Old  loss*** tensor(3576.3796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2853.4895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8216706
Old  loss*** tensor(3478.3765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2858.0796, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78061295
Old  loss*** tensor(4842.9492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3780.4688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.92566156
Old  loss*** tensor(910.8705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(843.1578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88557243
Old  loss*** tensor(983.2612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.7490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8027091
Old  loss*** tensor(3880.8906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3115.2263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689278
Old  loss*** tensor(986.6801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.3537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88280666
Old  loss*** tensor(1587.4309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.3945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86920244
Old  loss*** tensor(1369.8174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.6486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767352
Old  loss*** tensor(1227.5895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1076.2709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89384997
Old  loss*** tensor(440.5970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(393.8276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85264844
Old  loss*** tensor(1339.3972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.0349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8753689
Old  loss*** tensor(1261.1320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1103.9557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8491703
Old  loss*** tensor(1872.6221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1590.1750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90214425
Old  loss*** tensor(914.6984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(825.1899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87199736
Old  loss*** tensor(1454.1281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.9958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7762209
Old  loss*** tensor(2663.4067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2067.3921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84641236
Old  loss*** tensor(2468.0164, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2088.9595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90026605
Old  loss*** tensor(943.5839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.4765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89976823
Old  loss*** tensor(627.4753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(564.5823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85961354
Old  loss*** tensor(489.9428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(421.1614, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165881
Old  loss*** tensor(3434.9062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2804.9036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84787446
Old  loss*** tensor(2125.2993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1801.9871, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84467554
Old  loss*** tensor(2140.2424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1807.8104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870327
Old  loss*** tensor(586.2316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.2132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84578073
Old  loss*** tensor(1937.9691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1639.0969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772248
Old  loss*** tensor(1406.3904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.7206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031111
Old  loss*** tensor(2635.6658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.7324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89751536
Old  loss*** tensor(267.5964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(240.1719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8505981
Old  loss*** tensor(1680.5239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.4504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738255
Old  loss*** tensor(893.9492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.1556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83241
Old  loss*** tensor(2525.4331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2102.1958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9093237
Old  loss*** tensor(611.0800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.6695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588116
Old  loss*** tensor(1697.3950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1457.7426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87834823
Old  loss*** tensor(1283.8818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1127.6953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87852925
Old  loss*** tensor(287.2010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(252.3145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678149
Old  loss*** tensor(1384.4271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1201.4265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87906843
Old  loss*** tensor(1704.4739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1498.3492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892161
Old  loss*** tensor(720.1720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.5094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8125744
Old  loss*** tensor(3592.1323, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2918.8748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7233515
Old  loss*** tensor(4729.1123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3420.8103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641553
Old  loss*** tensor(2214.4453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1913.6246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85356367
Old  loss*** tensor(1998.8793, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1706.1708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801539
Old  loss*** tensor(738.6542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.1294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8049631
Old  loss*** tensor(3991.6057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3213.0955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8645827
Old  loss*** tensor(1337.2015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1156.1213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87952423
Old  loss*** tensor(1045.7389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.7527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86480206
Old  loss*** tensor(1619.9513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1400.9373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439193
Old  loss*** tensor(2119.4175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1788.6173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87788236
Old  loss*** tensor(1983.8003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1741.5433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615266
Old  loss*** tensor(2376.0903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2047.0651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78761226
Old  loss*** tensor(3512.2485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2766.2900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86912143
Old  loss*** tensor(722.7485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(628.1562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080751
Old  loss*** tensor(2715.8433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2194.6052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85679656
Old  loss*** tensor(1617.1228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.5453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7678952
Old  loss*** tensor(3563.2668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2736.2156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89145577
Old  loss*** tensor(1344.1985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1198.2935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8030453
Old  loss*** tensor(4188.6187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3363.6504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7479906
Old  loss*** tensor(3674.1057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2748.1965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83855367
Old  loss*** tensor(3232.4724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2710.6016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87637794
Old  loss*** tensor(1907.1514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1671.3854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79767287
Old  loss*** tensor(2606.2253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2078.9153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7952657
Old  loss*** tensor(3346.2441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2661.1531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8109549
Old  loss*** tensor(1888.7058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1531.6553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8315884
Old  loss*** tensor(2818.7698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2344.0562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812617
Old  loss*** tensor(104.4352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(92.0348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78231514
Old  loss*** tensor(3607.6707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2822.3354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218968
Old  loss*** tensor(544.2380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(447.3074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86152565
Old  loss*** tensor(2405.2344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2072.1711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399772
Old  loss*** tensor(2026.5270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1702.2365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.832277
Old  loss*** tensor(4219.7832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3512.0286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8582792
Old  loss*** tensor(1931.4940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1657.7612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79783654
Old  loss*** tensor(3171.8198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2530.5938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81703264
Old  loss*** tensor(3265.7834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2668.2517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80782616
Old  loss*** tensor(4575.6045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3696.2930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8817473
Old  loss*** tensor(3983.0242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3512.0208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86726534
Old  loss*** tensor(1589.1952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1378.2539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86491954
Old  loss*** tensor(2981.2649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2578.5542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76256835
Old  loss*** tensor(4045.6909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3085.1160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.836765
Old  loss*** tensor(810.0692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.8375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661146
Old  loss*** tensor(2053.6550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1778.7007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88196987
Old  loss*** tensor(1030.5826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(908.9428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310871
Old  loss*** tensor(2715.1804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2256.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86675227
Old  loss*** tensor(3409.1174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2954.8604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86787343
Old  loss*** tensor(3043.3147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2641.2119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061326
Old  loss*** tensor(3092.6294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2493.0693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83803934
Old  loss*** tensor(3409.1497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701658
Old  loss*** tensor(1441.4688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1254.3169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807703
Old  loss*** tensor(496.7458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(437.5190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795352
Old  loss*** tensor(1062.2819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(934.3143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.806759
Old  loss*** tensor(2580.4451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2081.7974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700643
Old  loss*** tensor(1870.4172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1627.3833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8782076
Old  loss*** tensor(1406.0580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1234.8108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830044
Old  loss*** tensor(1293.6469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.2959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879729
Old  loss*** tensor(1025.4882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(910.6057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8010685
Old  loss*** tensor(3429.4763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2747.2454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89253837
Old  loss*** tensor(997.1532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(889.9975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86851877
Old  loss*** tensor(1156.9171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1004.8042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81125474
Old  loss*** tensor(1672.9769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.2104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8612994
Old  loss*** tensor(914.0591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(787.2786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549187
Old  loss*** tensor(2760.1108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2359.6704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74481773
Old  loss*** tensor(4595.0312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3422.4607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85061026
Old  loss*** tensor(1374.6885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1169.3241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87638617
Old  loss*** tensor(1672.6349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.8740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84736145
Old  loss*** tensor(3690.6895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3127.3479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689053
Old  loss*** tensor(1819.6091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.0680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87251043
Old  loss*** tensor(1293.7396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1128.8013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80963236
Old  loss*** tensor(2122.0103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1718.0482, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88084793
Old  loss*** tensor(782.8263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.5509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739622
Old  loss*** tensor(1674.5028, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1463.4521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79844236
Old  loss*** tensor(2286.7466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1825.8353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88407147
Old  loss*** tensor(198.5833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(175.5619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86697835
Old  loss*** tensor(1246.5497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.7316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8296944
Old  loss*** tensor(3034.8120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2517.9666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84335893
Old  loss*** tensor(2361.0945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1991.2501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81060195
Old  loss*** tensor(2539.9814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.9138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84260553
Old  loss*** tensor(2050.5154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.7756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8181093
Old  loss*** tensor(2883.0195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2358.6250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91627306
Old  loss*** tensor(454.3562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(416.3143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867029
Old  loss*** tensor(616.5967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(546.7380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82511795
Old  loss*** tensor(3870.0820, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3193.2742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677913
Old  loss*** tensor(1276.3580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1107.6124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8126633
Old  loss*** tensor(2551.9949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2073.9126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82214797
Old  loss*** tensor(2228.6230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1832.2579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8465679
Old  loss*** tensor(1499.0192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1269.0216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83156943
Old  loss*** tensor(1467.2017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.0801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88928664
Old  loss*** tensor(1063.2111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(945.4994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89427483
Old  loss*** tensor(794.2779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(710.3027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.844725
Old  loss*** tensor(1682.9127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1421.5985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9090694
Old  loss*** tensor(622.1715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(565.5971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88095474
Old  loss*** tensor(1379.9016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1215.6309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8777269
Old  loss*** tensor(726.0072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(637.2361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87235534
Old  loss*** tensor(1648.2566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1437.8655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8325536
Old  loss*** tensor(2007.8206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1671.6183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812369
Old  loss*** tensor(3128.1230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2756.6174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84893817
Old  loss*** tensor(444.0999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(377.0134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901729
Old  loss*** tensor(234.1436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(208.4283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84851205
Old  loss*** tensor(1198.1040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.6057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8757973
Old  loss*** tensor(1408.0305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.1493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7939093
Old  loss*** tensor(4006.0137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3180.4116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7955955
Old  loss*** tensor(4457.5581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3546.4133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713063
Old  loss*** tensor(671.3035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(584.9110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8945774
Old  loss*** tensor(471.0040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(421.3495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85331607
Old  loss*** tensor(3831.4111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3269.4048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83342755
Old  loss*** tensor(2539.6145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.5847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8205856
Old  loss*** tensor(2507.6650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2057.7539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849714
Old  loss*** tensor(958.8803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(848.5816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88713455
Old  loss*** tensor(2202.2964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1953.7333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8733187
Old  loss*** tensor(1962.8489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1714.1926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75783515
Old  loss*** tensor(4120.0093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3122.2878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9142177
Old  loss*** tensor(721.8422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(659.9210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7723316
Old  loss*** tensor(4451.0718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.7034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81729674
Old  loss*** tensor(4504.7695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3681.7334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747777
Old  loss*** tensor(1243.5304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1087.8126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8216846
Old  loss*** tensor(2543.0374, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2089.5747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81205255
Old  loss*** tensor(2934.9138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2383.3042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8997419
Old  loss*** tensor(713.6371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.0892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535371
Old  loss*** tensor(3834.6877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3273.0481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7916206
Old  loss*** tensor(4221.9004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3342.1433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775209
Old  loss*** tensor(1104.4064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(969.1397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7835101
Old  loss*** tensor(3913.0994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3065.9529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8888871
Old  loss*** tensor(449.4695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.5276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85544
Old  loss*** tensor(1750.2579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1497.2407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88160527
Old  loss*** tensor(471.7949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(415.9369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83263695
Old  loss*** tensor(2409.2498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.0304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86496544
Old  loss*** tensor(729.8525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(631.2972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8105419
Old  loss*** tensor(2944.0110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2386.2444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83322203
Old  loss*** tensor(1927.2365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1605.8159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.818129
Old  loss*** tensor(1939.8652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.0601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87348145
Old  loss*** tensor(3886.5110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3394.7952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89137816
Old  loss*** tensor(1302.0492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1160.6182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87039053
Old  loss*** tensor(902.4305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(785.4670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80945814
Old  loss*** tensor(4664.8159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3775.9731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8198081
Old  loss*** tensor(3579.7703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2934.7249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83056104
Old  loss*** tensor(2283.5234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1896.6056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874237
Old  loss*** tensor(244.5733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(217.0401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87056863
Old  loss*** tensor(726.9670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.8747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7719046
Old  loss*** tensor(5145.1646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3971.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8396149
Old  loss*** tensor(3102.7378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2605.1050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78062654
Old  loss*** tensor(4308.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3363.4187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667107
Old  loss*** tensor(2912.4695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2524.2686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77748543
Old  loss*** tensor(3029.4365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2355.3428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75078523
Old  loss*** tensor(3280.6704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2463.0789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547902
Old  loss*** tensor(3131.0132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2676.3594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701616
Old  loss*** tensor(1917.4253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1668.4698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769944
Old  loss*** tensor(1060.3840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.9508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82001436
Old  loss*** tensor(2031.3518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1665.7377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786609
Old  loss*** tensor(589.9175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.3375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879485
Old  loss*** tensor(649.8158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.5032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635112
Old  loss*** tensor(2481.3328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2142.6587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88058853
Old  loss*** tensor(2288.7910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2015.4832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88395154
Old  loss*** tensor(779.7382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.2508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8959207
Old  loss*** tensor(1880.3029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1684.6023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890512
Old  loss*** tensor(949.1473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(845.2271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8143007
Old  loss*** tensor(4353.7642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3545.2732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7965842
Old  loss*** tensor(3168.1116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2523.6675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81316775
Old  loss*** tensor(1967.6665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1600.0430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889338
Old  loss*** tensor(431.1390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(383.2540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85814416
Old  loss*** tensor(2155.8208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1850.0050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795923
Old  loss*** tensor(1601.2029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1408.4058, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8527408
Old  loss*** tensor(1581.0441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1348.2208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86320543
Old  loss*** tensor(1525.7745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.0569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7893661
Old  loss*** tensor(4006.8945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3162.9067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699436
Old  loss*** tensor(1944.4177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.5338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8040605
Old  loss*** tensor(3834.1018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3082.8499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7027307
Old  loss*** tensor(5054.0303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3551.6223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8611766
Old  loss*** tensor(4512.8491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3886.3601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859341
Old  loss*** tensor(752.6057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7601341
Old  loss*** tensor(2866.2283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2178.7178, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.903419
Old  loss*** tensor(1891.1617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1708.5115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85804605
Old  loss*** tensor(1624.8533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1394.1990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8141186
Old  loss*** tensor(4429.9487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3606.5037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674288
Old  loss*** tensor(312.9144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(271.4310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852798
Old  loss*** tensor(1425.5349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1215.6934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853789
Old  loss*** tensor(2151.9478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1837.3092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85691416
Old  loss*** tensor(3101.5903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2657.7966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9103102
Old  loss*** tensor(758.7479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.6960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78196436
Old  loss*** tensor(4723.1763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3693.3555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885989
Old  loss*** tensor(1433.6832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1273.9694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547199
Old  loss*** tensor(1300.9697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.9647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8403764
Old  loss*** tensor(1886.2201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.1348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88990057
Old  loss*** tensor(1366.9944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.4891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9063612
Old  loss*** tensor(1343.1871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1217.4127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7655066
Old  loss*** tensor(3614.4233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2766.8650, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892874
Old  loss*** tensor(155.0416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(138.4326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86232495
Old  loss*** tensor(1408.5426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1214.6215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8285607
Old  loss*** tensor(1395.3259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1156.1122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82174623
Old  loss*** tensor(4418.9458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3631.2520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80685455
Old  loss*** tensor(3175.6406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2562.2800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9021938
Old  loss*** tensor(470.7377, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(424.6966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86448824
Old  loss*** tensor(946.2388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.0123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8129729
Old  loss*** tensor(2742.3425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2229.4502, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79203665
Old  loss*** tensor(3887.5874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3079.1118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851254
Old  loss*** tensor(734.2953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.9435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.764207
Old  loss*** tensor(3384.4407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2586.4133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79228234
Old  loss*** tensor(4957.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3927.8079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7901798
Old  loss*** tensor(4040.8276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3192.9802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8303187
Old  loss*** tensor(3339.5679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2772.9055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88189757
Old  loss*** tensor(158.1253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(139.4503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.833604
Old  loss*** tensor(4067.4739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3390.6624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85937506
Old  loss*** tensor(1146.8154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.5446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410243
Old  loss*** tensor(2824.1624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.1892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85832465
Old  loss*** tensor(1231.0618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.6506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79778725
Old  loss*** tensor(4004.1997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3194.4995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79603314
Old  loss*** tensor(2934.5911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2336.0317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82119495
Old  loss*** tensor(2913.3071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2392.3931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88351303
Old  loss*** tensor(1118.3250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(988.0547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7968272
Old  loss*** tensor(1496.0723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1192.1111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767101
Old  loss*** tensor(2115.4585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1854.6439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89216703
Old  loss*** tensor(1025.8802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(915.2565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8541277
Old  loss*** tensor(2653.0466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2266.0405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876076
Old  loss*** tensor(554.9861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(492.6099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83419436
Old  loss*** tensor(2632.7427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2196.2190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922734
Old  loss*** tensor(584.9268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(521.9147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85581195
Old  loss*** tensor(1496.0157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1280.3081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86765075
Old  loss*** tensor(583.6226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(506.3806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86889696
Old  loss*** tensor(2112.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1835.8995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8239247
Old  loss*** tensor(4358.2778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3590.8928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815675
Old  loss*** tensor(841.7404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(742.0509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8544712
Old  loss*** tensor(2190.9482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1872.1022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7845446
Old  loss*** tensor(3536.8284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2774.7996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88457817
Old  loss*** tensor(1128.4590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(998.2102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585519
Old  loss*** tensor(2809.4182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2412.0315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8897029
Old  loss*** tensor(757.3128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(673.7834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84950006
Old  loss*** tensor(1726.2480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.4479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928956
Old  loss*** tensor(4072.7849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3636.5715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78565264
Old  loss*** tensor(2423.4441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1903.9852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542675
Old  loss*** tensor(1643.9674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.3879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865178
Old  loss*** tensor(1775.8444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.4215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81680554
Old  loss*** tensor(2618.3394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.6741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83841693
Old  loss*** tensor(3782.3643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3171.1982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8940711
Old  loss*** tensor(443.9286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(396.9038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781885
Old  loss*** tensor(1049.8241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(921.9434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8203634
Old  loss*** tensor(2719.8479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2231.2637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9148973
Old  loss*** tensor(546.1906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(499.7083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87814236
Old  loss*** tensor(1036.4222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(910.1263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82268965
Old  loss*** tensor(2515.1411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.1807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89300346
Old  loss*** tensor(816.1564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(728.8305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796089
Old  loss*** tensor(385.3890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(338.9916, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8248331
Old  loss*** tensor(2497.5903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2060.0952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8412243
Old  loss*** tensor(2147.9705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1806.9249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8757185
Old  loss*** tensor(1128.6851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(988.4103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8260376
Old  loss*** tensor(3423.9380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2828.3015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772379
Old  loss*** tensor(1698.6672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.1353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873419
Old  loss*** tensor(1083.1729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(946.0637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7526351
Old  loss*** tensor(4390.6099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3304.5271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8984405
Old  loss*** tensor(696.2042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.4980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86728156
Old  loss*** tensor(1998.6932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1733.4298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8643426
Old  loss*** tensor(1675.7885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1448.4553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7452208
Old  loss*** tensor(5114.2319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3811.2319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7921878
Old  loss*** tensor(4729.4790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3746.6355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77084297
Old  loss*** tensor(3568.7051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2750.9111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8316004
Old  loss*** tensor(3306.5886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2749.7605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7957296
Old  loss*** tensor(3029.6179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2410.7566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8239218
Old  loss*** tensor(3094.7109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2549.7998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8211074
Old  loss*** tensor(3771.1692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3096.5349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77618706
Old  loss*** tensor(1953.0243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.9122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81443894
Old  loss*** tensor(2988.6672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2434.0869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8324158
Old  loss*** tensor(1421.2800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.0959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535017
Old  loss*** tensor(1435.5709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1225.2622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88537216
Old  loss*** tensor(570.8634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(505.4266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85359746
Old  loss*** tensor(2322.6187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.5814, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878716
Old  loss*** tensor(880.1288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(773.3833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84730816
Old  loss*** tensor(1666.8060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.2983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7942854
Old  loss*** tensor(3497.2036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2777.7778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760256
Old  loss*** tensor(487.5277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(427.0868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8219962
Old  loss*** tensor(2755.2925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2264.8401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8235233
Old  loss*** tensor(2278.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1876.6708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81557524
Old  loss*** tensor(2360.0750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1924.8187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7911545
Old  loss*** tensor(3987.3079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3154.5767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8625927
Old  loss*** tensor(950.2954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(819.7179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7988254
Old  loss*** tensor(4670.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3730.8315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79610914
Old  loss*** tensor(3798.4646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3023.9924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451162
Old  loss*** tensor(1713.5081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1448.1134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85204357
Old  loss*** tensor(1479.3730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.4902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85535586
Old  loss*** tensor(1207.8157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.1122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81086785
Old  loss*** tensor(1838.4143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.7111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8331423
Old  loss*** tensor(3496.2424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2912.8674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8356266
Old  loss*** tensor(2058.8057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.3928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85820735
Old  loss*** tensor(1189.6525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.9685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670379
Old  loss*** tensor(1427.3342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1237.5529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818474
Old  loss*** tensor(476.5580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(420.2514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616761
Old  loss*** tensor(2608.7610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2247.9070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8367305
Old  loss*** tensor(3010.9307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2519.3374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87581235
Old  loss*** tensor(870.2062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(762.1374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575884
Old  loss*** tensor(1634.0258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.3215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89730465
Old  loss*** tensor(3706.8953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3326.2144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493969
Old  loss*** tensor(1222.7083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1038.5646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87344795
Old  loss*** tensor(920.1805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.7297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8110252
Old  loss*** tensor(2437.8767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1977.1794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8891512
Old  loss*** tensor(1089.4844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(968.7164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9118662
Old  loss*** tensor(476.7766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(434.7564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853458
Old  loss*** tensor(174.3621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(154.3707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8305532
Old  loss*** tensor(3584.6392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2977.2334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8858434
Old  loss*** tensor(401.5164, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(355.6807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87047464
Old  loss*** tensor(1386.8462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.2145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747288
Old  loss*** tensor(949.3486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(830.4225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85600114
Old  loss*** tensor(1997.4996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1709.8619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85222733
Old  loss*** tensor(1564.5621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.3627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86027235
Old  loss*** tensor(1791.4259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1541.1141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7935603
Old  loss*** tensor(2162.3157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1715.9280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8946594
Old  loss*** tensor(96.3624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(86.2115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89361835
Old  loss*** tensor(671.3948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(599.9707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78010046
Old  loss*** tensor(4515.4570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3522.5100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615968
Old  loss*** tensor(2141.7883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1845.3580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8341382
Old  loss*** tensor(3079.0046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2568.3154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8846204
Old  loss*** tensor(800.0187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(707.7129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684237
Old  loss*** tensor(1191.7369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9089932
Old  loss*** tensor(944.1420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.2187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800222
Old  loss*** tensor(1638.9130, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1442.2798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8499112
Old  loss*** tensor(3339.2515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2838.0674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81917065
Old  loss*** tensor(3202.9402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2623.7546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.806128
Old  loss*** tensor(3879.5623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3127.4238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914412
Old  loss*** tensor(633.9607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(565.1387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914224
Old  loss*** tensor(266.8489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(237.8751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83245337
Old  loss*** tensor(2662.3464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2216.2793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89603794
Old  loss*** tensor(761.8738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(682.6678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7592788
Old  loss*** tensor(5013.3550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3806.5339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8537599
Old  loss*** tensor(2730.8816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2331.5171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86024773
Old  loss*** tensor(1345.1473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1157.1599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8591888
Old  loss*** tensor(1840.9126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.6915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87757504
Old  loss*** tensor(1358.1022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1191.8365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7935407
Old  loss*** tensor(2436.7053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1933.6249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83781683
Old  loss*** tensor(2313.2749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1938.1007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77988833
Old  loss*** tensor(4404.5430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3435.0518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84644586
Old  loss*** tensor(2499.9424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2116.0659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841213
Old  loss*** tensor(682.3090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(603.2440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418327
Old  loss*** tensor(2724.9944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2293.9893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74773014
Old  loss*** tensor(4457.3247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3332.8760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8078198
Old  loss*** tensor(2920.1077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2358.9207, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88326615
Old  loss*** tensor(1042.9078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(921.1652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88736093
Old  loss*** tensor(729.6937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.5016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8554022
Old  loss*** tensor(3101.8184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2653.3022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847666
Old  loss*** tensor(1169.6801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.8938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85520124
Old  loss*** tensor(1995.7898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1706.8019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9024447
Old  loss*** tensor(868.9957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(784.2206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8400873
Old  loss*** tensor(1668.3209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.5352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87267864
Old  loss*** tensor(1431.1428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1248.9277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82494813
Old  loss*** tensor(2097.3750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1730.2256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86002445
Old  loss*** tensor(1647.1813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1416.6162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84567374
Old  loss*** tensor(4011.4004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3392.3359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84946656
Old  loss*** tensor(2526.7556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2146.3943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594739
Old  loss*** tensor(1658.3483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.3070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85167134
Old  loss*** tensor(1329.6226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1132.4014, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86252797
Old  loss*** tensor(1097.8833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(946.9551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86717
Old  loss*** tensor(3817.3147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3310.2607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.908244
Old  loss*** tensor(423.4903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(384.6326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792865
Old  loss*** tensor(1745.4518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1534.7522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85199535
Old  loss*** tensor(1415.8330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.2831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785045
Old  loss*** tensor(2033.2841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1786.2493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7898104
Old  loss*** tensor(4230.7534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3341.4932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83145964
Old  loss*** tensor(2948.4106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2451.4844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698287
Old  loss*** tensor(1346.5605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1171.2770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7939739
Old  loss*** tensor(4902.1543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3892.1826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8932459
Old  loss*** tensor(805.7274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.7127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8223975
Old  loss*** tensor(3274.9375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2693.3003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8027862
Old  loss*** tensor(4126.3774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3312.5986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87881255
Old  loss*** tensor(467.6152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(410.9461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8315129
Old  loss*** tensor(1951.7596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1622.9133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77101994
Old  loss*** tensor(4372.2139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3371.0640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7578093
Old  loss*** tensor(4632.8311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3510.8025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86721843
Old  loss*** tensor(669.0497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(580.2122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724948
Old  loss*** tensor(1544.6846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1347.7292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455375
Old  loss*** tensor(1422.8960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1203.1119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8249706
Old  loss*** tensor(1125.9460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(928.8724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842418
Old  loss*** tensor(2428.3281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2045.6674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8222111
Old  loss*** tensor(1941.6655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1596.4590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8505046
Old  loss*** tensor(1617.6648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1375.8313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76772845
Old  loss*** tensor(3869.6123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2970.8115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79158175
Old  loss*** tensor(3919.3687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3102.5007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88030285
Old  loss*** tensor(1097.6213, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(966.2392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8247191
Old  loss*** tensor(1738.8190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1434.0371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85895014
Old  loss*** tensor(1602.6183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1376.5692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.896765
Old  loss*** tensor(1297.7526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1163.7791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.830844
Old  loss*** tensor(2503.1155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2079.6985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90193236
Old  loss*** tensor(1261.0184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1137.3533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81513524
Old  loss*** tensor(2791.2231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2275.2244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8161809
Old  loss*** tensor(1919.3800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1566.5613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89531773
Old  loss*** tensor(1146.9384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89667803
Old  loss*** tensor(2292.5239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.6558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87664694
Old  loss*** tensor(1366.0480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.5417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87269455
Old  loss*** tensor(1582.0223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1380.6223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7857617
Old  loss*** tensor(4531.0840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3560.3523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8350879
Old  loss*** tensor(2272.3989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.6528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8329241
Old  loss*** tensor(1304.8582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1086.8479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.804429
Old  loss*** tensor(3305.4248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2658.9795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8358669
Old  loss*** tensor(2088.2622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1745.5093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87997675
Old  loss*** tensor(874.2740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(769.3408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8582721
Old  loss*** tensor(770.4890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.2892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8348456
Old  loss*** tensor(3015.6079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2517.5669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76199245
Old  loss*** tensor(3302.0298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2516.1218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7813353
Old  loss*** tensor(5254.5396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4105.5571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8686149
Old  loss*** tensor(1049.6740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.7625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9115784
Old  loss*** tensor(869.1829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.3284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78686345
Old  loss*** tensor(3434.6382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2702.5913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82849914
Old  loss*** tensor(3041.3523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2519.7578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8706459
Old  loss*** tensor(1423.5044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1239.3683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86897457
Old  loss*** tensor(998.9514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.0633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8344765
Old  loss*** tensor(2419.4773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2018.9968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87052476
Old  loss*** tensor(3081.9460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2682.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401551
Old  loss*** tensor(2166.7473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1820.4038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90052724
Old  loss*** tensor(632.4282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(569.5189, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7662816
Old  loss*** tensor(3326.1113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2548.7380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849189
Old  loss*** tensor(1856.4597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1642.8163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87680423
Old  loss*** tensor(140.0730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(122.8166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76767826
Old  loss*** tensor(3545.0859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2721.4854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907831
Old  loss*** tensor(561.3224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.0165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82873094
Old  loss*** tensor(3794.2166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3144.3848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8868991
Old  loss*** tensor(899.5570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.8163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.752859
Old  loss*** tensor(4396.0938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3309.6387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641548
Old  loss*** tensor(259.9500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(224.6370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452414
Old  loss*** tensor(2282.6653, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.4033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642334
Old  loss*** tensor(1424.3677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1230.9861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86994004
Old  loss*** tensor(778.5167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.2629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85359484
Old  loss*** tensor(794.8113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.4468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80973566
Old  loss*** tensor(2438.9199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1974.8804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684592
Old  loss*** tensor(746.3920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(648.2110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8440607
Old  loss*** tensor(266.0824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(224.5897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8023826
Old  loss*** tensor(4386.2251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.4307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83914196
Old  loss*** tensor(2612.3992, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2192.1738, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7463106
Old  loss*** tensor(4405.1309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3287.5957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75779045
Old  loss*** tensor(4130.7871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3130.2710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85771275
Old  loss*** tensor(2199.5322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.5668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86971474
Old  loss*** tensor(1216.0116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.5833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9064555
Old  loss*** tensor(549.2313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(497.8538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81203675
Old  loss*** tensor(2219.3445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1802.1893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8757248
Old  loss*** tensor(1145.4253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.0773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8242721
Old  loss*** tensor(2737.3057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2256.2847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076627
Old  loss*** tensor(3214.4082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2596.1577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86951613
Old  loss*** tensor(986.9775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.1929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620236
Old  loss*** tensor(4194.8281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3616.0408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87409353
Old  loss*** tensor(2048.5923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1790.6613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879596
Old  loss*** tensor(922.7471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(811.6447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.883451
Old  loss*** tensor(589.3286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.6429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89657587
Old  loss*** tensor(403.6095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(361.8666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8989854
Old  loss*** tensor(1513.2496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1360.3893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83844656
Old  loss*** tensor(2527.0234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2118.7742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534943
Old  loss*** tensor(995.6687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.7975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85813224
Old  loss*** tensor(3847.4033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3301.5808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83991605
Old  loss*** tensor(1424.4688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1196.4342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821262
Old  loss*** tensor(1564.4725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1380.0623, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8625605
Old  loss*** tensor(1339.2649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1155.1970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618669
Old  loss*** tensor(1656.5222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1427.7017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8123816
Old  loss*** tensor(3174.7419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2579.1021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72953856
Old  loss*** tensor(5030.3447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3669.8306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700063
Old  loss*** tensor(1066.6692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(928.0089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8002739
Old  loss*** tensor(3831.2893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3066.0808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85890925
Old  loss*** tensor(824.6109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.2659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922132
Old  loss*** tensor(912.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(813.8130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281109
Old  loss*** tensor(2405.3508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1991.8972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724884
Old  loss*** tensor(3626.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3164.0364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82749903
Old  loss*** tensor(2142.6277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1773.0223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85844326
Old  loss*** tensor(1882.2765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1615.8275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90024453
Old  loss*** tensor(309.1347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(278.2968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8948519
Old  loss*** tensor(535.3788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(479.0847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84431946
Old  loss*** tensor(1929.1771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1628.8418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83428156
Old  loss*** tensor(3117.3926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2600.7832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79687107
Old  loss*** tensor(2489.2930, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1983.6455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8843771
Old  loss*** tensor(803.8732, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(710.9271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459399
Old  loss*** tensor(1873.6327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.9806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8693384
Old  loss*** tensor(1430.9480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.9780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908159
Old  loss*** tensor(1394.3694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.1265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88570815
Old  loss*** tensor(1362.7939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.0377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841944
Old  loss*** tensor(647.7842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(572.7672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8170926
Old  loss*** tensor(4313.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3524.4846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7728772
Old  loss*** tensor(5100.4478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3942.0198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73468375
Old  loss*** tensor(3439.1545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2526.6909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89052904
Old  loss*** tensor(897.4338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.1909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8469455
Old  loss*** tensor(747.1215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.7712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8718371
Old  loss*** tensor(1756.5206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1531.3998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463645
Old  loss*** tensor(2530.4949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.7209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76371926
Old  loss*** tensor(3857.0193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2945.6799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86999357
Old  loss*** tensor(994.2341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.9773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85173035
Old  loss*** tensor(1234.2881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1051.2806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89414203
Old  loss*** tensor(391.3878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(349.9562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869496
Old  loss*** tensor(1499.2233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1303.5686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84712386
Old  loss*** tensor(2476.3047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2097.7368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559768
Old  loss*** tensor(3938.8481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3371.5627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604748
Old  loss*** tensor(1972.0233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1696.8765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88598615
Old  loss*** tensor(719.1818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(637.1851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.883788
Old  loss*** tensor(591.3367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(522.6163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244049
Old  loss*** tensor(4117.9629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3394.8687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646704
Old  loss*** tensor(1789.3420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1547.1910, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793287
Old  loss*** tensor(1280.7677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1126.2158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399053
Old  loss*** tensor(2345.4719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1969.9744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8037175
Old  loss*** tensor(3348.6741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2691.3879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7895826
Old  loss*** tensor(3402.6494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2686.6729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781209
Old  loss*** tensor(1573.4247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1381.6571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84719074
Old  loss*** tensor(1984.1299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.9364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86239314
Old  loss*** tensor(1239.3286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1068.7885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8120627
Old  loss*** tensor(4134.4233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3357.4109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89098567
Old  loss*** tensor(294.7347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(262.6044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8863206
Old  loss*** tensor(669.4147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(593.3160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7888899
Old  loss*** tensor(3659.4219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2886.8809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8378997
Old  loss*** tensor(3246.3962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2720.1543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8001331
Old  loss*** tensor(3896.0491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3117.3579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359386
Old  loss*** tensor(1491.7932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.0475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80628574
Old  loss*** tensor(4435.8677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3576.5769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8363087
Old  loss*** tensor(1915.8134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1602.2114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762597
Old  loss*** tensor(1241.0079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1087.4452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8188089
Old  loss*** tensor(3972.9019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3253.0474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86821485
Old  loss*** tensor(1415.8431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.2560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773498
Old  loss*** tensor(606.8312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.4033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8338404
Old  loss*** tensor(2034.6760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1696.5951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8971697
Old  loss*** tensor(931.7145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.9061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881412
Old  loss*** tensor(2175.0579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1917.1222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875184
Old  loss*** tensor(895.4370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(794.7169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.790589
Old  loss*** tensor(3129.8196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2474.4009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748625
Old  loss*** tensor(2403.7534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2102.9536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.774289
Old  loss*** tensor(3561.6021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2757.7092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7270925
Old  loss*** tensor(4793.8789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3485.5935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89859545
Old  loss*** tensor(1055.5957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(948.5535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781314
Old  loss*** tensor(605.4982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(531.7070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8342164
Old  loss*** tensor(2803.4653, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2338.6968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88843954
Old  loss*** tensor(1012.0085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.1083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9013523
Old  loss*** tensor(993.8288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.7899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853979
Old  loss*** tensor(1136.3311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.1052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8951144
Old  loss*** tensor(1718.4648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1538.2227, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83976346
Old  loss*** tensor(2131.4448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1789.9095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87740993
Old  loss*** tensor(125.6012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(110.2038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8507421
Old  loss*** tensor(1561.6110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.5282, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79594713
Old  loss*** tensor(4041.9023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3217.1406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82585484
Old  loss*** tensor(2715.0654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2242.2500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9098876
Old  loss*** tensor(518.7983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(472.0481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8652114
Old  loss*** tensor(951.1366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.9343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81794935
Old  loss*** tensor(3012.9253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2464.4204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8681222
Old  loss*** tensor(1783.5037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.2992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874775
Old  loss*** tensor(2743.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2399.6765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80372477
Old  loss*** tensor(3862.7202, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3104.5640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83603626
Old  loss*** tensor(3952.6038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3304.5200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8424971
Old  loss*** tensor(2305.4797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1942.3600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672087
Old  loss*** tensor(2244.9883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1946.8734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460934
Old  loss*** tensor(1558.6609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1318.7727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454013
Old  loss*** tensor(4001.2751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3382.6831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84167624
Old  loss*** tensor(1835.7828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1545.1348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85352206
Old  loss*** tensor(1561.8519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.0751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82391065
Old  loss*** tensor(1755.3876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.2825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8916383
Old  loss*** tensor(1038.0247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.5425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79756105
Old  loss*** tensor(3150.7129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2512.8860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8938333
Old  loss*** tensor(840.6873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(751.4343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88444686
Old  loss*** tensor(497.1236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(439.6794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8300332
Old  loss*** tensor(2578.4995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2140.2402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81596076
Old  loss*** tensor(2657.6152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2168.5098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7512231
Old  loss*** tensor(4593.2192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3450.5322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84676325
Old  loss*** tensor(2638.5730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2234.2466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654112
Old  loss*** tensor(1007.6173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.0034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89035046
Old  loss*** tensor(765.4779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(681.5436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89682496
Old  loss*** tensor(433.9687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(389.1940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86493844
Old  loss*** tensor(609.6265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(527.2894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853672
Old  loss*** tensor(1167.7019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.8450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83559275
Old  loss*** tensor(3833.9656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3203.6338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8074744
Old  loss*** tensor(2766.4128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2233.8074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890875
Old  loss*** tensor(603.2642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(537.4330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81132174
Old  loss*** tensor(2168.2368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.1377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8312135
Old  loss*** tensor(2279.9460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1895.1218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7813202
Old  loss*** tensor(2691.8594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2103.2041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428992
Old  loss*** tensor(1138.6923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(959.8028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421744
Old  loss*** tensor(1175.0286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.5790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670422
Old  loss*** tensor(2157.1892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1870.3740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71591735
Old  loss*** tensor(4545.3345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3254.0837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.914875
Old  loss*** tensor(738.7502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(675.8641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88415676
Old  loss*** tensor(1239.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1096.2054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81232315
Old  loss*** tensor(3262.0911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2649.8721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88636804
Old  loss*** tensor(745.0616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(660.3988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81298625
Old  loss*** tensor(4464.4756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3629.5574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337743
Old  loss*** tensor(2745.4670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2289.0999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622453
Old  loss*** tensor(1832.2781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1579.8732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531693
Old  loss*** tensor(2218.7451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1892.9652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8555232
Old  loss*** tensor(1636.3917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.9712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842126
Old  loss*** tensor(2691.3630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2266.4668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8330972
Old  loss*** tensor(4268.6069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3556.1646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877934
Old  loss*** tensor(1151.7501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.5162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528081
Old  loss*** tensor(2205.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1880.4430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8561946
Old  loss*** tensor(1753.5264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1501.3599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.767382
Old  loss*** tensor(5008.9980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3843.8152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8278034
Old  loss*** tensor(1581.6523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1309.2971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8517805
Old  loss*** tensor(2141.5718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1824.1490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7904358
Old  loss*** tensor(3972.0396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3139.6423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7998938
Old  loss*** tensor(3278.0591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2622.0991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604217
Old  loss*** tensor(3398.5327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2924.1714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8273064
Old  loss*** tensor(2142.5332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1772.5314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7813829
Old  loss*** tensor(4619.7891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3609.8242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8185033
Old  loss*** tensor(3720.3999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3045.1597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586383
Old  loss*** tensor(1610.7480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1383.0499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.807626
Old  loss*** tensor(3714.9238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3000.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84740657
Old  loss*** tensor(1496.8365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.4291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8935199
Old  loss*** tensor(758.6200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.8420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88166034
Old  loss*** tensor(1642.1627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1447.8297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818053
Old  loss*** tensor(578.9946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.5605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502587
Old  loss*** tensor(1203.8822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1023.6113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000642
Old  loss*** tensor(1113.5370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.2548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536932
Old  loss*** tensor(1968.9694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.8958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823985
Old  loss*** tensor(211.9951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(187.0641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796953
Old  loss*** tensor(823.0701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(724.0509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931891
Old  loss*** tensor(365.5620, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(326.5160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88205236
Old  loss*** tensor(861.4699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.8616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535354
Old  loss*** tensor(1516.8497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.6849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8584062
Old  loss*** tensor(4439.8535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3811.1978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87561405
Old  loss*** tensor(1550.6433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.7650, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88672215
Old  loss*** tensor(886.4545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.0389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8471689
Old  loss*** tensor(3550.6665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3008.0144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.835025
Old  loss*** tensor(1850.2799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1545.0300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669143
Old  loss*** tensor(2134.0239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1850.0157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7547324
Old  loss*** tensor(4330.6411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3268.4751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88318384
Old  loss*** tensor(1059.8865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(936.0746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7419895
Old  loss*** tensor(3346.1233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2482.7883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875648
Old  loss*** tensor(755.9731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(670.9752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741777
Old  loss*** tensor(1530.5995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1338.0160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698268
Old  loss*** tensor(1679.2629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1460.6678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8303648
Old  loss*** tensor(2547.6038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2115.4404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79649866
Old  loss*** tensor(3631.1436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2892.2009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86317384
Old  loss*** tensor(3141.7349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2711.8633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83339083
Old  loss*** tensor(1448.6783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.3153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7898778
Old  loss*** tensor(4149.1719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3277.3386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85936093
Old  loss*** tensor(1042.9636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(896.2822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8789334
Old  loss*** tensor(864.2325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.6028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.737138
Old  loss*** tensor(3747.8643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2762.6931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81983167
Old  loss*** tensor(2471.2556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2026.0137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678479
Old  loss*** tensor(1221.6232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1060.1831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8709305
Old  loss*** tensor(1068.7480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(930.8052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87444675
Old  loss*** tensor(997.7776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.5034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885425
Old  loss*** tensor(1508.2938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.4810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650652
Old  loss*** tensor(1680.1740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1453.4601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88937587
Old  loss*** tensor(428.9395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(381.4885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81485903
Old  loss*** tensor(3109.1204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.4949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.775758
Old  loss*** tensor(4465.5972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3464.2229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80814
Old  loss*** tensor(3862.9402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3121.7964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7988429
Old  loss*** tensor(3292.0498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2629.8306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91160625
Old  loss*** tensor(484.0372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(441.2513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762448
Old  loss*** tensor(444.2068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(389.2339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85146046
Old  loss*** tensor(1916.7893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1632.0703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85506845
Old  loss*** tensor(2380.6770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2035.6417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830248
Old  loss*** tensor(121.9612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(107.6948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7767644
Old  loss*** tensor(2633.3638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2045.5032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8882257
Old  loss*** tensor(271.9016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(241.5100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8627115
Old  loss*** tensor(3125.3076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2696.2388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.824062
Old  loss*** tensor(3801.5945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3132.7495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84364736
Old  loss*** tensor(2866.2720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2418.1228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7722755
Old  loss*** tensor(2684.2327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2072.9670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86830944
Old  loss*** tensor(1421.7765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1234.5420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7728804
Old  loss*** tensor(2710.0063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.5107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764252
Old  loss*** tensor(1357.5579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1189.7980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426455
Old  loss*** tensor(1716.8894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.7291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585304
Old  loss*** tensor(1906.0135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1636.3706, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864534
Old  loss*** tensor(1113.1378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(962.3455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8003136
Old  loss*** tensor(3465.8948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2773.8027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80665
Old  loss*** tensor(3513.1042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2833.8455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.866117
Old  loss*** tensor(986.4558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.3862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701297
Old  loss*** tensor(862.1393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(750.1730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552715
Old  loss*** tensor(1514.8236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1295.5854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76126987
Old  loss*** tensor(4339.2163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3303.3147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86436045
Old  loss*** tensor(2499.7166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2160.6562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84826314
Old  loss*** tensor(2753.2200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2335.4551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87128365
Old  loss*** tensor(1447.4244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1261.1172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7636039
Old  loss*** tensor(3367.3682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2571.3354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7814747
Old  loss*** tensor(2584.6030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2019.8019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89888394
Old  loss*** tensor(613.0322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(551.0447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8593425
Old  loss*** tensor(1482.0610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1273.5980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83569825
Old  loss*** tensor(3334.7148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2786.8154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8214487
Old  loss*** tensor(2728.7705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2241.5449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88123256
Old  loss*** tensor(1624.1770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.2777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86446047
Old  loss*** tensor(2767.0542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2392.0090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83586246
Old  loss*** tensor(2785.0740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2327.9387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86560595
Old  loss*** tensor(724.8141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(627.4034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847323
Old  loss*** tensor(642.1244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(568.1082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9096786
Old  loss*** tensor(425.4487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(387.0216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816688
Old  loss*** tensor(1157.6053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.6245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86569387
Old  loss*** tensor(1389.4998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1202.8815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7994838
Old  loss*** tensor(2102.3875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.8247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8633304
Old  loss*** tensor(3768.1760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3253.1809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772129
Old  loss*** tensor(627.2051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(550.1924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178064
Old  loss*** tensor(3810.8440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3116.5327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8999827
Old  loss*** tensor(886.6388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.9596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8866202
Old  loss*** tensor(1429.4392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.3698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8448951
Old  loss*** tensor(4250.8306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3591.5061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76274633
Old  loss*** tensor(3921.7400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2991.2927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87827873
Old  loss*** tensor(436.0739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(382.9944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86874986
Old  loss*** tensor(1289.7318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1120.4543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7806448
Old  loss*** tensor(2759.7415, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2154.3777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677021
Old  loss*** tensor(1789.0375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1552.3516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756989
Old  loss*** tensor(2441.1865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2137.7444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855209
Old  loss*** tensor(1385.8435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.1934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050024
Old  loss*** tensor(4927.9722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3967.0293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7752836
Old  loss*** tensor(4535.2700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3516.1204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86122864
Old  loss*** tensor(1418.2196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1221.4114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8269427
Old  loss*** tensor(4199.9648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3473.1301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77147746
Old  loss*** tensor(3305.0908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2549.8030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7879336
Old  loss*** tensor(4380.4834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3451.5300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8365511
Old  loss*** tensor(2028.7987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1697.1937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84219366
Old  loss*** tensor(1052.2004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.1566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88355744
Old  loss*** tensor(351.3662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(310.4522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483509
Old  loss*** tensor(2220.0952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1883.4197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629108
Old  loss*** tensor(1224.1177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.3043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86831516
Old  loss*** tensor(1784.2725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1549.3108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76149213
Old  loss*** tensor(3406.7188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2594.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77507424
Old  loss*** tensor(4013.5361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3110.7886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88013554
Old  loss*** tensor(92.2557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(81.1976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90937114
Old  loss*** tensor(684.2205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(622.2104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852885
Old  loss*** tensor(568.7833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(503.5373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89387536
Old  loss*** tensor(321.2710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(287.1762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7540241
Old  loss*** tensor(4136.9551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3119.3638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89959085
Old  loss*** tensor(893.1658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.4838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90595114
Old  loss*** tensor(462.0144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(418.5624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747775
Old  loss*** tensor(546.0125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(477.6395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783794
Old  loss*** tensor(1167.6129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.6072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819456
Old  loss*** tensor(1717.9220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.1138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85386455
Old  loss*** tensor(1690.3844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.3594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597443
Old  loss*** tensor(1749.9449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1504.5052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81471527
Old  loss*** tensor(2971.4355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2420.8740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741818
Old  loss*** tensor(1636.0072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.1677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84168136
Old  loss*** tensor(2331.9482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1962.7573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8212578
Old  loss*** tensor(2391.9067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1964.3722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.799399
Old  loss*** tensor(1882.8403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.1407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808658
Old  loss*** tensor(899.3256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(792.1851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8053458
Old  loss*** tensor(3548.3682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.6633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86810744
Old  loss*** tensor(725.1400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.4995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86872625
Old  loss*** tensor(1628.1948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.4556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86835814
Old  loss*** tensor(1462.7531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1270.1935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659303
Old  loss*** tensor(1151.3374, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(996.9780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82507396
Old  loss*** tensor(4175.1367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3444.7966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79667914
Old  loss*** tensor(2428.7058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1934.8993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9037198
Old  loss*** tensor(1389.7148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.9128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618246
Old  loss*** tensor(872.1527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(751.6426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79247093
Old  loss*** tensor(2026.6537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1606.0641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74667674
Old  loss*** tensor(4004.8555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2990.3325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451364
Old  loss*** tensor(4738.7319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4004.8748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88535583
Old  loss*** tensor(117.4251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(103.9630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75722766
Old  loss*** tensor(4261.8076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3227.1587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87996805
Old  loss*** tensor(4214.2393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3708.3960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87014633
Old  loss*** tensor(1059.7139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(922.1061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7932155
Old  loss*** tensor(3042.1187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2413.0557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88443935
Old  loss*** tensor(1574.3505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1392.4175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8396237
Old  loss*** tensor(2509.9106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2107.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82668257
Old  loss*** tensor(2072.7605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1713.5150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85297626
Old  loss*** tensor(1289.9255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1100.2759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83551395
Old  loss*** tensor(1811.9760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1513.9312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8949075
Old  loss*** tensor(1010.9230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.6826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939723
Old  loss*** tensor(707.7418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.7015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716378
Old  loss*** tensor(1007.3123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(878.0115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82151115
Old  loss*** tensor(2206.0366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1812.2837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7040946
Old  loss*** tensor(3324.2432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2340.5815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83666617
Old  loss*** tensor(2459.3672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2057.6694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384061
Old  loss*** tensor(2325.8801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1950.0321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89947236
Old  loss*** tensor(543.7117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.0537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8403545
Old  loss*** tensor(1742.2051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1464.0698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8067832
Old  loss*** tensor(2649.4819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2137.5576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86231124
Old  loss*** tensor(2248.0193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1938.4923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218136
Old  loss*** tensor(3217.7561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2644.3958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.779047
Old  loss*** tensor(3708.4854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2889.0845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78324914
Old  loss*** tensor(4018.9448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3147.8350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81838113
Old  loss*** tensor(4047.1714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3312.1287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83344793
Old  loss*** tensor(2434.3452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2028.9000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858412
Old  loss*** tensor(1185.1230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.3239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85274833
Old  loss*** tensor(3050.1604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2601.0193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024257
Old  loss*** tensor(4085.0020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3277.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85785514
Old  loss*** tensor(2430.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2085.3672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86053455
Old  loss*** tensor(3118.4990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2683.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79749876
Old  loss*** tensor(4685.9951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3737.0752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84909755
Old  loss*** tensor(2251.7905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1911.9899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81736827
Old  loss*** tensor(3190.9480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2608.1797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87904906
Old  loss*** tensor(1478.7942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9017078
Old  loss*** tensor(544.5797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(491.0517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7941412
Old  loss*** tensor(4736.9829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3761.8333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86414504
Old  loss*** tensor(1855.9362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1603.7980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87585413
Old  loss*** tensor(2498.6052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2188.4138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747417
Old  loss*** tensor(959.1821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.0366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89955187
Old  loss*** tensor(1659.1178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1492.4625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87972665
Old  loss*** tensor(1261.6309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1109.8903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540789
Old  loss*** tensor(1495.3361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1277.1350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87435585
Old  loss*** tensor(1450.3262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.1012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823563
Old  loss*** tensor(574.8775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(507.2468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758341
Old  loss*** tensor(1164.9506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.3034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512882
Old  loss*** tensor(542.4835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.8098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664672
Old  loss*** tensor(2056.3728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1781.7795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860723
Old  loss*** tensor(1643.5375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.6305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8380594
Old  loss*** tensor(2086.7947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1748.8579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683406
Old  loss*** tensor(1952.8671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.7538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86449355
Old  loss*** tensor(1819.4663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1572.9169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9085909
Old  loss*** tensor(417.2133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783741
Old  loss*** tensor(889.6970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.4868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793167
Old  loss*** tensor(111.7111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(98.2294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86847746
Old  loss*** tensor(1325.2682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.9656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763188
Old  loss*** tensor(548.7677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.8954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796228
Old  loss*** tensor(396.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(348.7784, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86334085
Old  loss*** tensor(1676.7460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1447.6033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87847805
Old  loss*** tensor(3187.3262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2799.9961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8954818
Old  loss*** tensor(742.0932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(664.5309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81745607
Old  loss*** tensor(1998.1094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1633.3666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8257246
Old  loss*** tensor(2157.6892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1781.6571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72605157
Old  loss*** tensor(4823.1699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3501.8701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84614587
Old  loss*** tensor(2876.3218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2433.7878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8044313
Old  loss*** tensor(3900.3677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3137.5779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8870585
Old  loss*** tensor(1162.8303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1031.4985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.899776
Old  loss*** tensor(248.3095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(223.4229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83634573
Old  loss*** tensor(3350.6997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2802.3435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81302416
Old  loss*** tensor(3581.6079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2911.9338, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81136274
Old  loss*** tensor(2283.0652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1852.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7922505
Old  loss*** tensor(2552.6277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2022.3206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672644
Old  loss*** tensor(1159.0602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.2116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81736326
Old  loss*** tensor(3333.0557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2724.3171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781744
Old  loss*** tensor(783.4779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(688.0303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84196275
Old  loss*** tensor(2131.4856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1794.6315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8988811
Old  loss*** tensor(502.4679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.6589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929673
Old  loss*** tensor(397.4568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(354.9159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88046265
Old  loss*** tensor(964.8875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.5474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8912767
Old  loss*** tensor(1082.5259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(964.8301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8019339
Old  loss*** tensor(3970.5789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3184.1418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84667885
Old  loss*** tensor(3060.9402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2591.6333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81981015
Old  loss*** tensor(3018.1101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2474.2773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7657101
Old  loss*** tensor(4229.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3238.2012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83481824
Old  loss*** tensor(2779.4080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2320.3005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7165665
Old  loss*** tensor(4635.5410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3321.6733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853516
Old  loss*** tensor(1416.6936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1209.1707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8287792
Old  loss*** tensor(1287.6434, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1067.1721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75783575
Old  loss*** tensor(4578.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3469.3743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89147127
Old  loss*** tensor(754.3575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(672.4881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815569
Old  loss*** tensor(435.3462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(383.7824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.767539
Old  loss*** tensor(3529.4033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2708.9548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88607496
Old  loss*** tensor(1531.9878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.4561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91244024
Old  loss*** tensor(852.4487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(777.8085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80906194
Old  loss*** tensor(3853.6592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3117.8489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9017242
Old  loss*** tensor(1092.7008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.3148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842393
Old  loss*** tensor(2336.6409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1968.3699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86034113
Old  loss*** tensor(1047.9623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(901.6050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88365144
Old  loss*** tensor(1095.3864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(967.9397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8707037
Old  loss*** tensor(449.7585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(391.6064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8726538
Old  loss*** tensor(779.5963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(680.3177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7838524
Old  loss*** tensor(3114.6382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2441.4165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82062644
Old  loss*** tensor(2550.3892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2092.9167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347831
Old  loss*** tensor(2366.4636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1975.4838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91015095
Old  loss*** tensor(781.7142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(711.4780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8527668
Old  loss*** tensor(1700.7546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.3472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76290375
Old  loss*** tensor(4578.4595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3492.9238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8498485
Old  loss*** tensor(1531.9539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1301.9287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572539
Old  loss*** tensor(1207.8999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.4769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629929
Old  loss*** tensor(783.2623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(675.9498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82752013
Old  loss*** tensor(2771.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2293.2437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8486644
Old  loss*** tensor(3675.1750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.9902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8561858
Old  loss*** tensor(1343.7423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.4930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88256574
Old  loss*** tensor(965.0635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(851.7319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388018
Old  loss*** tensor(1771.0126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.5286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8093443
Old  loss*** tensor(2848.5293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2305.4409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83938277
Old  loss*** tensor(1607.9707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1349.7029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8245206
Old  loss*** tensor(5037.3564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4153.4043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8325137
Old  loss*** tensor(2331.2500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1940.7975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862803
Old  loss*** tensor(1605.9495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1423.3214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8902305
Old  loss*** tensor(443.3458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(394.6799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7968346
Old  loss*** tensor(2703.9285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2154.5837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895511
Old  loss*** tensor(1082.9347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(969.7799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83779097
Old  loss*** tensor(2183.4575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1829.2810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8602277
Old  loss*** tensor(1390.0642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1195.7717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.880083
Old  loss*** tensor(2423.0383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.4749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.889025
Old  loss*** tensor(127.7738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(113.5941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89400244
Old  loss*** tensor(1012.2333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.9391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78686816
Old  loss*** tensor(4189.1509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3296.3093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82995844
Old  loss*** tensor(3130.5923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2598.2615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79506886
Old  loss*** tensor(2674.0471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2126.0515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767224
Old  loss*** tensor(542.1423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(475.3083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88049793
Old  loss*** tensor(1815.4514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.5012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85911083
Old  loss*** tensor(1887.3278, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1621.4237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8695346
Old  loss*** tensor(1016.4724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.8579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84404427
Old  loss*** tensor(1922.9730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1623.0743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89663637
Old  loss*** tensor(798.3152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(715.7985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84865105
Old  loss*** tensor(1829.9646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1553.0013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89632523
Old  loss*** tensor(422.5306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(378.7249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8485114
Old  loss*** tensor(2333.4937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1979.9960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88742363
Old  loss*** tensor(1572.1987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.2063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820801
Old  loss*** tensor(3736.9773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3296.3132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87476856
Old  loss*** tensor(834.0386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(729.5908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7280823
Old  loss*** tensor(3227.4565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2349.8540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88505924
Old  loss*** tensor(1041.8872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(922.1319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87203693
Old  loss*** tensor(1485.4363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1295.3553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8561516
Old  loss*** tensor(1630.7911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1396.2045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632922
Old  loss*** tensor(1851.6210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.4900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80870944
Old  loss*** tensor(4204.3022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3400.0588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563123
Old  loss*** tensor(1991.4812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1705.3298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8402573
Old  loss*** tensor(2091.3748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1757.2928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742059
Old  loss*** tensor(108.6688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(94.9989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699901
Old  loss*** tensor(1733.8203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1508.4065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8273456
Old  loss*** tensor(1439.2604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.7657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8397099
Old  loss*** tensor(3608.6902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3030.2527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86403763
Old  loss*** tensor(4074.8518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3520.8252, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682704
Old  loss*** tensor(1394.1321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1210.4836, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874532
Old  loss*** tensor(514.8452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(456.9010, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874832
Old  loss*** tensor(1003.0939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(877.5386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88785964
Old  loss*** tensor(1635.0020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1451.6522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7506335
Old  loss*** tensor(4062.8613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3049.7197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8652171
Old  loss*** tensor(1280.0654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1107.5345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87153506
Old  loss*** tensor(2186.7314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1905.8131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8434868
Old  loss*** tensor(2863.8638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2415.6313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824233
Old  loss*** tensor(1405.0129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1239.8162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82062805
Old  loss*** tensor(3052.0095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2504.5647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8465047
Old  loss*** tensor(3959.5977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3351.8179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7778543
Old  loss*** tensor(3097.4497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2409.3647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73085284
Old  loss*** tensor(4268.8965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3119.9351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7946347
Old  loss*** tensor(1090.1573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(866.2769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7438549
Old  loss*** tensor(5176.6304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3850.6619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528644
Old  loss*** tensor(2731.4084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2329.5210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78063107
Old  loss*** tensor(3176.5901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2479.7449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7768078
Old  loss*** tensor(4075.4768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3165.8621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8687487
Old  loss*** tensor(1523.3070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1323.3710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7793872
Old  loss*** tensor(4001.6848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.8618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8057851
Old  loss*** tensor(2743.1912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2210.4226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8266667
Old  loss*** tensor(2287.6047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1891.0867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88749504
Old  loss*** tensor(593.1360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(526.4053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9021101
Old  loss*** tensor(615.7662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.4889, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84524405
Old  loss*** tensor(2084.3877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.8163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7448125
Old  loss*** tensor(4234.5659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.9575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79880106
Old  loss*** tensor(2669.5703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.4556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9009265
Old  loss*** tensor(769.8186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(693.5500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91773343
Old  loss*** tensor(584.1551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(536.0986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539895
Old  loss*** tensor(1690.7255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.8618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8049723
Old  loss*** tensor(2756.3257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2218.7659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549824
Old  loss*** tensor(1387.6234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1186.3936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778667
Old  loss*** tensor(542.6907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(476.4101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87830055
Old  loss*** tensor(772.1926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.2172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8545337
Old  loss*** tensor(2946.8572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2518.1887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88404584
Old  loss*** tensor(1895.5447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1675.7484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759539
Old  loss*** tensor(711.1090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(622.8987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89390755
Old  loss*** tensor(268.1166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(239.6715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8304755
Old  loss*** tensor(4598.7241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3819.1277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8361966
Old  loss*** tensor(3581.4053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2994.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796779
Old  loss*** tensor(444.0357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.6084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665445
Old  loss*** tensor(2070.6602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1794.3191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80832565
Old  loss*** tensor(4112.0181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3323.8496, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88393784
Old  loss*** tensor(946.5379, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(836.6807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88937813
Old  loss*** tensor(988.6484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.2823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8864284
Old  loss*** tensor(731.9630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(648.8328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7863579
Old  loss*** tensor(3555.1921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2795.6533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8181911
Old  loss*** tensor(3502.9575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2866.0886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88300294
Old  loss*** tensor(1164.6886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1028.4235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81305504
Old  loss*** tensor(3913.2476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3181.6855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8089961
Old  loss*** tensor(3351.9980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2711.7532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87693787
Old  loss*** tensor(1200.9839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.1882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81786245
Old  loss*** tensor(4581.3311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3746.8987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347994
Old  loss*** tensor(2482.5259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2072.4111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82286376
Old  loss*** tensor(3664.0430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3015.0081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9091145
Old  loss*** tensor(943.3645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.6263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87221664
Old  loss*** tensor(1086.0748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(947.2925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87352705
Old  loss*** tensor(1190.5291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1039.9594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78099644
Old  loss*** tensor(4271.9077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3336.3447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660391
Old  loss*** tensor(1156.6721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.7233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84241664
Old  loss*** tensor(1191.5902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.8154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8975982
Old  loss*** tensor(706.3013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(633.9748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792407
Old  loss*** tensor(1358.0447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.0481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857553
Old  loss*** tensor(1951.6228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1673.6200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71415675
Old  loss*** tensor(5020.7827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.6257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8158298
Old  loss*** tensor(2921.9795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2383.8379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481029
Old  loss*** tensor(3482.7649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2953.7432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87456155
Old  loss*** tensor(1121.7157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.0094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540245
Old  loss*** tensor(2312.1958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1974.6719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281812
Old  loss*** tensor(1568.0021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.5898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88201153
Old  loss*** tensor(621.2662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(547.9640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87858856
Old  loss*** tensor(1401.0867, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1230.9788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85592467
Old  loss*** tensor(1840.0869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1574.9758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86186343
Old  loss*** tensor(1971.0518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1698.7775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7179593
Old  loss*** tensor(5155.0752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3701.1340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.866995
Old  loss*** tensor(1037.6373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.6263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89133584
Old  loss*** tensor(368.6841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(328.6213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7651429
Old  loss*** tensor(3508.5752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2684.5615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388711
Old  loss*** tensor(3071.8181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2576.8596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8275008
Old  loss*** tensor(4587.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3796.2312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88785625
Old  loss*** tensor(1316.2925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1168.6785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.901827
Old  loss*** tensor(1011.1246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.8595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81703293
Old  loss*** tensor(3384.9954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2765.6526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87099123
Old  loss*** tensor(1050.4093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(914.8973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298633
Old  loss*** tensor(2122.2122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.1460, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455962
Old  loss*** tensor(2497.0369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2111.4849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8019078
Old  loss*** tensor(2892.3735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2319.4167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8515057
Old  loss*** tensor(1757.1918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1496.2588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87401056
Old  loss*** tensor(1247.2900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1090.1447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7753775
Old  loss*** tensor(4230.4888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3280.2258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8753763
Old  loss*** tensor(1515.5360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1326.6643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84442663
Old  loss*** tensor(1879.4352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.0452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90465635
Old  loss*** tensor(222.4393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(201.2311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7961272
Old  loss*** tensor(1153.9531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(918.6935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81056833
Old  loss*** tensor(4422.8940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.0579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83961
Old  loss*** tensor(2951.6572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.2410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86544627
Old  loss*** tensor(1531.8871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1325.7660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8644701
Old  loss*** tensor(1274.2675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1101.5662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83142185
Old  loss*** tensor(2038.8176, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.1176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86176115
Old  loss*** tensor(2035.0349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.7140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872057
Old  loss*** tensor(943.5099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.7945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8625039
Old  loss*** tensor(2153.7300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1857.6005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9004168
Old  loss*** tensor(668.6465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.0605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84895813
Old  loss*** tensor(1328.3285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1127.6953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655441
Old  loss*** tensor(1684.1615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1457.7161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86645854
Old  loss*** tensor(3344.8926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2898.2107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87088555
Old  loss*** tensor(603.1075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(525.2376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90241265
Old  loss*** tensor(765.8017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(691.0692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89193475
Old  loss*** tensor(1518.9994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1354.8484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84083307
Old  loss*** tensor(2538.0549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2134.0806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.912356
Old  loss*** tensor(837.9928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(764.5478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82572925
Old  loss*** tensor(3461.9841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2858.6616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8630825
Old  loss*** tensor(1904.5564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1643.7893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8778312
Old  loss*** tensor(728.3165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.3390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87438977
Old  loss*** tensor(963.3286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(842.3247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85938096
Old  loss*** tensor(2664.2920, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2289.6418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.826806
Old  loss*** tensor(2786.1804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2303.6306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7680608
Old  loss*** tensor(4358.5708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3347.6475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804995
Old  loss*** tensor(136.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(120.3363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86053336
Old  loss*** tensor(1639.5592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.8954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8833782
Old  loss*** tensor(301.6041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(266.4305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9067232
Old  loss*** tensor(745.7012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(676.1446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8182672
Old  loss*** tensor(4218.9878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3452.2595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86334103
Old  loss*** tensor(2805.6099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2422.1980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7791784
Old  loss*** tensor(3856.6426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3005.0125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87697744
Old  loss*** tensor(1014.8409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(889.9926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8513489
Old  loss*** tensor(1895.6958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1613.8984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86398154
Old  loss*** tensor(3197.2837, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2762.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8276421
Old  loss*** tensor(2091.3438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1730.8842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9113616
Old  loss*** tensor(508.0084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.9793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83796597
Old  loss*** tensor(361.3739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(302.8190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759377
Old  loss*** tensor(1531.0115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1341.0707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83420277
Old  loss*** tensor(2325.3862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1939.8436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79031837
Old  loss*** tensor(3628.8635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2867.9575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81563336
Old  loss*** tensor(4849.5596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3955.4626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7813599
Old  loss*** tensor(2457.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1920.3234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8268808
Old  loss*** tensor(2418.3728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1999.7061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860046
Old  loss*** tensor(753.9265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(648.4115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77304816
Old  loss*** tensor(3152.4275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2436.9783, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87304413
Old  loss*** tensor(1077.1365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(940.3877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82288206
Old  loss*** tensor(2540.5957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2090.6106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9122611
Old  loss*** tensor(1696.3287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1547.4948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81105804
Old  loss*** tensor(3726.5583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3022.4551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802893
Old  loss*** tensor(447.7248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(394.1273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82314956
Old  loss*** tensor(3908.7954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3217.5232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79961216
Old  loss*** tensor(5327.9077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4260.2598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87696606
Old  loss*** tensor(1877.6989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1646.6782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85425895
Old  loss*** tensor(975.8008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(833.5865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89010954
Old  loss*** tensor(1225.5587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1090.8815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8530213
Old  loss*** tensor(1161.8483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(991.0814, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772937
Old  loss*** tensor(808.5683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(709.3519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79385173
Old  loss*** tensor(2893.6665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2297.1421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7855765
Old  loss*** tensor(3493.9119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2744.7351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88247013
Old  loss*** tensor(479.3894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(423.0468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426457
Old  loss*** tensor(3987.9543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3360.4326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78292024
Old  loss*** tensor(4060.8257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3179.3027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77592695
Old  loss*** tensor(4025.3049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3123.3425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739327
Old  loss*** tensor(968.6901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(846.5700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73493564
Old  loss*** tensor(3408.2673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2504.8572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7824024
Old  loss*** tensor(2529.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1979.1492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87677205
Old  loss*** tensor(1623.8121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1423.7131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87958896
Old  loss*** tensor(521.2017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(458.4432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480327
Old  loss*** tensor(2359.7349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2001.1323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663626
Old  loss*** tensor(928.2531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(804.2037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8139656
Old  loss*** tensor(1761.7533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1434.0066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87604666
Old  loss*** tensor(1482.9178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.1052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8789865
Old  loss*** tensor(1013.9553, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(891.2530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911494
Old  loss*** tensor(1649.5809, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1470.0231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8882948
Old  loss*** tensor(720.1644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.7183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87508774
Old  loss*** tensor(697.9675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(610.7828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399813
Old  loss*** tensor(1770.1105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1486.8597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85178494
Old  loss*** tensor(2046.5747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1743.2416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8478613
Old  loss*** tensor(1951.5908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1654.6783, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88179696
Old  loss*** tensor(946.4767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.6003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85518885
Old  loss*** tensor(1654.4855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.8976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.884367
Old  loss*** tensor(1116.9667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(987.8085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72132254
Old  loss*** tensor(5138.3828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3706.4314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85055643
Old  loss*** tensor(4466.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3798.7222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796083
Old  loss*** tensor(1008.3986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.9957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83153796
Old  loss*** tensor(1962.0427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1631.5131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82740265
Old  loss*** tensor(2424.9509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.4108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87824386
Old  loss*** tensor(631.5338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.6407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732443
Old  loss*** tensor(1250.9243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1092.3625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8681015
Old  loss*** tensor(1149.6871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(998.0451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8981248
Old  loss*** tensor(1263.9041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1135.1436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9073671
Old  loss*** tensor(612.4616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.7275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8473227
Old  loss*** tensor(2532.8354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2146.1289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85773444
Old  loss*** tensor(2262.6912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1940.7881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.92911005
Old  loss*** tensor(686.7791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(638.0934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8307429
Old  loss*** tensor(4155.1528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3451.8638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939545
Old  loss*** tensor(492.7810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(440.5238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87025106
Old  loss*** tensor(122.8194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(106.8837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86136556
Old  loss*** tensor(1965.1305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1692.6957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.876883
Old  loss*** tensor(627.9872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(550.6713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81720126
Old  loss*** tensor(3976.3645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3249.4900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78576744
Old  loss*** tensor(2801.6943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2201.4802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563193
Old  loss*** tensor(3027.8042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2592.7671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764938
Old  loss*** tensor(1407.7896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.9188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728832
Old  loss*** tensor(2624.5393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.9163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855869
Old  loss*** tensor(797.8447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.5608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8526242
Old  loss*** tensor(2975.9714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2537.3853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7620592
Old  loss*** tensor(4724.7817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3600.5635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79560256
Old  loss*** tensor(4095.6765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3258.5308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542644
Old  loss*** tensor(2879.9326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2460.2239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885906
Old  loss*** tensor(1369.1129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.5808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83327645
Old  loss*** tensor(1642.8107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1368.9154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911741
Old  loss*** tensor(974.6931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.6212, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88994014
Old  loss*** tensor(449.5241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(400.0496, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8532356
Old  loss*** tensor(1178.7417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.7444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678344
Old  loss*** tensor(1423.1061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1235.0204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8583616
Old  loss*** tensor(2695.8611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2314.0237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732908
Old  loss*** tensor(1921.4186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.9572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8845568
Old  loss*** tensor(300.4767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(265.7887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922781
Old  loss*** tensor(456.9895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(407.7617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660015
Old  loss*** tensor(1221.4056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.7391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7936117
Old  loss*** tensor(4230.0439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3357.0125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.813051
Old  loss*** tensor(3116.5493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.9136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7343513
Old  loss*** tensor(4149.0513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3046.8611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85220635
Old  loss*** tensor(2367.4541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2017.5594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88178086
Old  loss*** tensor(2021.4973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1782.5177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7949512
Old  loss*** tensor(3187.2087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.6753, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90915656
Old  loss*** tensor(1174.6744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1067.9630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7993683
Old  loss*** tensor(3505.2864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2802.0149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9009297
Old  loss*** tensor(1589.7516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1432.2544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908349
Old  loss*** tensor(1775.2917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1581.4919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597021
Old  loss*** tensor(2406.4568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2068.8359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859657
Old  loss*** tensor(1352.5737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1198.3340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8607389
Old  loss*** tensor(944.0567, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.5863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115672
Old  loss*** tensor(2860.0994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2321.1628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8538711
Old  loss*** tensor(4269.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3645.9822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84949005
Old  loss*** tensor(2904.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2467.6504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540311
Old  loss*** tensor(1191.3549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.4541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7719499
Old  loss*** tensor(2880.0840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2223.2805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82520574
Old  loss*** tensor(2423.3232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1999.7402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88845855
Old  loss*** tensor(1310.4742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1164.3020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82268095
Old  loss*** tensor(2241.3174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1843.8892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8694169
Old  loss*** tensor(1706.2662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1483.4567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89958304
Old  loss*** tensor(1023.6155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(920.8271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7624065
Old  loss*** tensor(4932.1646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3760.3145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83359605
Old  loss*** tensor(2064.3835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.8619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7581556
Old  loss*** tensor(3344.6609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2535.7734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82248354
Old  loss*** tensor(2919.2100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2401.0022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9038908
Old  loss*** tensor(1626.4521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1470.1351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617035
Old  loss*** tensor(946.6539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(815.7350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867656
Old  loss*** tensor(324.4029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(287.6693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.833102
Old  loss*** tensor(2491.3687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.5642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8589114
Old  loss*** tensor(1683.9912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.3993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8142968
Old  loss*** tensor(3998.7314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3256.1541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.791456
Old  loss*** tensor(4341.7886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3436.3345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78276014
Old  loss*** tensor(3670.9209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2873.4507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663944
Old  loss*** tensor(1715.6285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1486.4110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88611704
Old  loss*** tensor(428.3981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.6109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88238513
Old  loss*** tensor(588.6450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.4116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8424457
Old  loss*** tensor(3292.2922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2773.5774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7837815
Old  loss*** tensor(3982.1890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3121.1663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84586823
Old  loss*** tensor(3506.9121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2966.3855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7616216
Old  loss*** tensor(4996.4238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3805.3843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88371384
Old  loss*** tensor(1490.2666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.9692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81884325
Old  loss*** tensor(3964.9810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3246.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763864
Old  loss*** tensor(713.4649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.2709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91216195
Old  loss*** tensor(967.1109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(882.1617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81143403
Old  loss*** tensor(3147.2239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2553.7646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86915624
Old  loss*** tensor(1697.4471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1475.3468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88117063
Old  loss*** tensor(802.7242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(707.3370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8190986
Old  loss*** tensor(2673.2209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2189.6316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7890802
Old  loss*** tensor(4012.7168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3166.3555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87668717
Old  loss*** tensor(870.6731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(763.3079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86673236
Old  loss*** tensor(2641.4338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2289.4163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81342137
Old  loss*** tensor(1691.6825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1376.0507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8584258
Old  loss*** tensor(1137.8794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(976.7850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451975
Old  loss*** tensor(467.7090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(395.3065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8238871
Old  loss*** tensor(4243.9971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3496.5745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74128985
Old  loss*** tensor(4748.0522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.6829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610976
Old  loss*** tensor(2543.8748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2190.5244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560869
Old  loss*** tensor(1678.4951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.9377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8411058
Old  loss*** tensor(2574.5676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2165.4839, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908614
Old  loss*** tensor(321.9797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(286.8393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84815264
Old  loss*** tensor(3669.1274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3111.9802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7846737
Old  loss*** tensor(3014.2065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2365.1685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89216673
Old  loss*** tensor(1151.9680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1027.7476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88626087
Old  loss*** tensor(1559.4048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1382.0394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597189
Old  loss*** tensor(1068.5347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(918.6395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86976206
Old  loss*** tensor(1056.6644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.0466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82248235
Old  loss*** tensor(2767.2310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2275.9985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865341
Old  loss*** tensor(1600.4557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1384.9399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85978174
Old  loss*** tensor(2304.7141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1981.5511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85270953
Old  loss*** tensor(2002.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1707.3654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82905716
Old  loss*** tensor(4052.6343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3359.8655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867687
Old  loss*** tensor(424.6756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(376.5890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81008065
Old  loss*** tensor(3673.4053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2975.7546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87329024
Old  loss*** tensor(2200.8687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1921.9971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7223717
Old  loss*** tensor(2838.4858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2050.4419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8355609
Old  loss*** tensor(2136.6738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1785.3212, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8406849
Old  loss*** tensor(1443.4723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.5054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80557823
Old  loss*** tensor(3627.6309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2922.3403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88162196
Old  loss*** tensor(481.9823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(424.9262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677688
Old  loss*** tensor(1388.7025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1205.0728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7998998
Old  loss*** tensor(3458.6953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2766.6099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82579
Old  loss*** tensor(2522.2517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2082.8501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85771906
Old  loss*** tensor(2741.3296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2351.2905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86982435
Old  loss*** tensor(1265.2671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1100.5602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85594046
Old  loss*** tensor(2449.4983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2096.6248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084274
Old  loss*** tensor(2974.3271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.5276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8944183
Old  loss*** tensor(758.5256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.4391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.856918
Old  loss*** tensor(1567.8541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1343.5223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83159804
Old  loss*** tensor(2117.9316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.2678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886641
Old  loss*** tensor(538.5562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(477.5060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881285
Old  loss*** tensor(952.0988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.0704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337578
Old  loss*** tensor(4037.8337, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3366.5754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586244
Old  loss*** tensor(2834.6941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2433.9375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85425675
Old  loss*** tensor(1753.4198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1497.8707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83995074
Old  loss*** tensor(2982.8591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2505.4548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127075
Old  loss*** tensor(4195.3955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3409.6294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89008605
Old  loss*** tensor(580.0296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(516.2762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72619814
Old  loss*** tensor(5397.0664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3919.3396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806783
Old  loss*** tensor(730.2861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(643.1472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84590364
Old  loss*** tensor(1698.8269, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1437.0438, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939396
Old  loss*** tensor(961.9518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(859.9269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9273633
Old  loss*** tensor(892.2681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(827.4567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86167777
Old  loss*** tensor(1389.3086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.1364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88534427
Old  loss*** tensor(1043.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(923.9272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88296664
Old  loss*** tensor(567.0777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.7107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81109387
Old  loss*** tensor(2701.0317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2190.7903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8894707
Old  loss*** tensor(922.8594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(820.8564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646356
Old  loss*** tensor(1178.7333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.1747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90115905
Old  loss*** tensor(1975.8672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1780.5706, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8921628
Old  loss*** tensor(1279.4326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1141.4622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88403565
Old  loss*** tensor(946.1281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(836.4109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7734663
Old  loss*** tensor(4717.3970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3648.7476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83972025
Old  loss*** tensor(1457.6718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1224.0365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8934079
Old  loss*** tensor(574.8961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(513.6167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76678705
Old  loss*** tensor(5506.6177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4222.4033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618791
Old  loss*** tensor(4182.1113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3604.4744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82994086
Old  loss*** tensor(3006.8293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2495.4905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608519
Old  loss*** tensor(913.5812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.4581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81436646
Old  loss*** tensor(3220.7544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2622.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91584826
Old  loss*** tensor(568.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.7384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9010014
Old  loss*** tensor(1165.0016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.6681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483647
Old  loss*** tensor(1881.1133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1595.8701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741719
Old  loss*** tensor(402.7936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(352.1109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850633
Old  loss*** tensor(1368.8521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1211.5208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83799374
Old  loss*** tensor(2197.1926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1841.2336, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7986183
Old  loss*** tensor(4711.6602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3762.8181, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873041
Old  loss*** tensor(1994.8263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1770.0176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84937096
Old  loss*** tensor(2971.5955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2523.9868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76468253
Old  loss*** tensor(3220.5969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2462.7341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84344715
Old  loss*** tensor(2513.1602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2119.7178, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8554405
Old  loss*** tensor(939.4048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.6049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87042993
Old  loss*** tensor(1450.8291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1262.8451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8104564
Old  loss*** tensor(949.3110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(769.3752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7399559
Old  loss*** tensor(3883.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2873.7917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502172
Old  loss*** tensor(1698.8884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1444.4242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88339657
Old  loss*** tensor(244.9633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(216.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85083145
Old  loss*** tensor(2039.2465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1735.0551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7934463
Old  loss*** tensor(4207.5830, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3338.4912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89784515
Old  loss*** tensor(725.8536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(651.7042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7578384
Old  loss*** tensor(3452.6040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2616.5159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88060665
Old  loss*** tensor(73.5174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(64.7399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8730114
Old  loss*** tensor(1351.4918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1179.8678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75479877
Old  loss*** tensor(4012.8647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3028.9053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426204
Old  loss*** tensor(1835.1450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1546.3306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631494
Old  loss*** tensor(1764.5719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1523.0892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481577
Old  loss*** tensor(1601.1145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.9976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9167072
Old  loss*** tensor(1691.8783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1550.9570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87815964
Old  loss*** tensor(1162.3060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.6902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704039
Old  loss*** tensor(1639.9774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1427.4427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781071
Old  loss*** tensor(227.2440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(199.5446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7951669
Old  loss*** tensor(4150.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3300.4087, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84496653
Old  loss*** tensor(3772.8701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3187.9490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89613914
Old  loss*** tensor(2297.9802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.3101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84403116
Old  loss*** tensor(2187.1858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1846.0530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8016706
Old  loss*** tensor(1301.3907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1043.2867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80944943
Old  loss*** tensor(1321.1992, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1069.4440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80178106
Old  loss*** tensor(2219.3521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1779.4344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900558
Old  loss*** tensor(1104.4745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(983.0439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703662
Old  loss*** tensor(777.0231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(676.2947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85859156
Old  loss*** tensor(1859.2109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1596.3029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89321136
Old  loss*** tensor(264.1685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(235.9583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9000336
Old  loss*** tensor(815.4661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(733.9469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86915016
Old  loss*** tensor(648.7042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(563.8214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848281
Old  loss*** tensor(1740.0150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1539.6141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89277935
Old  loss*** tensor(489.3468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(436.8787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8123289
Old  loss*** tensor(2484.8457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2018.5120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89512014
Old  loss*** tensor(1313.8210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1176.0277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.6899066
Old  loss*** tensor(5456.8105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3764.6897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83059835
Old  loss*** tensor(2968.8076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2465.8867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849387
Old  loss*** tensor(1034.8220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(915.7541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7728114
Old  loss*** tensor(4268.3115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3298.5999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87618697
Old  loss*** tensor(1462.3619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1281.3025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7622248
Old  loss*** tensor(4126.5166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3145.3333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89276206
Old  loss*** tensor(791.0021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.1767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80617595
Old  loss*** tensor(5041.9658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4064.7117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83807373
Old  loss*** tensor(3066.5879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2570.0269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90727437
Old  loss*** tensor(644.3504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(584.6026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77550906
Old  loss*** tensor(4159.3101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3225.5825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81090033
Old  loss*** tensor(2902.1116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2353.3232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8702177
Old  loss*** tensor(975.8237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.1790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84981406
Old  loss*** tensor(1374.9828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1168.4797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786503
Old  loss*** tensor(982.3101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(863.1071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79364777
Old  loss*** tensor(3551.0310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2818.2678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84351665
Old  loss*** tensor(1961.0188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1654.1520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728608
Old  loss*** tensor(966.8833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(843.9545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8379011
Old  loss*** tensor(2277.8054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1908.5757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9124947
Old  loss*** tensor(750.7688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(685.0726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86198527
Old  loss*** tensor(1252.3195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.4810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8042298
Old  loss*** tensor(5088.4087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4092.2500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885576
Old  loss*** tensor(1491.0444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1320.4332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8734968
Old  loss*** tensor(1817.3224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.4253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81793547
Old  loss*** tensor(2549.0430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2084.9526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675753
Old  loss*** tensor(1543.9624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1339.5037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8330219
Old  loss*** tensor(3503.6157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2918.5886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869568
Old  loss*** tensor(1695.6335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.4686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82750976
Old  loss*** tensor(1888.1804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.4877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81895864
Old  loss*** tensor(2558.0872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.9675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8715833
Old  loss*** tensor(1309.8710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1141.6616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87353957
Old  loss*** tensor(1111.4421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(970.8887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87413573
Old  loss*** tensor(2915.2334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2548.3096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89739037
Old  loss*** tensor(1237.7302, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1110.7272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80046326
Old  loss*** tensor(3390.2334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2713.7573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8474924
Old  loss*** tensor(2840.5371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2407.3335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85718375
Old  loss*** tensor(1321.1758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1132.4904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8344235
Old  loss*** tensor(2691.0068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2245.4392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8168082
Old  loss*** tensor(700.0898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.8391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87753
Old  loss*** tensor(1500.0544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.3428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85879016
Old  loss*** tensor(2662.0916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2286.1780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86547244
Old  loss*** tensor(3832.0642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3316.5459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88975304
Old  loss*** tensor(515.3719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(458.5537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.880297
Old  loss*** tensor(1103.6605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(971.5491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79096377
Old  loss*** tensor(4349.5142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3440.3081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839603
Old  loss*** tensor(550.0121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(486.1888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82761884
Old  loss*** tensor(3203.5979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2651.3579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7940017
Old  loss*** tensor(4111.7163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3264.7097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86425686
Old  loss*** tensor(1780.2258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1538.5724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8920411
Old  loss*** tensor(935.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.4561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83718777
Old  loss*** tensor(2024.7554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.1005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88616884
Old  loss*** tensor(457.5399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.4576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8230083
Old  loss*** tensor(3519.9673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2896.9624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613059
Old  loss*** tensor(1921.9227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.3634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8170286
Old  loss*** tensor(4229.4492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3455.5808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88768655
Old  loss*** tensor(1058.7004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(939.7941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87531585
Old  loss*** tensor(117.3904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(102.7536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8723707
Old  loss*** tensor(962.2972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.4799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88228154
Old  loss*** tensor(3061.3120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2700.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86096555
Old  loss*** tensor(2263.2668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1948.5947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82682943
Old  loss*** tensor(2469.4419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2041.8073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7996921
Old  loss*** tensor(4369.6104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3494.3428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8743539
Old  loss*** tensor(420.6702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(367.8146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738556
Old  loss*** tensor(2442.0144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2133.9680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863334
Old  loss*** tensor(1435.1689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1239.0302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.841272
Old  loss*** tensor(3256.5356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.6323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680205
Old  loss*** tensor(908.3590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(788.4742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88663316
Old  loss*** tensor(1048.8422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.9382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81021166
Old  loss*** tensor(4451.0098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3606.2600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747623
Old  loss*** tensor(1305.2400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1141.7748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8623098
Old  loss*** tensor(1148.1029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(990.0204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75424343
Old  loss*** tensor(4677.7466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3528.1597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756236
Old  loss*** tensor(745.5034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.7804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85991704
Old  loss*** tensor(1930.2446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.8502, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8477007
Old  loss*** tensor(1758.9165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1491.0348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87744105
Old  loss*** tensor(632.4849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.9683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82537407
Old  loss*** tensor(2835.2007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2340.1011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7983286
Old  loss*** tensor(3123.5181, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2493.5938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84682214
Old  loss*** tensor(1496.6189, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.3700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634752
Old  loss*** tensor(987.1707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(852.3974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79974097
Old  loss*** tensor(3787.6543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3029.1423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86722654
Old  loss*** tensor(1887.3365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1636.7483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81159985
Old  loss*** tensor(3446.9043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2797.5071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84475935
Old  loss*** tensor(3146.3748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2657.9294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7643132
Old  loss*** tensor(5066.7671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3872.5972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8229244
Old  loss*** tensor(2196.5110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1807.5624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.727
Old  loss*** tensor(4052.3281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2946.0425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8898696
Old  loss*** tensor(1293.7742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1151.2903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559166
Old  loss*** tensor(2322.4670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1987.8381, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81013155
Old  loss*** tensor(2058.4395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1667.6067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8179914
Old  loss*** tensor(2813.2590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2301.2217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8140979
Old  loss*** tensor(3889.2988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3166.2700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.766869
Old  loss*** tensor(3446.3738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2642.9172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88180727
Old  loss*** tensor(1167.0385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1029.1030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83093977
Old  loss*** tensor(4028.3235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3347.2942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549515
Old  loss*** tensor(994.2933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.0725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519584
Old  loss*** tensor(2695.3467, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2296.3232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563458
Old  loss*** tensor(2189.3928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1874.8773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812207
Old  loss*** tensor(531.9847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(468.7959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84370875
Old  loss*** tensor(2125.8230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1793.5754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75584066
Old  loss*** tensor(4959.9546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3748.9353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9040345
Old  loss*** tensor(1226.3076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1108.6244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90497994
Old  loss*** tensor(438.7180, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(397.0310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89170265
Old  loss*** tensor(1345.9426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.1807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86702216
Old  loss*** tensor(1977.0352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1714.1333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8948426
Old  loss*** tensor(618.7346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(553.6701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7884518
Old  loss*** tensor(3914.4197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3086.3313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608599
Old  loss*** tensor(2046.6031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.8385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76800716
Old  loss*** tensor(3748.2964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2878.7185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779031
Old  loss*** tensor(932.0662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.2639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8472754
Old  loss*** tensor(2460.4321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2084.6636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89769167
Old  loss*** tensor(771.1248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.2323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9058341
Old  loss*** tensor(806.4374, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(730.4985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86777127
Old  loss*** tensor(1415.0404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.9314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8296386
Old  loss*** tensor(2696.2690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2236.9290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616239
Old  loss*** tensor(1323.5153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1140.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618673
Old  loss*** tensor(1557.3741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1342.2499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86421186
Old  loss*** tensor(2842.2468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2456.3035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89727986
Old  loss*** tensor(511.5644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(459.0164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617661
Old  loss*** tensor(1859.8461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1602.7523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85966086
Old  loss*** tensor(2193.4805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.6493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8169894
Old  loss*** tensor(3175.1279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2594.0459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76088655
Old  loss*** tensor(4704.1104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3579.2942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680867
Old  loss*** tensor(1190.4204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.3881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735785
Old  loss*** tensor(1684.8114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1471.8149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7617566
Old  loss*** tensor(3683.6646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2806.0557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634441
Old  loss*** tensor(342.7511, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(295.9464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8245724
Old  loss*** tensor(1817.1494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1498.3712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803824
Old  loss*** tensor(633.1313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(557.3976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8469743
Old  loss*** tensor(1516.8723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1284.7518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86412764
Old  loss*** tensor(780.2103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.2013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.6879687
Old  loss*** tensor(5051.9785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3475.6030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86127377
Old  loss*** tensor(1171.0042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1008.5552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77170044
Old  loss*** tensor(2847.9556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2197.7686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650632
Old  loss*** tensor(3946.6255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3414.0803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820096
Old  loss*** tensor(763.0441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(673.0123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87894505
Old  loss*** tensor(220.7137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(193.9952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81909716
Old  loss*** tensor(3679.4165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3013.7996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89062095
Old  loss*** tensor(856.5450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(762.8569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7897492
Old  loss*** tensor(2011.5066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8978038
Old  loss*** tensor(397.1325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(356.5471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8120955
Old  loss*** tensor(2302.0833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1869.5115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85765314
Old  loss*** tensor(1607.5138, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1378.6892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83069456
Old  loss*** tensor(2578.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.9009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89140975
Old  loss*** tensor(801.9053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(714.8262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8561425
Old  loss*** tensor(1661.7427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1422.6886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88811326
Old  loss*** tensor(1697.3983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.4819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80087304
Old  loss*** tensor(4317.1909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3457.5217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.822049
Old  loss*** tensor(1815.5664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1492.4846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85338795
Old  loss*** tensor(1972.4053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1683.2269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732995
Old  loss*** tensor(2343.5500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2046.6211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660413
Old  loss*** tensor(1916.0208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.3531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7686213
Old  loss*** tensor(4399.6357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3381.6538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87436366
Old  loss*** tensor(1064.9722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(931.1730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8044865
Old  loss*** tensor(4348.3369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3498.1785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84068334
Old  loss*** tensor(2649.0620, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2227.0222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8588401
Old  loss*** tensor(2009.6162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1725.9390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87039745
Old  loss*** tensor(470.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(409.9088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78251064
Old  loss*** tensor(3046.2939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2383.7573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8646228
Old  loss*** tensor(1442.6268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.3280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8216058
Old  loss*** tensor(2379.7288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1955.1990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860984
Old  loss*** tensor(119.7620, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(106.1209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780215
Old  loss*** tensor(1038.3177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.6653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86395323
Old  loss*** tensor(337.5945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(291.6658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86879253
Old  loss*** tensor(2324.1907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2019.2395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75531995
Old  loss*** tensor(3900.6047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2946.2046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82883036
Old  loss*** tensor(2297.9290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.5933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697344
Old  loss*** tensor(1248.9963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1086.2950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85932183
Old  loss*** tensor(734.5571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(631.2209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8416873
Old  loss*** tensor(4182.3076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3520.1953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653972
Old  loss*** tensor(1808.5549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1565.1184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82569134
Old  loss*** tensor(3212.8745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2652.8428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87447745
Old  loss*** tensor(884.2788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(773.2819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8695855
Old  loss*** tensor(3645.1533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3169.7725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8892392
Old  loss*** tensor(431.9627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(384.1182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653067
Old  loss*** tensor(1284.2397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.2612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87907106
Old  loss*** tensor(1099.7661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(966.7726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750011
Old  loss*** tensor(643.2996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(562.8879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770219
Old  loss*** tensor(898.5521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(788.0499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8960636
Old  loss*** tensor(1019.9507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.9407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.884655
Old  loss*** tensor(1214.3339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1074.2665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84087634
Old  loss*** tensor(4327.4160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3638.8218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86552143
Old  loss*** tensor(1167.8019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1010.7576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78718233
Old  loss*** tensor(5042.6865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3969.5137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874529
Old  loss*** tensor(477.1283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(417.2625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8052633
Old  loss*** tensor(4671.4771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3761.7690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663368
Old  loss*** tensor(838.9128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(726.7810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618541
Old  loss*** tensor(2097.1145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1807.4067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8399817
Old  loss*** tensor(1678.9221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.2638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779486
Old  loss*** tensor(862.1961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(756.9639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86992025
Old  loss*** tensor(2558.3364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2225.5486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8334676
Old  loss*** tensor(2482.5513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.1260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87137127
Old  loss*** tensor(693.6967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(604.4674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735038
Old  loss*** tensor(1353.1335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1181.9673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851842
Old  loss*** tensor(1285.0763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1137.5293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86959606
Old  loss*** tensor(3531.4314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3070.9189, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815038
Old  loss*** tensor(476.7794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(420.2829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87864935
Old  loss*** tensor(859.6984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(755.3735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87629986
Old  loss*** tensor(2979.5854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2611.0103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9015561
Old  loss*** tensor(1204.3701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.8073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297492
Old  loss*** tensor(2491.3103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2067.1628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421178
Old  loss*** tensor(3828.5574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3224.0962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81288934
Old  loss*** tensor(2832.8840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2302.8213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85275835
Old  loss*** tensor(1794.0977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.9318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744869
Old  loss*** tensor(1146.5283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.6240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873894
Old  loss*** tensor(114.8529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(101.9193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7412126
Old  loss*** tensor(5396.1646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3999.7051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87369084
Old  loss*** tensor(712.1981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(622.2409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506068
Old  loss*** tensor(3538.4871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3009.8611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704624
Old  loss*** tensor(998.0715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.7837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78043085
Old  loss*** tensor(2713.4954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2117.6956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8605184
Old  loss*** tensor(1257.7993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1082.3595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924373
Old  loss*** tensor(1288.1296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.5750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.859903
Old  loss*** tensor(1772.1831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1523.9055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7554315
Old  loss*** tensor(3507.8948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2649.9741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552276
Old  loss*** tensor(1494.3881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1278.0419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89123297
Old  loss*** tensor(372.5815, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(332.0569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82047725
Old  loss*** tensor(2065.5757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.7578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655088
Old  loss*** tensor(1104.9143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(956.3130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8564239
Old  loss*** tensor(1885.8632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1615.0983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88833666
Old  loss*** tensor(2403.8479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2135.4263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88393193
Old  loss*** tensor(974.3535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(861.2622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72406363
Old  loss*** tensor(4804.3066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3478.6238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87917876
Old  loss*** tensor(912.7266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.4498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78509736
Old  loss*** tensor(3441.3860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2701.8230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083391
Old  loss*** tensor(2542.2952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.0366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853854
Old  loss*** tensor(2095.8594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1855.6433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87879455
Old  loss*** tensor(1501.0941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1319.1533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74622333
Old  loss*** tensor(4522.7017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3374.9456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802076
Old  loss*** tensor(954.9647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(840.5671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81913865
Old  loss*** tensor(2280.7810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1868.2759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528575
Old  loss*** tensor(2014.3392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1717.9442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9026968
Old  loss*** tensor(479.2711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(432.6365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689809
Old  loss*** tensor(642.4410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(558.2689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8465433
Old  loss*** tensor(1450.3105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1227.7507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86799246
Old  loss*** tensor(1217.7979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.0393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87090504
Old  loss*** tensor(1402.5402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1221.4792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439044
Old  loss*** tensor(2027.5006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.0166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883742
Old  loss*** tensor(496.2643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(440.8683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884194
Old  loss*** tensor(653.5916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(580.6634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8395981
Old  loss*** tensor(4349.7422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3652.0354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79942906
Old  loss*** tensor(2600.9172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2079.2488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337115
Old  loss*** tensor(3651.1931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3044.0417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79943174
Old  loss*** tensor(4269.7134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3413.3445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8215418
Old  loss*** tensor(4210.2769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3458.9185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7675515
Old  loss*** tensor(3176.4587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2438.0957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7568538
Old  loss*** tensor(5220.6113, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3951.2395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8066244
Old  loss*** tensor(3530.4873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2847.7773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8896446
Old  loss*** tensor(1756.5538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.7086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8686776
Old  loss*** tensor(1482.4335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1287.7567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8172059
Old  loss*** tensor(3027.3159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2473.9404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9024044
Old  loss*** tensor(1540.3636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1390.0310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8378592
Old  loss*** tensor(2500.0605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.6987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.891044
Old  loss*** tensor(750.2470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.5031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880062
Old  loss*** tensor(1035.2932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.3468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410462
Old  loss*** tensor(2416.3035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2032.2229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82546496
Old  loss*** tensor(3673.4065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3032.2683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84490955
Old  loss*** tensor(702.6548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(593.6797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.851458
Old  loss*** tensor(1613.9941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.2483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79627836
Old  loss*** tensor(2593.8611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2065.4355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8325347
Old  loss*** tensor(2852.8750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.1174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865156
Old  loss*** tensor(815.1084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(705.1959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8955156
Old  loss*** tensor(718.5844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(643.5035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83382595
Old  loss*** tensor(2002.3080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1669.5763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618623
Old  loss*** tensor(1838.4144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.4601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8888118
Old  loss*** tensor(157.5497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(140.0320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86546814
Old  loss*** tensor(1693.7802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.9127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8592783
Old  loss*** tensor(1723.1613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1480.6752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87216055
Old  loss*** tensor(1737.2538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.1642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80630714
Old  loss*** tensor(3041.4834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2452.3699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557975
Old  loss*** tensor(1181.2472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1010.9084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8898833
Old  loss*** tensor(1101.4933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(980.2004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82929206
Old  loss*** tensor(3355.9006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2783.0217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75756073
Old  loss*** tensor(4186.7871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3171.7456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908216
Old  loss*** tensor(279.8683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(249.3128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83217835
Old  loss*** tensor(4001.4399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3329.9116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7714503
Old  loss*** tensor(3849.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2969.4609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85578746
Old  loss*** tensor(1539.9445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.8651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8433099
Old  loss*** tensor(2083.1160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1756.7123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82126534
Old  loss*** tensor(2160.7539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1774.5522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84747463
Old  loss*** tensor(1832.5591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1553.0474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.846424
Old  loss*** tensor(3425.3796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2899.3235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82399005
Old  loss*** tensor(2534.7676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2088.6233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542691
Old  loss*** tensor(1080.9946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(923.4603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7787561
Old  loss*** tensor(3340.0496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2601.0840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.902704
Old  loss*** tensor(919.3599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(829.9099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80676174
Old  loss*** tensor(2337.5925, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.8802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8972325
Old  loss*** tensor(1415.2430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1269.8020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84556997
Old  loss*** tensor(1152.8114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.7827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7647692
Old  loss*** tensor(4087.1360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3125.7158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88748455
Old  loss*** tensor(1963.5436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1742.6146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442323
Old  loss*** tensor(2260.1475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1908.0895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85093015
Old  loss*** tensor(1417.6234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.2985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672326
Old  loss*** tensor(4327.4126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3752.8733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812791
Old  loss*** tensor(607.6218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(535.4844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81294847
Old  loss*** tensor(3495.6929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2841.8181, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84386283
Old  loss*** tensor(1619.5054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1366.6404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8324317
Old  loss*** tensor(1600.4606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1332.2740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90237445
Old  loss*** tensor(1098.0813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(990.8805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671163
Old  loss*** tensor(798.1195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.0624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359805
Old  loss*** tensor(1432.0737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.1857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86403215
Old  loss*** tensor(2231.0854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1927.7296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83149725
Old  loss*** tensor(1403.4280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.9465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8444701
Old  loss*** tensor(2580.1448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2178.8550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744246
Old  loss*** tensor(528.8325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.4241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.814288
Old  loss*** tensor(4003.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3260.1389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88699764
Old  loss*** tensor(335.9207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(297.9609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762662
Old  loss*** tensor(891.3232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(781.0364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87089866
Old  loss*** tensor(1957.9539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1705.1794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85907876
Old  loss*** tensor(2373.2539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.8120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89606786
Old  loss*** tensor(756.8438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.1834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86861056
Old  loss*** tensor(1289.9767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1120.4874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90062845
Old  loss*** tensor(1302.5114, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1173.0787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78412145
Old  loss*** tensor(4606.0791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3611.7253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8395807
Old  loss*** tensor(1321.5918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1109.5830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84212774
Old  loss*** tensor(1953.4873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1645.0858, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8015261
Old  loss*** tensor(2804.1875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2247.6296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847321
Old  loss*** tensor(4256.8740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3606.9387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88601875
Old  loss*** tensor(552.5410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.5617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822284
Old  loss*** tensor(1750.6610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1544.4828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8593318
Old  loss*** tensor(755.9037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.5721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8987545
Old  loss*** tensor(488.2337, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(438.8022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359813
Old  loss*** tensor(2507.2212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2095.9900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88325596
Old  loss*** tensor(87.7091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(77.4696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8593204
Old  loss*** tensor(1226.0054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.5314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7794008
Old  loss*** tensor(2555.1257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1991.4672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8566971
Old  loss*** tensor(1665.3566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1426.7061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83840376
Old  loss*** tensor(2651.5334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2223.0557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86901206
Old  loss*** tensor(994.0246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(863.8193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87451994
Old  loss*** tensor(1211.8743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.8082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86041504
Old  loss*** tensor(2825.8936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2431.4414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8694271
Old  loss*** tensor(3829.1331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3329.1521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8109416
Old  loss*** tensor(3641.7095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2953.2136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8643527
Old  loss*** tensor(1644.3909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1421.3337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8810469
Old  loss*** tensor(1555.1531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1370.1628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8199931
Old  loss*** tensor(2637.0686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2162.3779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8420994
Old  loss*** tensor(2309.8708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1945.1409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85706747
Old  loss*** tensor(1613.8328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1383.1636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298898
Old  loss*** tensor(3106.4531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2578.0137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9111851
Old  loss*** tensor(1045.1195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(952.2973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79761124
Old  loss*** tensor(4117.8638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3284.4543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9032378
Old  loss*** tensor(359.2018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(324.4446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87418216
Old  loss*** tensor(2076.9839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1815.6622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82123613
Old  loss*** tensor(3619.0898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2972.1274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162985
Old  loss*** tensor(3103.0195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2532.9902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8331512
Old  loss*** tensor(3568.8943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2973.4287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162025
Old  loss*** tensor(3304.5208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2697.1582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78595626
Old  loss*** tensor(3069.8008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2412.7292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87856627
Old  loss*** tensor(720.7298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(633.2089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7639812
Old  loss*** tensor(4266.4961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3259.5229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75688446
Old  loss*** tensor(4589.3296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3473.5923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88214815
Old  loss*** tensor(587.0973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(517.9068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89223886
Old  loss*** tensor(935.7207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.8864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7829442
Old  loss*** tensor(2809.8665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2199.9688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877499
Old  loss*** tensor(716.1237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(628.3978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8789908
Old  loss*** tensor(3065.5686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2694.6067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622164
Old  loss*** tensor(115.7089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(99.7661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8725195
Old  loss*** tensor(3082.7390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2689.7500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604786
Old  loss*** tensor(1408.0983, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1211.6384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87998366
Old  loss*** tensor(1193.0897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.8994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8870274
Old  loss*** tensor(1445.4515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1282.1552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86271536
Old  loss*** tensor(1293.4471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1115.8767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512708
Old  loss*** tensor(3777.3171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3215.5198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82417333
Old  loss*** tensor(3654.1665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3011.6665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7631811
Old  loss*** tensor(4994.1533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3811.4434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874725
Old  loss*** tensor(1024.1938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.8879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738904
Old  loss*** tensor(716.3064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(625.9733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520533
Old  loss*** tensor(4430.1035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3774.6843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762518
Old  loss*** tensor(1072.6288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(939.8929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81868464
Old  loss*** tensor(3032.2952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2482.4934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88721085
Old  loss*** tensor(2324.3318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2062.1724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86655986
Old  loss*** tensor(1020.5118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(884.3345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084523
Old  loss*** tensor(4510.8618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3646.8167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8036541
Old  loss*** tensor(1760.5251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.8531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872931
Old  loss*** tensor(790.7801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.2964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8733609
Old  loss*** tensor(1161.7847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1014.6573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752313
Old  loss*** tensor(1150.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1007.2637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8527087
Old  loss*** tensor(1503.3350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1281.9067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87647766
Old  loss*** tensor(426.3401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(373.6776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8045336
Old  loss*** tensor(4529.1489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3643.8525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9005702
Old  loss*** tensor(250.0390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(225.1777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86680454
Old  loss*** tensor(1426.6770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1236.6501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85280085
Old  loss*** tensor(2254.7280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1922.8340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88569003
Old  loss*** tensor(252.2028, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(223.3735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8339347
Old  loss*** tensor(2545.3792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2122.6802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8967499
Old  loss*** tensor(854.2443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(766.0435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82567704
Old  loss*** tensor(2233.2400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1843.9349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8148127
Old  loss*** tensor(3912.4541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3187.9175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8014006
Old  loss*** tensor(2473.9324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.6108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881243
Old  loss*** tensor(1773.1985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.6188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87186426
Old  loss*** tensor(939.3923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(819.0226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8182662
Old  loss*** tensor(1975.1389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1616.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83726215
Old  loss*** tensor(3655.2290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3060.3850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8122139
Old  loss*** tensor(3969.7466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3224.2834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8150711
Old  loss*** tensor(2740.6848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2233.8530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674657
Old  loss*** tensor(1888.6135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1638.3074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8318434
Old  loss*** tensor(3267.5610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2718.0991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78661877
Old  loss*** tensor(4414.0010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3472.1360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89056695
Old  loss*** tensor(1405.8954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1252.0439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89781785
Old  loss*** tensor(520.6938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(467.4882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82355046
Old  loss*** tensor(1743.3468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1435.7340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8805064
Old  loss*** tensor(776.4586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(683.6768, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8893417
Old  loss*** tensor(1006.5692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.1840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81502676
Old  loss*** tensor(2190.1887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1785.0624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83259064
Old  loss*** tensor(2143.0471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1784.2810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7422107
Old  loss*** tensor(4396.7432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3263.3098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7802532
Old  loss*** tensor(3131.8154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2443.6089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8282389
Old  loss*** tensor(4576.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3790.8035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8600309
Old  loss*** tensor(4112.4268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3536.8140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86942476
Old  loss*** tensor(2488.4766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2163.5432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87464887
Old  loss*** tensor(482.4847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(422.0047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83729553
Old  loss*** tensor(4196.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3513.3420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8318326
Old  loss*** tensor(1562.1702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.4641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8290407
Old  loss*** tensor(1936.5571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1605.4847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84804064
Old  loss*** tensor(1228.7289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1042.0121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79791105
Old  loss*** tensor(4354.1470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3474.2219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89299047
Old  loss*** tensor(407.8852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(364.2375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8863569
Old  loss*** tensor(1531.0280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.0372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7740116
Old  loss*** tensor(3353.2568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2595.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85738206
Old  loss*** tensor(1743.1938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1494.5831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8980358
Old  loss*** tensor(1116.2133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.3995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.850757
Old  loss*** tensor(2038.9873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1734.6827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.822209
Old  loss*** tensor(2478.9937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.2509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87308955
Old  loss*** tensor(617.4735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(539.1097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7895004
Old  loss*** tensor(2571.2192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2029.9786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7860667
Old  loss*** tensor(3773.9167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2966.5503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8999541
Old  loss*** tensor(1178.6398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1060.7217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82081527
Old  loss*** tensor(4769.4624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3914.8477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87139344
Old  loss*** tensor(460.5075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.2832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759677
Old  loss*** tensor(680.5801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(596.1661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88418573
Old  loss*** tensor(1116.1995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(986.9276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7838317
Old  loss*** tensor(4081.1628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3198.9448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9134227
Old  loss*** tensor(898.5079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(820.7175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7560147
Old  loss*** tensor(4507.5122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3407.7456, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8467512
Old  loss*** tensor(1177.7455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(997.2574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90035987
Old  loss*** tensor(660.3419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(594.5453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792372
Old  loss*** tensor(1013.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.9156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8935603
Old  loss*** tensor(1118.7943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.7101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87667835
Old  loss*** tensor(1637.2657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1435.3555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.830897
Old  loss*** tensor(2328.3345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1934.6061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716078
Old  loss*** tensor(1817.9894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.5737, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650719
Old  loss*** tensor(3179.3164, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2750.3372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87533456
Old  loss*** tensor(726.0392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.5272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8649857
Old  loss*** tensor(1386.8481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.6038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8580071
Old  loss*** tensor(1107.7230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(950.4342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82331574
Old  loss*** tensor(2137.1265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.5299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8391604
Old  loss*** tensor(2174.8738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1825.0679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77152586
Old  loss*** tensor(2785.8655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2149.3672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8138697
Old  loss*** tensor(2446.4458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1991.0881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79829466
Old  loss*** tensor(2342.7932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1870.2394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636021
Old  loss*** tensor(1091.5587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.6724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672943
Old  loss*** tensor(745.4615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.5345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88627934
Old  loss*** tensor(709.9053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.1744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.835032
Old  loss*** tensor(2025.1931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.1011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86791694
Old  loss*** tensor(1779.3993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1544.3708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90050757
Old  loss*** tensor(587.0104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(528.6073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594908
Old  loss*** tensor(1992.3833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1712.4352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76483303
Old  loss*** tensor(4897.3140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3745.6274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87079275
Old  loss*** tensor(951.2599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(828.3502, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748878
Old  loss*** tensor(1368.6720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.4344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88581
Old  loss*** tensor(915.2504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(810.7379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86233175
Old  loss*** tensor(1391.0420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.5397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85296535
Old  loss*** tensor(1432.3646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1221.7574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8141388
Old  loss*** tensor(2512.2896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2045.3524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9132136
Old  loss*** tensor(837.4944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(764.8113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7984778
Old  loss*** tensor(2868.4602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.4019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8553518
Old  loss*** tensor(2974.7993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2544.5000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.891423
Old  loss*** tensor(219.7096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(195.8542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750496
Old  loss*** tensor(116.0071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(101.5119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8843128
Old  loss*** tensor(358.7281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(317.2279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89560544
Old  loss*** tensor(743.2357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.6459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86762726
Old  loss*** tensor(1927.1188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1672.0208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218037
Old  loss*** tensor(4439.6040, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3648.4829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86906326
Old  loss*** tensor(1523.8308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1324.3054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8090464
Old  loss*** tensor(2775.5034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2245.5110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8692801
Old  loss*** tensor(2044.1655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1776.9524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76673025
Old  loss*** tensor(3807.2483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2919.1323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495795
Old  loss*** tensor(3629.6743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3083.6970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739892
Old  loss*** tensor(2157.4863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.6198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86351675
Old  loss*** tensor(1975.4156, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1705.8044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604591
Old  loss*** tensor(917.4315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(789.4123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8707499
Old  loss*** tensor(2387.2229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2078.6741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8651811
Old  loss*** tensor(2678.9058, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2317.7385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85700405
Old  loss*** tensor(2746.0457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2353.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89403045
Old  loss*** tensor(558.5542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(499.3645, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85758114
Old  loss*** tensor(1387.8801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.2198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83522016
Old  loss*** tensor(3012.8669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2516.4072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572603
Old  loss*** tensor(2971.9109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2547.7012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7747847
Old  loss*** tensor(4151.7876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3216.7415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85083634
Old  loss*** tensor(2395.8838, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.5050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8302412
Old  loss*** tensor(2895.3008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2403.7981, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80122745
Old  loss*** tensor(4540.1528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3637.6951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748554
Old  loss*** tensor(2013.8662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.8417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8118228
Old  loss*** tensor(3588.0439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2912.8557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82980055
Old  loss*** tensor(2804.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2327.5144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84283555
Old  loss*** tensor(1563.6265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.8800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91098535
Old  loss*** tensor(848.7615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(773.2094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410651
Old  loss*** tensor(1835.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1543.7570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8513648
Old  loss*** tensor(3923.1665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3340.0459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7989452
Old  loss*** tensor(3060.0276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2444.7944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88241976
Old  loss*** tensor(1562.9299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1379.1603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8686082
Old  loss*** tensor(1591.1993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1382.1288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832442
Old  loss*** tensor(136.4372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(120.5074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8825695
Old  loss*** tensor(1630.6351, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1439.1488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86688024
Old  loss*** tensor(934.2217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(809.8583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284396
Old  loss*** tensor(3881.7107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3215.7629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82367074
Old  loss*** tensor(3480.5049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2866.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85217166
Old  loss*** tensor(2382.2075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2030.0497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641949
Old  loss*** tensor(1974.8293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1706.6375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89540833
Old  loss*** tensor(518.8004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(464.5382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84913653
Old  loss*** tensor(3547.2932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3012.1362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.838708
Old  loss*** tensor(3068.0483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2573.1965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803711
Old  loss*** tensor(628.6127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(553.4125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8427751
Old  loss*** tensor(1499.8015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1263.9954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8549154
Old  loss*** tensor(1620.5791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.4580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88394177
Old  loss*** tensor(99.6090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(88.0486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8544554
Old  loss*** tensor(1045.3098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(893.1707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7728189
Old  loss*** tensor(4570.8584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3532.4458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88767135
Old  loss*** tensor(632.8312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(561.7462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710912
Old  loss*** tensor(1106.4895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(963.8533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.828817
Old  loss*** tensor(1917.3503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1589.1326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85727215
Old  loss*** tensor(1275.8862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.7817, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89517856
Old  loss*** tensor(887.7974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(794.7372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82027644
Old  loss*** tensor(3410.6660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2797.6890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88587373
Old  loss*** tensor(512.6701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(454.1610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87977046
Old  loss*** tensor(912.5073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.7970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8414371
Old  loss*** tensor(3909.5684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3289.6558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83185136
Old  loss*** tensor(2476.0598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.7136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87023807
Old  loss*** tensor(4248.7578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3697.4307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7195325
Old  loss*** tensor(3562.6060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2563.4106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87279594
Old  loss*** tensor(1131.3011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(987.3950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8196117
Old  loss*** tensor(2941.2681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2410.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80026174
Old  loss*** tensor(2189.2891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1752.0043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8121575
Old  loss*** tensor(2262.8784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1837.8137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536362
Old  loss*** tensor(1839.0360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1569.8677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9073949
Old  loss*** tensor(1313.1154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1191.5142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87096614
Old  loss*** tensor(2092.6018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1822.5853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7671187
Old  loss*** tensor(3157.6953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2422.3271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729297
Old  loss*** tensor(1530.5757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.0850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796989
Old  loss*** tensor(933.7080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(821.3819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80909234
Old  loss*** tensor(4258.5176, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3445.5339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879223
Old  loss*** tensor(1116.0308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.2399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853445
Old  loss*** tensor(607.3766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(537.7375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85128975
Old  loss*** tensor(1339.3912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1140.2101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8692349
Old  loss*** tensor(1071.1874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(931.1135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86858666
Old  loss*** tensor(698.5614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(606.7611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7726257
Old  loss*** tensor(4245.1904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3279.9431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78882754
Old  loss*** tensor(3499.5684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2760.5559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76193565
Old  loss*** tensor(3904.6311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2975.0776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8714329
Old  loss*** tensor(1415.8831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1233.8470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7928535
Old  loss*** tensor(4175.7075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3310.7241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82519996
Old  loss*** tensor(3035.0830, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2504.5503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72789615
Old  loss*** tensor(4574.7886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3329.9709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7959106
Old  loss*** tensor(3853.1035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3066.7258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.838941
Old  loss*** tensor(2582.3274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2166.4202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83659196
Old  loss*** tensor(3032.8494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2537.2573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719184
Old  loss*** tensor(720.9306, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(628.5927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88032174
Old  loss*** tensor(379.2273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(333.8420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655699
Old  loss*** tensor(1937.3173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1676.8835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8249644
Old  loss*** tensor(1586.1279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1308.4990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89508855
Old  loss*** tensor(147.6839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(132.1901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683913
Old  loss*** tensor(1404.1730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.3716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86199063
Old  loss*** tensor(2073.1746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1787.0570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7714122
Old  loss*** tensor(4556.7178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3515.1077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8133534
Old  loss*** tensor(2686.9727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2185.4585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8986205
Old  loss*** tensor(725.3036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(651.7726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84275985
Old  loss*** tensor(4165.0640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3510.1487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90023977
Old  loss*** tensor(651.2001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.2363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298322
Old  loss*** tensor(3664.6655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3041.0574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7990128
Old  loss*** tensor(3471.0103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2773.3816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428749
Old  loss*** tensor(2074.1287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1748.2310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908254
Old  loss*** tensor(313.2131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(279.0182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8337617
Old  loss*** tensor(4816.7295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4016.0046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822858
Old  loss*** tensor(775.6646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(684.3578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88598925
Old  loss*** tensor(943.1948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.6604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8614995
Old  loss*** tensor(849.4041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(731.7612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83490956
Old  loss*** tensor(3155.8633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2634.8604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7577646
Old  loss*** tensor(4437.0640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.2500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540741
Old  loss*** tensor(1676.5844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.9272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8905601
Old  loss*** tensor(1151.9069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.8423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698107
Old  loss*** tensor(2213.9380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1925.7069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88970464
Old  loss*** tensor(1999.7727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1779.2070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84879786
Old  loss*** tensor(3338.7981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2833.9646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87215775
Old  loss*** tensor(1964.5442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1713.3925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8627318
Old  loss*** tensor(1531.3817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1321.1718, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88354146
Old  loss*** tensor(976.3475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(862.6435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.894913
Old  loss*** tensor(503.9646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.0045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90117353
Old  loss*** tensor(1170.9298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1055.2109, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84066796
Old  loss*** tensor(2257.5474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.8478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87474746
Old  loss*** tensor(1953.3257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1708.6666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82141435
Old  loss*** tensor(4208.3242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3456.7778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89695776
Old  loss*** tensor(1414.7638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.9834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900877
Old  loss*** tensor(344.8529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(306.9494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88613
Old  loss*** tensor(1175.8154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1041.9253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77652
Old  loss*** tensor(4400.1157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3416.7778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811658
Old  loss*** tensor(1734.2598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.1704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89682686
Old  loss*** tensor(658.6396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(590.6857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8355492
Old  loss*** tensor(2925.0603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2444.0317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8035555
Old  loss*** tensor(3032.5542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2436.8257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89237946
Old  loss*** tensor(1449.6162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1293.6078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8335462
Old  loss*** tensor(2558.3684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.5183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8872252
Old  loss*** tensor(919.8998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(816.1583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89599574
Old  loss*** tensor(1217.8772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.2128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604
Old  loss*** tensor(1365.4891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1174.8668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8271754
Old  loss*** tensor(1970.3312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1629.8094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8514354
Old  loss*** tensor(2593.9436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2208.5754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387461
Old  loss*** tensor(2718.2859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2279.9517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88629436
Old  loss*** tensor(664.0267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(588.5231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.876076
Old  loss*** tensor(1497.6307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1312.0383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8714238
Old  loss*** tensor(1264.8761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1102.2432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86956584
Old  loss*** tensor(1938.9249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1686.0229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7617243
Old  loss*** tensor(4395.1670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3347.9055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.829743
Old  loss*** tensor(1982.9736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1645.3585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8720373
Old  loss*** tensor(131.9536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(115.0685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84337467
Old  loss*** tensor(1561.7970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.1801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915683
Old  loss*** tensor(909.3973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(810.7898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8144208
Old  loss*** tensor(2636.0271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2146.8354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483199
Old  loss*** tensor(949.6147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(805.5771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8782981
Old  loss*** tensor(839.0613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(736.9459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7981463
Old  loss*** tensor(3655.6089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2917.7107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8550221
Old  loss*** tensor(1211.3950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.7695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85412836
Old  loss*** tensor(2498.3848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2133.9414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650594
Old  loss*** tensor(2273.8589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1967.0229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.902629
Old  loss*** tensor(999.5861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(902.2554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8894088
Old  loss*** tensor(411.7375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(366.2029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641909
Old  loss*** tensor(1745.3506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1508.3160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7888591
Old  loss*** tensor(3529.7007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2784.4365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9180827
Old  loss*** tensor(1306.2697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.2635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8158603
Old  loss*** tensor(2637.0361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2151.4531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7417502
Old  loss*** tensor(3199.3687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2373.1323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492026
Old  loss*** tensor(1982.0262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1683.1418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7473743
Old  loss*** tensor(5082.7144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3798.6902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81379694
Old  loss*** tensor(1184.2714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(963.7564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851088
Old  loss*** tensor(2561.1741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2266.9177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8443692
Old  loss*** tensor(1789.0399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1510.6101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8445028
Old  loss*** tensor(1916.5770, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1618.5547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85451186
Old  loss*** tensor(254.7106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(217.6533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7621006
Old  loss*** tensor(4274.8916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3257.8975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80343497
Old  loss*** tensor(3029.5322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2434.0322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86681455
Old  loss*** tensor(1004.1093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.3765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83806276
Old  loss*** tensor(2975.6079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2493.7461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689883
Old  loss*** tensor(1564.7878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.7823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77458173
Old  loss*** tensor(2254.1672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1746.0367, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7725975
Old  loss*** tensor(4816.6626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3721.3416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8037158
Old  loss*** tensor(3818.6013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3069.0703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8351295
Old  loss*** tensor(4401.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3676.1809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.806026
Old  loss*** tensor(4476.3877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3608.0847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742552
Old  loss*** tensor(1151.7006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.8802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82798004
Old  loss*** tensor(3004.8184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2487.9297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840641
Old  loss*** tensor(817.9466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(723.1172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8751774
Old  loss*** tensor(1489.7402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1303.7870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9126162
Old  loss*** tensor(1890.8645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1725.6335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88415456
Old  loss*** tensor(1033.5417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.8107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80981684
Old  loss*** tensor(3084.1494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2497.5962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87282276
Old  loss*** tensor(1296.5571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1131.6646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7581289
Old  loss*** tensor(5014.0908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3801.3271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87665325
Old  loss*** tensor(923.1583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(809.2897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88179076
Old  loss*** tensor(1500.6903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1323.2948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.873788
Old  loss*** tensor(140.6646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(122.9111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8740188
Old  loss*** tensor(1702.0167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1487.5946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831996
Old  loss*** tensor(1100.2596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(971.7488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82616365
Old  loss*** tensor(2269.1021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1874.6497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75932896
Old  loss*** tensor(4664.7549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3542.0835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8668922
Old  loss*** tensor(3116.2366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2701.4412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8324812
Old  loss*** tensor(1771.8683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1475.0470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88360417
Old  loss*** tensor(495.3586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(437.7009, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7832693
Old  loss*** tensor(3499.4338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2740.9990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8112161
Old  loss*** tensor(4349.2637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3528.1929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8248311
Old  loss*** tensor(4121.6826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3399.6921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83398753
Old  loss*** tensor(2848.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.5725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87425137
Old  loss*** tensor(482.6482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(421.9558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7904648
Old  loss*** tensor(4067.5901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3215.2869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9055826
Old  loss*** tensor(1015.9857, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(920.0590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89070714
Old  loss*** tensor(738.3329, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(657.6384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89137685
Old  loss*** tensor(1148.6301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1023.8623, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88350034
Old  loss*** tensor(1131.3794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.5741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9024139
Old  loss*** tensor(663.3288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(598.5971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86436725
Old  loss*** tensor(1176.9237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.2943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255379
Old  loss*** tensor(2482.6448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2049.5173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72991663
Old  loss*** tensor(5059.4419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3692.9707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8125814
Old  loss*** tensor(3076.0005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2499.5007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.831314
Old  loss*** tensor(4069.4131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3382.9602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89326537
Old  loss*** tensor(787.4955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(703.4424, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8937398
Old  loss*** tensor(1215.5161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1086.3551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8071133
Old  loss*** tensor(4426.7422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3572.8826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656092
Old  loss*** tensor(1416.1719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1225.8514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88797987
Old  loss*** tensor(1814.4137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1611.1628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83887386
Old  loss*** tensor(3382.9163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2837.8401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86492217
Old  loss*** tensor(1527.2582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1320.9595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89839214
Old  loss*** tensor(514.2525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.0004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573364
Old  loss*** tensor(1596.1650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1368.4504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85094017
Old  loss*** tensor(2550.2937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2170.1475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8720963
Old  loss*** tensor(683.2473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.8575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8723923
Old  loss*** tensor(534.6362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(466.4125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8126997
Old  loss*** tensor(2909.0356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2364.1724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8913831
Old  loss*** tensor(812.7485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(724.4703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8825832
Old  loss*** tensor(950.5805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(838.9664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85218453
Old  loss*** tensor(1355.4536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1155.0966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830308
Old  loss*** tensor(380.2932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(335.8106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86809874
Old  loss*** tensor(1305.6884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1133.4664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8457636
Old  loss*** tensor(2141.3247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1811.0546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8332727
Old  loss*** tensor(3002.6047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2501.9885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492096
Old  loss*** tensor(1581.5720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1343.0862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8371563
Old  loss*** tensor(2274.8613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.4144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82463485
Old  loss*** tensor(2213.3955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1825.2430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616938
Old  loss*** tensor(1179.3669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.2532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84125614
Old  loss*** tensor(1175.9402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.2669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8352568
Old  loss*** tensor(2470.6738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2063.6472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8556994
Old  loss*** tensor(1462.6886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1251.6218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88303393
Old  loss*** tensor(1101.5958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.7465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558551
Old  loss*** tensor(388.1878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(332.2325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85271895
Old  loss*** tensor(2194.0457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1870.9043, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72711873
Old  loss*** tensor(4331.8882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3149.7971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8362898
Old  loss*** tensor(2206.4165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1845.2036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87535566
Old  loss*** tensor(651.0524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(569.9024, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.833226
Old  loss*** tensor(2132.9131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1777.1987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7860616
Old  loss*** tensor(3630.9255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2854.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81891596
Old  loss*** tensor(2487.6270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2037.1575, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89532954
Old  loss*** tensor(1579.9558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.5811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84766114
Old  loss*** tensor(2916.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2472.0066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90179104
Old  loss*** tensor(938.3674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(846.2114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88159335
Old  loss*** tensor(1256.8734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1108.0513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8443771
Old  loss*** tensor(2014.8224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1701.2699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84693754
Old  loss*** tensor(4738.8359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4013.4980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87773705
Old  loss*** tensor(1763.9580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1548.2913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79759395
Old  loss*** tensor(3611.5083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2880.5171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439112
Old  loss*** tensor(2240.6860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1890.9399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89389306
Old  loss*** tensor(1685.8591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1506.9778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87321407
Old  loss*** tensor(816.2462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.7577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401382
Old  loss*** tensor(3172.2759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2665.1501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814992
Old  loss*** tensor(778.9882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.6775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839698
Old  loss*** tensor(2407.8391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2021.8577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87386423
Old  loss*** tensor(554.8657, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(484.8773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84509075
Old  loss*** tensor(1107.3483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(935.8098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492112
Old  loss*** tensor(1666.0813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.8550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75657314
Old  loss*** tensor(2868.2898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2170.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82184756
Old  loss*** tensor(1666.4023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1369.5287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77655303
Old  loss*** tensor(4578.5957, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3555.5225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7897732
Old  loss*** tensor(3468.3909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.2422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8140075
Old  loss*** tensor(3815.5427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3105.8804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.861928
Old  loss*** tensor(2349.3909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2025.0057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.824339
Old  loss*** tensor(1889.2646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1557.3945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88833606
Old  loss*** tensor(339.7284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(301.7930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89772844
Old  loss*** tensor(962.8149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.3464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87136006
Old  loss*** tensor(1044.7197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(910.3270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8548969
Old  loss*** tensor(965.8398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(825.6935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80685604
Old  loss*** tensor(3263.6165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.2686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86772144
Old  loss*** tensor(1496.3442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.4100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8373239
Old  loss*** tensor(998.4120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.9942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713012
Old  loss*** tensor(1056.0636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(920.1495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8899749
Old  loss*** tensor(1569.2263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1396.5720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86560977
Old  loss*** tensor(882.4102, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(763.8229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78910613
Old  loss*** tensor(4141.1519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3267.8083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9247772
Old  loss*** tensor(1179.1272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1090.4299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716248
Old  loss*** tensor(541.7588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(472.2104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80664116
Old  loss*** tensor(3489.9424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2815.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8737468
Old  loss*** tensor(3960.9089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3460.8315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8242112
Old  loss*** tensor(2818.8210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2323.3037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80923855
Old  loss*** tensor(2227.2244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1802.3558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911998
Old  loss*** tensor(804.9158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(717.3409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820654
Old  loss*** tensor(90.1614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(79.5283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8393811
Old  loss*** tensor(2868.8438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2408.0532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80152935
Old  loss*** tensor(3609.6865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2893.2698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8236795
Old  loss*** tensor(3756.7534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3094.3608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89891034
Old  loss*** tensor(1017.3910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(914.5433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8467306
Old  loss*** tensor(1929.8069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1634.0265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87537247
Old  loss*** tensor(407.4978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(356.7123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90468204
Old  loss*** tensor(1260.3147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1140.1841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83077455
Old  loss*** tensor(3209.3359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2666.2346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828465
Old  loss*** tensor(1537.3616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.2543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83326536
Old  loss*** tensor(2061.5923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1717.8534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7901332
Old  loss*** tensor(3332.6895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.2686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88673604
Old  loss*** tensor(1620.4473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1436.9089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8546519
Old  loss*** tensor(2790.4958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2384.9026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7634597
Old  loss*** tensor(4546.6382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3471.1750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7866736
Old  loss*** tensor(2967.4404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2334.4070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863476
Old  loss*** tensor(648.2966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(559.7886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84471047
Old  loss*** tensor(4357.2383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3680.6047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9043134
Old  loss*** tensor(511.9867, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(462.9965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8491632
Old  loss*** tensor(1696.1233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1440.2854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7313906
Old  loss*** tensor(4520.8613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3306.5154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8625126
Old  loss*** tensor(1332.8806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.6263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7914157
Old  loss*** tensor(3897.9717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3084.9160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839145
Old  loss*** tensor(775.5142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(685.4882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8333821
Old  loss*** tensor(2546.3237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2122.0608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889196
Old  loss*** tensor(370.7159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(329.5366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719399
Old  loss*** tensor(1253.8673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.2969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310503
Old  loss*** tensor(2725.2009, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2264.7791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84083736
Old  loss*** tensor(2883.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2424.2422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89668405
Old  loss*** tensor(696.3506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(624.4065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7886853
Old  loss*** tensor(4053.6379, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3197.0447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81560665
Old  loss*** tensor(4395.9297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.3496, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87609243
Old  loss*** tensor(1405.8693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.6714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609426
Old  loss*** tensor(1259.2201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.1162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698628
Old  loss*** tensor(1799.6941, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1565.4869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613775
Old  loss*** tensor(745.3225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.0040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8943262
Old  loss*** tensor(293.2548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(262.2654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83050114
Old  loss*** tensor(2474.6160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.1714, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78034484
Old  loss*** tensor(4891.3564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3816.9448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8148948
Old  loss*** tensor(3290.1282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2681.1084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81277776
Old  loss*** tensor(2483.4280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2018.4750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78904516
Old  loss*** tensor(2640.7764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.6919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8504226
Old  loss*** tensor(1991.7052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.7911, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763534
Old  loss*** tensor(1511.2688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1324.4055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87950194
Old  loss*** tensor(472.3618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(415.4431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9014071
Old  loss*** tensor(228.0422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(205.5588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617375
Old  loss*** tensor(2044.7123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1762.0052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8105085
Old  loss*** tensor(3039.8267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2463.8054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8645266
Old  loss*** tensor(944.0493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(816.1557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8147981
Old  loss*** tensor(975.8446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(795.1163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83646345
Old  loss*** tensor(2022.1594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.4624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8118574
Old  loss*** tensor(4439.3945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3604.1553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87970674
Old  loss*** tensor(820.3701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(721.6851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84631467
Old  loss*** tensor(2081.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.8743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87724745
Old  loss*** tensor(731.6985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(641.8806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85006344
Old  loss*** tensor(1364.7321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1160.1089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91355634
Old  loss*** tensor(248.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(226.5631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7997726
Old  loss*** tensor(2380.5688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1903.9138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88940656
Old  loss*** tensor(2768.2612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2462.1096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426517
Old  loss*** tensor(1703.8782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1435.7759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85502195
Old  loss*** tensor(1851.1918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1582.8096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89187336
Old  loss*** tensor(982.2756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(876.0654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700097
Old  loss*** tensor(3381.7244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2942.1331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.856199
Old  loss*** tensor(1295.1429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1108.9001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81667805
Old  loss*** tensor(4457.4995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3640.3420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87254745
Old  loss*** tensor(2983.1924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2602.9768, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8600838
Old  loss*** tensor(4120.7793, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3544.2156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528477
Old  loss*** tensor(2250.5149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1919.3464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87614655
Old  loss*** tensor(1199.5428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.9753, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83345115
Old  loss*** tensor(1596.9733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1330.9993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570048
Old  loss*** tensor(2387.3281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2045.9517, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8524273
Old  loss*** tensor(2069.0754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1763.7365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7427857
Old  loss*** tensor(5094.3633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3784.0203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8936288
Old  loss*** tensor(677.2565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(605.2159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8182315
Old  loss*** tensor(2708.7654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2216.3972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699934
Old  loss*** tensor(944.7382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(821.9160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84768224
Old  loss*** tensor(2450.4131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2077.1716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813789
Old  loss*** tensor(1397.4479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.6810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867407
Old  loss*** tensor(545.0667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.3328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.801042
Old  loss*** tensor(3704.7134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2967.6311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83206034
Old  loss*** tensor(4772.9761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3971.4041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87027264
Old  loss*** tensor(1642.8861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.7588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8817911
Old  loss*** tensor(1264.0588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1114.6359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050325
Old  loss*** tensor(3191.4768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2569.2424, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90387
Old  loss*** tensor(353.1352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(319.1883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80550796
Old  loss*** tensor(3553.7766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2862.5955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847963
Old  loss*** tensor(2129.4041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1805.6558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8837364
Old  loss*** tensor(3054.0879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2699.0085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84842527
Old  loss*** tensor(1730.8120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1468.4646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.741879
Old  loss*** tensor(3303.0020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2450.4277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9125085
Old  loss*** tensor(1067.4845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.0887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.809839
Old  loss*** tensor(2444.2229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1979.4270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86763227
Old  loss*** tensor(1240.9791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1076.7135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86576045
Old  loss*** tensor(1536.4680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1330.2133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8367528
Old  loss*** tensor(1724.4207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1442.9138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658073
Old  loss*** tensor(1005.5338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.5984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86089337
Old  loss*** tensor(1473.5421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.5626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907467
Old  loss*** tensor(1107.6843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(986.6662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928619
Old  loss*** tensor(520.7626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(464.9691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7620131
Old  loss*** tensor(4159.2124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3169.3743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7760484
Old  loss*** tensor(3209.6958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2490.8794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531613
Old  loss*** tensor(1326.7714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1131.9500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8944255
Old  loss*** tensor(1158.2545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.9724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84228975
Old  loss*** tensor(1650.8687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1390.5098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.6864915
Old  loss*** tensor(4034.1621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2769.4180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87630177
Old  loss*** tensor(1430.7490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1253.7679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86877
Old  loss*** tensor(1252.4856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1088.1219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9074794
Old  loss*** tensor(926.7680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(841.0229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87591624
Old  loss*** tensor(584.8686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(512.2959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786906
Old  loss*** tensor(1928.0955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.1993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820251
Old  loss*** tensor(415.6105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(366.5789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88844
Old  loss*** tensor(136.9036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(121.6307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864593
Old  loss*** tensor(1007.0103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.6541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770588
Old  loss*** tensor(1365.4238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.5570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8967706
Old  loss*** tensor(1253.3879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1124.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81603837
Old  loss*** tensor(2919.4978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2382.4221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79550207
Old  loss*** tensor(5104.7905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4060.8713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81271887
Old  loss*** tensor(2241.4106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1821.6367, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762233
Old  loss*** tensor(1017.4326, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(891.4981, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9005692
Old  loss*** tensor(722.6729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.8170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795745
Old  loss*** tensor(529.6182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(465.8386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8118559
Old  loss*** tensor(3737.4204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3034.2468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88089895
Old  loss*** tensor(365.2121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(321.7150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529644
Old  loss*** tensor(2879.7942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2456.3618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442379
Old  loss*** tensor(1974.1366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1666.6410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86936516
Old  loss*** tensor(4159.6479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3616.2529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86763597
Old  loss*** tensor(1383.7300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.5739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80684346
Old  loss*** tensor(3524.5693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2843.7756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9064392
Old  loss*** tensor(1473.0022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.1869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8617354
Old  loss*** tensor(783.1486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.8668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8537481
Old  loss*** tensor(1145.7480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.1802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7878782
Old  loss*** tensor(2448.1926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1928.8777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77255523
Old  loss*** tensor(4449.8374, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.7451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87420315
Old  loss*** tensor(4017.4780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3512.0920, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.754143
Old  loss*** tensor(4991.9790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3764.6660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84285164
Old  loss*** tensor(1983.0549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1671.4211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869502
Old  loss*** tensor(713.2844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.6477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.789875
Old  loss*** tensor(4532.3154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3579.9624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.803235
Old  loss*** tensor(4586.9312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3684.3835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9025686
Old  loss*** tensor(720.0021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.8513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642192
Old  loss*** tensor(1012.7659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(875.2518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7995492
Old  loss*** tensor(3124.3586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2498.0786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82981086
Old  loss*** tensor(3324.2446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2758.4944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87955475
Old  loss*** tensor(100.6188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(88.4997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76181805
Old  loss*** tensor(4187.8560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3190.3843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81789386
Old  loss*** tensor(2559.4214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2093.3350, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86756754
Old  loss*** tensor(1014.1690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.8601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85150194
Old  loss*** tensor(1858.1246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1582.1968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90038097
Old  loss*** tensor(263.1061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(236.8958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82812023
Old  loss*** tensor(1753.2131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1451.8712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90154827
Old  loss*** tensor(990.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(893.0553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81130874
Old  loss*** tensor(2876.4990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2333.7288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88335836
Old  loss*** tensor(1505.8967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1330.2465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85600317
Old  loss*** tensor(1880.0764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1609.3513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8120229
Old  loss*** tensor(3409.1802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2768.3325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7367415
Old  loss*** tensor(4356.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3209.4653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81484306
Old  loss*** tensor(4107.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3346.6958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8237276
Old  loss*** tensor(3531.7896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2909.2327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700949
Old  loss*** tensor(1500.1406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1305.2646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88895607
Old  loss*** tensor(2119.3188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1883.9813, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88271314
Old  loss*** tensor(1740.4535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.3212, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785784
Old  loss*** tensor(518.4557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(455.5040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.790274
Old  loss*** tensor(3315.2795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2619.9792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7729544
Old  loss*** tensor(3741.7168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2892.1765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87660915
Old  loss*** tensor(822.7852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(721.2610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90668344
Old  loss*** tensor(607.9125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(551.1842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89687866
Old  loss*** tensor(234.3763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(210.2071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76065797
Old  loss*** tensor(4046.1758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3077.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752676
Old  loss*** tensor(1613.8242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.5281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85251105
Old  loss*** tensor(1707.4753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1455.6416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88036764
Old  loss*** tensor(630.6890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.2382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8906319
Old  loss*** tensor(1030.3303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(917.6451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88390714
Old  loss*** tensor(827.3522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(731.3025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80337405
Old  loss*** tensor(4090.2393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3285.9922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717786
Old  loss*** tensor(2322.4485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2024.6609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85647225
Old  loss*** tensor(1606.6946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1376.0894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7955578
Old  loss*** tensor(3320.7600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2641.8564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8532143
Old  loss*** tensor(1227.5277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1047.3442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80761
Old  loss*** tensor(4112.3950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3321.2112, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87305355
Old  loss*** tensor(877.8373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(766.3989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857355
Old  loss*** tensor(996.3016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(882.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86357975
Old  loss*** tensor(3955.9036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3416.2383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8145844
Old  loss*** tensor(2803.4944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2283.6826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91089404
Old  loss*** tensor(1134.1932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.1299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79353815
Old  loss*** tensor(4034.0981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3201.2107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88996434
Old  loss*** tensor(1202.5143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1070.1948, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218366
Old  loss*** tensor(2924.6848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2403.6130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80153716
Old  loss*** tensor(2491.7705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1997.2467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76803076
Old  loss*** tensor(5015.2358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3851.8555, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677441
Old  loss*** tensor(1894.0454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1643.5468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8085388
Old  loss*** tensor(2769.6321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2239.3550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7693762
Old  loss*** tensor(4781.0054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3678.3918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87797284
Old  loss*** tensor(2903.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2549.5051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86398464
Old  loss*** tensor(616.7958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.9021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8681627
Old  loss*** tensor(910.1390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(790.1487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8346338
Old  loss*** tensor(2173.1814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1813.8107, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590591
Old  loss*** tensor(1062.8715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(913.0694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88519466
Old  loss*** tensor(466.8154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(413.2225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86173755
Old  loss*** tensor(2276.8582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1962.0542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860121
Old  loss*** tensor(1306.2976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1123.5740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8513584
Old  loss*** tensor(2542.7500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2164.7915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775188
Old  loss*** tensor(807.4568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.5585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8618569
Old  loss*** tensor(1513.9786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1304.8329, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7509699
Old  loss*** tensor(3716.4575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2790.9478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8843411
Old  loss*** tensor(705.1128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.5602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673173
Old  loss*** tensor(1391.3951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.7811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82752573
Old  loss*** tensor(3382.3579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2798.9883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8142586
Old  loss*** tensor(2030.6857, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1653.5032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87682647
Old  loss*** tensor(692.0297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(606.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8183855
Old  loss*** tensor(2286.8174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1871.4982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8837104
Old  loss*** tensor(1490.4136, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.0940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8805735
Old  loss*** tensor(1297.6348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.6628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865771
Old  loss*** tensor(859.2394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.7820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85383606
Old  loss*** tensor(2559.9546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2185.7815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.906639
Old  loss*** tensor(641.0490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(581.2000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8328165
Old  loss*** tensor(1593.2169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1326.8573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86340153
Old  loss*** tensor(1443.3755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1246.2126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570133
Old  loss*** tensor(1752.1407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1501.6079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8348321
Old  loss*** tensor(4176.4219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3486.6108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8049154
Old  loss*** tensor(1266.7800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.6508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635247
Old  loss*** tensor(1264.0428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.5322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796443
Old  loss*** tensor(344.8400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(303.3365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061733
Old  loss*** tensor(2581.7688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2081.3530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84464973
Old  loss*** tensor(2060.5933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1740.4795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8685317
Old  loss*** tensor(1408.3972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1223.2377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89988106
Old  loss*** tensor(483.9543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(435.5013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87500554
Old  loss*** tensor(1149.6702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.9678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031329
Old  loss*** tensor(2191.6289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1760.1693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809842
Old  loss*** tensor(480.5816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(423.3848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87289274
Old  loss*** tensor(98.5568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(86.0295, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8581507
Old  loss*** tensor(2628.9033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.9954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8119174
Old  loss*** tensor(4207.7681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3416.3601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86432576
Old  loss*** tensor(1191.1370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1029.5304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79470545
Old  loss*** tensor(4234.7476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3365.3770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75795937
Old  loss*** tensor(4116.0674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3119.8118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86681783
Old  loss*** tensor(3600.7678, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3121.2097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8936455
Old  loss*** tensor(1327.1836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1186.0317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85671663
Old  loss*** tensor(2944.3894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2522.5073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8461809
Old  loss*** tensor(2630.4006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2225.7949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8210999
Old  loss*** tensor(3206.3503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2632.7339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82885164
Old  loss*** tensor(2149.2026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1781.3701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82128376
Old  loss*** tensor(2957.2341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2428.7283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72457933
Old  loss*** tensor(5083.8198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3683.6309, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8832906
Old  loss*** tensor(1713.6083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1513.6140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83128476
Old  loss*** tensor(3668.2046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3049.3225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875224
Old  loss*** tensor(1888.2706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1675.8824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80619645
Old  loss*** tensor(4494.1655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3623.1804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81212777
Old  loss*** tensor(3559.7822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2890.9980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776156
Old  loss*** tensor(1111.6293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.5831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677975
Old  loss*** tensor(2329.0396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2021.1346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85753536
Old  loss*** tensor(1984.0906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1701.4279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7546152
Old  loss*** tensor(4051.0168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3056.9587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90080404
Old  loss*** tensor(945.2430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(851.4787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82927865
Old  loss*** tensor(2490.1050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2064.9910, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641314
Old  loss*** tensor(2713.1096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2344.4832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683735
Old  loss*** tensor(1428.4900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.4629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88043773
Old  loss*** tensor(1124.7592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(990.2804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77736413
Old  loss*** tensor(2522.7646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1961.1068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886106
Old  loss*** tensor(1145.3850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1014.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860636
Old  loss*** tensor(1641.5485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.7756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735254
Old  loss*** tensor(749.2272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(654.4689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8378345
Old  loss*** tensor(2196.2993, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1840.1353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82723814
Old  loss*** tensor(4188.3911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3464.7969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877113
Old  loss*** tensor(872.5508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(765.3256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89665675
Old  loss*** tensor(713.4069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.6811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914151
Old  loss*** tensor(988.7870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.4197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90819895
Old  loss*** tensor(2265.7041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2057.7102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85271907
Old  loss*** tensor(1627.3729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1387.6919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85591024
Old  loss*** tensor(4001.7866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3425.1702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83355117
Old  loss*** tensor(3246.9746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2706.5195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85305464
Old  loss*** tensor(2719.6714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2320.0283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609913
Old  loss*** tensor(3889.7451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3349.0366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83428013
Old  loss*** tensor(1671.6991, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1394.6654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9048502
Old  loss*** tensor(597.8275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(540.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8396971
Old  loss*** tensor(1012.5390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.2261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084818
Old  loss*** tensor(3646.0823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2947.7913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84901285
Old  loss*** tensor(2044.2391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1735.5853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87006515
Old  loss*** tensor(1413.3700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.7240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7822788
Old  loss*** tensor(3561.3877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2785.9980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851466
Old  loss*** tensor(413.2913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(365.8234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76719654
Old  loss*** tensor(4707.8750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3611.8655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807943
Old  loss*** tensor(985.5296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.0488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847166
Old  loss*** tensor(1307.9021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1108.0101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7339439
Old  loss*** tensor(4165.5366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3057.2700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8289368
Old  loss*** tensor(2885.7554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2392.1089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.856881
Old  loss*** tensor(2159.4558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1850.3967, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89510036
Old  loss*** tensor(1027.0962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.3542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8450351
Old  loss*** tensor(1745.2147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.7677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83105624
Old  loss*** tensor(2890.5713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2402.2273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7859018
Old  loss*** tensor(4370.6660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3434.9143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8369456
Old  loss*** tensor(3732.3330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3123.7598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8392736
Old  loss*** tensor(1520.6078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1276.2059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8679596
Old  loss*** tensor(1289.1542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1118.9337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8564573
Old  loss*** tensor(1186.8613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.4960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841202
Old  loss*** tensor(134.0783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(118.5414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8096073
Old  loss*** tensor(2165.7397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.3988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8979957
Old  loss*** tensor(423.6675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(380.4516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823885
Old  loss*** tensor(589.6946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.3397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79082406
Old  loss*** tensor(3443.1379, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2722.9163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8902117
Old  loss*** tensor(1652.5242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1471.0963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710503
Old  loss*** tensor(1520.5227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1324.4518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784206
Old  loss*** tensor(1262.7913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1109.2618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88096976
Old  loss*** tensor(633.7025, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(558.2728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87194514
Old  loss*** tensor(464.6877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.1821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7588317
Old  loss*** tensor(4536.0200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3442.0757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421972
Old  loss*** tensor(1100.8821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(927.1598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674367
Old  loss*** tensor(767.8129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.0291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8014864
Old  loss*** tensor(3071.4919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2461.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83373547
Old  loss*** tensor(2832.9792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2361.9553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8370453
Old  loss*** tensor(2871.1641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2403.2944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8501961
Old  loss*** tensor(470.1956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.7585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78362846
Old  loss*** tensor(4939.4736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3870.7122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8598962
Old  loss*** tensor(1403.3440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.7301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8432126
Old  loss*** tensor(1574.5570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1327.6863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85713315
Old  loss*** tensor(1389.5626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1191.0402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85454315
Old  loss*** tensor(1862.7991, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1591.8422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8607321
Old  loss*** tensor(1180.2910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1015.9144, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8494623
Old  loss*** tensor(1956.1223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1661.6521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869511
Old  loss*** tensor(3652.8733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3239.9199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84650135
Old  loss*** tensor(3283.0886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2779.1389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87396145
Old  loss*** tensor(735.7418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(643.0099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7941566
Old  loss*** tensor(3261.2876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2589.9731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79009277
Old  loss*** tensor(5294.8379, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4183.4131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84131026
Old  loss*** tensor(1798.5608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1513.1477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162932
Old  loss*** tensor(3092.4050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2524.3091, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83563536
Old  loss*** tensor(1200.2413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.9641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84721255
Old  loss*** tensor(2579.0071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2184.9673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8951922
Old  loss*** tensor(1345.7598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1204.7136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85162234
Old  loss*** tensor(772.7675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.1061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8392
Old  loss*** tensor(1874.9186, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1573.4318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9018254
Old  loss*** tensor(2379.4453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2145.8442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82347184
Old  loss*** tensor(2050.0898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1688.1913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85623884
Old  loss*** tensor(1940.6995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1661.7023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88882494
Old  loss*** tensor(815.6297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(724.9520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85191274
Old  loss*** tensor(2022.7771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1723.2296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78232396
Old  loss*** tensor(4301.4644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3365.1387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86135775
Old  loss*** tensor(858.1467, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.1713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8357453
Old  loss*** tensor(4222.1006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3528.6006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786852
Old  loss*** tensor(2409.6619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2117.3342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90732384
Old  loss*** tensor(3872.5122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3513.6226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480202
Old  loss*** tensor(2215.4097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1878.7122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88089323
Old  loss*** tensor(1083.0668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(954.0662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8456877
Old  loss*** tensor(1646.7871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1392.6676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911239
Old  loss*** tensor(280.5833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(250.0345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8863654
Old  loss*** tensor(462.3518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(409.8127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674363
Old  loss*** tensor(2159.7986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1873.4877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895359
Old  loss*** tensor(800.1729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(716.4420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85585403
Old  loss*** tensor(1502.5804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1285.9895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89675033
Old  loss*** tensor(265.3134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(237.9198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78104126
Old  loss*** tensor(3018.3359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2357.4448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74033844
Old  loss*** tensor(2779.3950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2057.6929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87300414
Old  loss*** tensor(1015.1072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.1927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83847487
Old  loss*** tensor(1812.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1519.7684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85010755
Old  loss*** tensor(1580.6714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1343.7407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88832045
Old  loss*** tensor(1132.8621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.3445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79471385
Old  loss*** tensor(4615.2344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3667.7908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84754014
Old  loss*** tensor(1611.6239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1365.9159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73708653
Old  loss*** tensor(5131.8945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3782.6504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744801
Old  loss*** tensor(1150.5922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.1700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.910543
Old  loss*** tensor(678.7744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(618.0533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495822
Old  loss*** tensor(1542.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1310.2188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78962904
Old  loss*** tensor(2587.9895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2043.5516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86225295
Old  loss*** tensor(698.2719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.0870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758926
Old  loss*** tensor(156.7207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(137.2705, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7891815
Old  loss*** tensor(4557.8311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3596.9558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7949758
Old  loss*** tensor(4294.6045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3414.1067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86039865
Old  loss*** tensor(1300.8894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1119.2834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855522
Old  loss*** tensor(475.1525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(420.7724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84792924
Old  loss*** tensor(2951.6370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2502.7793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7960142
Old  loss*** tensor(4308.3862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3429.5366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88502014
Old  loss*** tensor(1322.6940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1170.6108, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586108
Old  loss*** tensor(929.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(798.0151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78994334
Old  loss*** tensor(3935.7349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3109.0076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451399
Old  loss*** tensor(1884.2516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1592.4562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178668
Old  loss*** tensor(3018.7107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2468.9033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8137567
Old  loss*** tensor(2100.3169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1709.1470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.757635
Old  loss*** tensor(4372.1855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3312.5208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88653123
Old  loss*** tensor(672.3220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(596.0344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84615207
Old  loss*** tensor(3940.2361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3334.0388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820797
Old  loss*** tensor(1726.1747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.6237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8530605
Old  loss*** tensor(1224.9486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.9552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8897158
Old  loss*** tensor(704.4110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(626.7256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889667
Old  loss*** tensor(2683.5972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2385.6284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86747193
Old  loss*** tensor(1008.2903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(874.6635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87938905
Old  loss*** tensor(708.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.1171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87839353
Old  loss*** tensor(199.0845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(174.8745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8919651
Old  loss*** tensor(587.6701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(524.1812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84400976
Old  loss*** tensor(1456.5596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.3505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81296384
Old  loss*** tensor(2373.2622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.3763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7052236
Old  loss*** tensor(4714.6499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3324.8826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8797445
Old  loss*** tensor(1227.0728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.5105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8471179
Old  loss*** tensor(1711.5214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.8604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8599082
Old  loss*** tensor(4064.1968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3494.8362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558034
Old  loss*** tensor(1606.2257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.6134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573626
Old  loss*** tensor(2297.4880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1969.7804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87140167
Old  loss*** tensor(2354.8579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2052.0271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8864231
Old  loss*** tensor(1008.7861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(894.2113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8216182
Old  loss*** tensor(3115.2974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2559.5850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.837561
Old  loss*** tensor(2938.7322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2461.3674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7425011
Old  loss*** tensor(4295.9624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3189.7568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8504653
Old  loss*** tensor(1402.7582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1192.9972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684766
Old  loss*** tensor(1405.0743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.2742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8389951
Old  loss*** tensor(2108.8472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1769.3124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84497374
Old  loss*** tensor(1638.1615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1384.2035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698994
Old  loss*** tensor(395.5802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(344.1150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88625264
Old  loss*** tensor(1047.1005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(927.9955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86813366
Old  loss*** tensor(2220.7070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1927.8705, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81898844
Old  loss*** tensor(2797.9851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.5176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86684597
Old  loss*** tensor(1934.4261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1676.8495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7769693
Old  loss*** tensor(3541.2305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2751.4275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7709492
Old  loss*** tensor(4074.8660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3141.5146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7985348
Old  loss*** tensor(3082.3777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2461.3860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8474915
Old  loss*** tensor(1669.0045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.4672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8965908
Old  loss*** tensor(734.5522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.5928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89588004
Old  loss*** tensor(1004.0452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(899.5041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8430043
Old  loss*** tensor(3436.2117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2896.7412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8630534
Old  loss*** tensor(1345.8206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1161.5150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89756656
Old  loss*** tensor(1642.7776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.5022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8201734
Old  loss*** tensor(2719.4109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2230.3884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8755606
Old  loss*** tensor(512.2564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(448.5115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81637657
Old  loss*** tensor(2207.7979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1802.3944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80467105
Old  loss*** tensor(3962.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3188.8088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89345294
Old  loss*** tensor(1179.0952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.4661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559437
Old  loss*** tensor(855.4136, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(732.1859, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88286304
Old  loss*** tensor(596.3840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(526.5255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745499
Old  loss*** tensor(2443.5034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2136.9658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81510234
Old  loss*** tensor(3331.0217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2715.1235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7785384
Old  loss*** tensor(3106.9126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2418.8508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86256576
Old  loss*** tensor(1201.1178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1036.0431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8611717
Old  loss*** tensor(1295.0732, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1115.2804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86186665
Old  loss*** tensor(1104.9951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(952.3585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81511426
Old  loss*** tensor(2423.0513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1975.0636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8551665
Old  loss*** tensor(2947.1887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2520.3372, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862351
Old  loss*** tensor(1687.5654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1495.5797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7601874
Old  loss*** tensor(5076.8403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3859.3501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85073906
Old  loss*** tensor(2121.3594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1804.7233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8458679
Old  loss*** tensor(1774.2513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1500.7822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7462255
Old  loss*** tensor(5003.0371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3733.3938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759486
Old  loss*** tensor(672.2949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(588.8958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8365973
Old  loss*** tensor(2295.0422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1920.0262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8346636
Old  loss*** tensor(3341.2405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2788.8120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8342301
Old  loss*** tensor(1833.7629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.7803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85531753
Old  loss*** tensor(1793.4478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1533.9673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8925999
Old  loss*** tensor(215.9034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(192.7154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7551272
Old  loss*** tensor(4118.0635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3109.6616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895718
Old  loss*** tensor(388.3391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(347.8423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87637234
Old  loss*** tensor(1525.4908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.8979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85261935
Old  loss*** tensor(2332.6531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1988.8651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8858756
Old  loss*** tensor(457.8969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.6397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8408538
Old  loss*** tensor(1990.5853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1673.7913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86174554
Old  loss*** tensor(1084.5521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(934.6080, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8858864
Old  loss*** tensor(560.7153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.7301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8357014
Old  loss*** tensor(2263.5981, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1891.6921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79970336
Old  loss*** tensor(4373.8052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3497.7466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80449677
Old  loss*** tensor(2087.0439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1679.0201, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7921089
Old  loss*** tensor(2535.5063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2008.3971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85043365
Old  loss*** tensor(4069.0100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3460.4231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85406613
Old  loss*** tensor(1284.4243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1096.9833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8612176
Old  loss*** tensor(930.6699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(801.5093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88091487
Old  loss*** tensor(150.5205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(132.5957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031962
Old  loss*** tensor(2114.4758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1698.3390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7981876
Old  loss*** tensor(3933.1545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3139.3953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552857
Old  loss*** tensor(1883.7798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1611.1699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89615977
Old  loss*** tensor(990.6596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.7893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454913
Old  loss*** tensor(1448.0452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1224.3096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8317834
Old  loss*** tensor(2255.7681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1876.3104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7982131
Old  loss*** tensor(3703.1460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2955.8997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8578073
Old  loss*** tensor(3456.1484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2964.7092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784774
Old  loss*** tensor(598.0569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(525.3795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86550534
Old  loss*** tensor(1917.2518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.3917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8177548
Old  loss*** tensor(2644.4988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2162.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8240958
Old  loss*** tensor(1926.3563, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.5021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89046085
Old  loss*** tensor(811.8410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(722.9127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924074
Old  loss*** tensor(932.8373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(832.4709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879574
Old  loss*** tensor(959.5919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(852.0767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87030745
Old  loss*** tensor(1844.2336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1605.0503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884608
Old  loss*** tensor(93.3508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(82.9386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75010264
Old  loss*** tensor(3723.6440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2793.1152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083309
Old  loss*** tensor(3918.6228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3167.5439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931376
Old  loss*** tensor(1094.0740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(977.1586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82245076
Old  loss*** tensor(4007.0103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3295.5686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8363252
Old  loss*** tensor(1627.6866, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1361.2754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861986
Old  loss*** tensor(1032.7112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(915.1872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8070644
Old  loss*** tensor(3011.2224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2430.2505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8026236
Old  loss*** tensor(3611.6155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2898.7678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8376862
Old  loss*** tensor(2456.9485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.1519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88727486
Old  loss*** tensor(429.7412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(381.2986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86611855
Old  loss*** tensor(2973.2214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2575.1624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8373154
Old  loss*** tensor(3254.5383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2725.0750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8794643
Old  loss*** tensor(1592.3441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1400.4098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869325
Old  loss*** tensor(1146.9956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.3077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8595617
Old  loss*** tensor(1750.5765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1504.7285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89096177
Old  loss*** tensor(1086.3140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(967.8642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7384783
Old  loss*** tensor(4980.3291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3677.8650, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911799
Old  loss*** tensor(1559.0887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1389.4286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781495
Old  loss*** tensor(1206.8142, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.7633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8881072
Old  loss*** tensor(852.2382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(756.8789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8317342
Old  loss*** tensor(4223.1577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3512.5447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8340444
Old  loss*** tensor(3153.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2629.7429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87254095
Old  loss*** tensor(2068.7148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1805.0385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85877216
Old  loss*** tensor(791.1807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(679.4439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88745457
Old  loss*** tensor(1202.2057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1066.9030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9007793
Old  loss*** tensor(1012.7231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(912.2401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89290047
Old  loss*** tensor(534.7900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(477.5143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.826316
Old  loss*** tensor(3962.2700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3274.0872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85120624
Old  loss*** tensor(1696.4038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.9895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83792126
Old  loss*** tensor(2132.9529, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1787.2466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869295
Old  loss*** tensor(1097.6749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(954.2033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398433
Old  loss*** tensor(1929.5432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1620.5139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84164524
Old  loss*** tensor(1695.8954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1427.3423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024883
Old  loss*** tensor(2471.0554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.9932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8657861
Old  loss*** tensor(1936.1399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1676.2830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9047123
Old  loss*** tensor(310.3585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(280.7852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8059133
Old  loss*** tensor(2778.3765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2239.1306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7800344
Old  loss*** tensor(4188.2368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3266.9690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81569314
Old  loss*** tensor(2550.4707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2080.4014, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.883561
Old  loss*** tensor(2212.3123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1954.7129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8448806
Old  loss*** tensor(4391.9570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3710.6792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8911841
Old  loss*** tensor(1477.2314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.4851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86742
Old  loss*** tensor(2094.3445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1816.6763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749767
Old  loss*** tensor(705.8148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(617.5715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619058
Old  loss*** tensor(1257.0076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1083.4221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80146074
Old  loss*** tensor(4479.9331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3590.4905, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85538363
Old  loss*** tensor(1814.2554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1551.8844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89980257
Old  loss*** tensor(692.9688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.5351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85629463
Old  loss*** tensor(2632.2734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2254.0017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86980444
Old  loss*** tensor(1378.4795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.0076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8933519
Old  loss*** tensor(681.5848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(608.8951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75002
Old  loss*** tensor(4715.8428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3536.9766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824229
Old  loss*** tensor(697.6870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(615.6550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570795
Old  loss*** tensor(2594.4834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2223.6785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716348
Old  loss*** tensor(852.0165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(742.6472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165269
Old  loss*** tensor(3595.6187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2935.9194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79984814
Old  loss*** tensor(3290.1201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2631.5964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8692939
Old  loss*** tensor(1346.8999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1170.8519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7908456
Old  loss*** tensor(2840.1646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2246.1316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752961
Old  loss*** tensor(506.2109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(443.0845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8912808
Old  loss*** tensor(184.4507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(164.3974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7716921
Old  loss*** tensor(5241.3896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4044.7390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8245246
Old  loss*** tensor(3099.5850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2555.6841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8354353
Old  loss*** tensor(2645.6421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2210.2627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89468884
Old  loss*** tensor(1578.2754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.0654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7976343
Old  loss*** tensor(4012.8428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3200.7810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724278
Old  loss*** tensor(475.0978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(414.4885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8363125
Old  loss*** tensor(3204.9419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2680.3328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8695466
Old  loss*** tensor(1638.5179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1424.7677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8386839
Old  loss*** tensor(2168.5481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1818.7264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85089445
Old  loss*** tensor(3096.4614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2634.7620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8039399
Old  loss*** tensor(1988.5616, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.6840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80744094
Old  loss*** tensor(3155.6506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2548.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8422349
Old  loss*** tensor(1815.6256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.1832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827976
Old  loss*** tensor(1174.0518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1036.4501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88895845
Old  loss*** tensor(385.2189, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(342.4436, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.814117
Old  loss*** tensor(3868.0210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3149.0217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8065629
Old  loss*** tensor(2312.0571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.8195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8319258
Old  loss*** tensor(2406.5320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2002.0560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88025
Old  loss*** tensor(1247.4166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.0385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647545
Old  loss*** tensor(1079.0140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(933.0822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89545876
Old  loss*** tensor(655.3392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.8293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.809367
Old  loss*** tensor(2578.3250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2086.8110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8424753
Old  loss*** tensor(2088.2178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.2719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8888901
Old  loss*** tensor(2578.1128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.6589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8135139
Old  loss*** tensor(2517.7256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2048.2046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8400125
Old  loss*** tensor(2205.0037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1852.2306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769131
Old  loss*** tensor(1159.9486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.1741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86316645
Old  loss*** tensor(4089.1143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3529.5862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7645087
Old  loss*** tensor(5193.3926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3970.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929001
Old  loss*** tensor(453.8557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872724
Old  loss*** tensor(946.4623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.0004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86034095
Old  loss*** tensor(2726.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2345.2925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83704317
Old  loss*** tensor(1113.5873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(932.1206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90502787
Old  loss*** tensor(1291.3948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1168.7483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88676983
Old  loss*** tensor(706.7253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(626.7026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84605336
Old  loss*** tensor(1999.2133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.4410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8086916
Old  loss*** tensor(3600.1919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2911.4451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81783384
Old  loss*** tensor(1908.6576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1560.9647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8950804
Old  loss*** tensor(195.9990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(175.4349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80397046
Old  loss*** tensor(4131.3296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3321.4670, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89356536
Old  loss*** tensor(1211.3676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1082.4360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208208
Old  loss*** tensor(3825.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3139.7720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88917243
Old  loss*** tensor(985.8381, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(876.5800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88482356
Old  loss*** tensor(1338.3416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1184.1962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88901615
Old  loss*** tensor(556.3584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(494.6116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816527
Old  loss*** tensor(1151.3346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1015.0773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86729455
Old  loss*** tensor(4134.2944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.6511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88550913
Old  loss*** tensor(1703.2310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1508.2266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85772586
Old  loss*** tensor(1044.8444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(896.1900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664438
Old  loss*** tensor(1454.2817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.0535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8694935
Old  loss*** tensor(1502.2101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.1619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85192674
Old  loss*** tensor(1641.6016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1398.5243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7741827
Old  loss*** tensor(3878.1062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3002.3625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.928553
Old  loss*** tensor(779.1835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(723.5132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81443995
Old  loss*** tensor(3204.7505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2610.0769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855903
Old  loss*** tensor(915.3726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(783.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88025486
Old  loss*** tensor(2796.4053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2461.5493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8367313
Old  loss*** tensor(2492.3049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2085.3896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8721981
Old  loss*** tensor(166.1439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(144.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915351
Old  loss*** tensor(905.2639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(807.0745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9052968
Old  loss*** tensor(1286.1396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1164.3381, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83344674
Old  loss*** tensor(2871.5437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2393.2788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84266603
Old  loss*** tensor(3020.1877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2545.0095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539802
Old  loss*** tensor(1811.4984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1546.9838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850356
Old  loss*** tensor(626.0848, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.1073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8578009
Old  loss*** tensor(2748.6194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2357.7681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8377329
Old  loss*** tensor(2805.2874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2350.0815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781485
Old  loss*** tensor(410.9195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(360.8484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83841705
Old  loss*** tensor(4008.3843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3360.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7686229
Old  loss*** tensor(4769.5640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3665.9958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8122375
Old  loss*** tensor(4089.9875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3322.0413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77210224
Old  loss*** tensor(3420.2080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2640.7502, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88175666
Old  loss*** tensor(794.5430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(700.5936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853492
Old  loss*** tensor(3223.9932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2751.6523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86785746
Old  loss*** tensor(1566.0798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.1340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9018289
Old  loss*** tensor(1141.5576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1029.4896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.868281
Old  loss*** tensor(1478.6666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1283.8982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865061
Old  loss*** tensor(1149.3354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1018.8929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658424
Old  loss*** tensor(3079.9888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2666.7849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84188426
Old  loss*** tensor(1995.5945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1680.0596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88423
Old  loss*** tensor(1584.4845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1401.0487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90884966
Old  loss*** tensor(791.9897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.7996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8174416
Old  loss*** tensor(2856.5159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2335.0349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8486098
Old  loss*** tensor(4010.3098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3403.1882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85928464
Old  loss*** tensor(1403.7666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.2351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9054451
Old  loss*** tensor(869.9305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(787.6743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83171
Old  loss*** tensor(2420.6545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2013.2826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061309
Old  loss*** tensor(3888.6863, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3134.7900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7428645
Old  loss*** tensor(3273.2751, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2431.5999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82359415
Old  loss*** tensor(1318.5898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.9829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8430892
Old  loss*** tensor(1673.1790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.6392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773184
Old  loss*** tensor(550.7503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.1834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84608537
Old  loss*** tensor(3271.1274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2767.6531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85368234
Old  loss*** tensor(1723.9076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1471.6694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88753045
Old  loss*** tensor(223.7432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(198.5789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9023843
Old  loss*** tensor(531.6953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(479.7935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84359175
Old  loss*** tensor(2890.9045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2438.7432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7542589
Old  loss*** tensor(4729.6787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3567.4021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75687623
Old  loss*** tensor(4857.1016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3676.2246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622321
Old  loss*** tensor(1085.2050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(935.6985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790891
Old  loss*** tensor(794.2987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(698.2593, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84283304
Old  loss*** tensor(2095.8923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1766.4873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85553086
Old  loss*** tensor(1914.0150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1637.4989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8484283
Old  loss*** tensor(3116.5752, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2644.1907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629385
Old  loss*** tensor(2152.0381, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1857.0765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8666653
Old  loss*** tensor(1499.2725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1299.3674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75835824
Old  loss*** tensor(4803.2222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3642.5630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84362006
Old  loss*** tensor(1734.1653, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1462.9766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89608765
Old  loss*** tensor(261.4006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(234.2378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85603845
Old  loss*** tensor(1172.1923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.4417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86225784
Old  loss*** tensor(1022.0447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.2661, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9006238
Old  loss*** tensor(702.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.6440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83940077
Old  loss*** tensor(3711.5474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3115.4758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87888217
Old  loss*** tensor(1291.9454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1135.4678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85347396
Old  loss*** tensor(1903.7511, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1624.8020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87093633
Old  loss*** tensor(1390.0123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1210.6122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518308
Old  loss*** tensor(2065.4810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.4403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083662
Old  loss*** tensor(3371.3738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2725.3044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80955076
Old  loss*** tensor(2969.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.2078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88253367
Old  loss*** tensor(531.1077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(468.7205, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841392
Old  loss*** tensor(226.6008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.3467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82931393
Old  loss*** tensor(4412.3218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3659.2000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799169
Old  loss*** tensor(2874.1421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2529.0061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717228
Old  loss*** tensor(1556.6158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1356.9375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85311234
Old  loss*** tensor(2315.4607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1975.3481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8404612
Old  loss*** tensor(1364.4880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.7992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8242359
Old  loss*** tensor(2692.8608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2219.5527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8461411
Old  loss*** tensor(2752.3103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2328.8428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7887162
Old  loss*** tensor(4324.3779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3410.7070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89090544
Old  loss*** tensor(509.2554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(453.6984, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8468725
Old  loss*** tensor(1670.6254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.8066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89496917
Old  loss*** tensor(663.9174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(594.1855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8099693
Old  loss*** tensor(3165.9280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2564.3044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8619273
Old  loss*** tensor(2846.1509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2453.1750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87334776
Old  loss*** tensor(550.6257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.8878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8507699
Old  loss*** tensor(1328.4170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1130.1771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7972822
Old  loss*** tensor(2911.8394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2321.5579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75279814
Old  loss*** tensor(3551.9038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2673.8667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87034
Old  loss*** tensor(1903.7098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1656.8748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8567587
Old  loss*** tensor(1908.7216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1635.3138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89242804
Old  loss*** tensor(556.7377, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.8484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.854417
Old  loss*** tensor(1382.1694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1180.9491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8256694
Old  loss*** tensor(3427.8999, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2830.3120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127315
Old  loss*** tensor(3356.5012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2727.9343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901932
Old  loss*** tensor(1180.9022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1051.2312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85836387
Old  loss*** tensor(1638.7961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1406.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.739051
Old  loss*** tensor(5287.7949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3907.9500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8908099
Old  loss*** tensor(907.9659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(808.8251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80392635
Old  loss*** tensor(4756.4219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3823.8130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89825225
Old  loss*** tensor(945.1782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.0085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83526576
Old  loss*** tensor(1661.4926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1387.7878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84231746
Old  loss*** tensor(2499.8420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2105.6606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8300461
Old  loss*** tensor(3056.9734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2537.4290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88341606
Old  loss*** tensor(788.6262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(696.6851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87228465
Old  loss*** tensor(1316.3939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1148.2703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7393937
Old  loss*** tensor(4169.2002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3082.6804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89067584
Old  loss*** tensor(1212.3536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.8141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8274289
Old  loss*** tensor(2720.4014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2250.9387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804599
Old  loss*** tensor(543.9204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.9001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8364747
Old  loss*** tensor(1971.2629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1648.9116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87649786
Old  loss*** tensor(2138.0713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1874.0149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717752
Old  loss*** tensor(1118.1382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.7651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.811116
Old  loss*** tensor(3530.5913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2863.7190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81262785
Old  loss*** tensor(2364.6836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1921.6078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608134
Old  loss*** tensor(1458.1891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.2286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83569884
Old  loss*** tensor(4546.4839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3799.4912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7926028
Old  loss*** tensor(3666.8818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2906.3806, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8817001
Old  loss*** tensor(957.7228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.4243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790925
Old  loss*** tensor(1414.3842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.3745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86096853
Old  loss*** tensor(1987.3748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.0671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83597064
Old  loss*** tensor(1629.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1362.4097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88601375
Old  loss*** tensor(205.3195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(181.9159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8478253
Old  loss*** tensor(2207.1938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1871.3148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8532029
Old  loss*** tensor(3073.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2621.8953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8547504
Old  loss*** tensor(1149.8376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(982.8242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89350164
Old  loss*** tensor(1289.3716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1152.0557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8213864
Old  loss*** tensor(3637.3918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2987.7041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8679343
Old  loss*** tensor(2143.6519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1860.5490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8317474
Old  loss*** tensor(3878.9214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3226.2827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7501681
Old  loss*** tensor(1622.2439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.9556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8852047
Old  loss*** tensor(781.2950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(691.6060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87800044
Old  loss*** tensor(1076.2086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.9116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924297
Old  loss*** tensor(138.7899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(123.8603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760334
Old  loss*** tensor(718.4390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.3766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87665755
Old  loss*** tensor(1146.3984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1004.9988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641114
Old  loss*** tensor(713.8407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(616.8379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813449
Old  loss*** tensor(577.2782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(508.7812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8243281
Old  loss*** tensor(4313.3843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3555.6440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608051
Old  loss*** tensor(1790.4507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1541.2291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84470975
Old  loss*** tensor(2061.9968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1741.7888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87955314
Old  loss*** tensor(759.9512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.4175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503398
Old  loss*** tensor(1661.3042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.6730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736416
Old  loss*** tensor(1528.0753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1334.9902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8106625
Old  loss*** tensor(3677.3450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2981.0857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84247226
Old  loss*** tensor(2260.8303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.6868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80706406
Old  loss*** tensor(4626.3315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3733.7458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928877
Old  loss*** tensor(456.1526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(407.2931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83133435
Old  loss*** tensor(2171.0481, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1804.8668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439969
Old  loss*** tensor(3986.3816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3364.4937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88168395
Old  loss*** tensor(1012.6602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(892.8463, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85872424
Old  loss*** tensor(2380.3755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2044.0862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8026996
Old  loss*** tensor(2795.9712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2244.3250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7796089
Old  loss*** tensor(4100.8311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3197.0444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85173464
Old  loss*** tensor(2905.5376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2474.7471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8023467
Old  loss*** tensor(4573.3472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3669.4102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8128189
Old  loss*** tensor(3140.3611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2552.5447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84433115
Old  loss*** tensor(978.2933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.0035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9042023
Old  loss*** tensor(1133.4475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1024.8658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703976
Old  loss*** tensor(1200.7324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1045.1146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86719143
Old  loss*** tensor(876.2416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.8692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678516
Old  loss*** tensor(1130.1254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(980.7811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80298454
Old  loss*** tensor(2091.5254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1679.4625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78520626
Old  loss*** tensor(2406.8557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1889.8782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86272985
Old  loss*** tensor(1622.7150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.9646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560276
Old  loss*** tensor(1865.9116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1597.2719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857409
Old  loss*** tensor(417.3106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(369.6290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89233637
Old  loss*** tensor(1330.4689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1187.2257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88262933
Old  loss*** tensor(933.5271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(823.9584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8869451
Old  loss*** tensor(1325.2894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1175.4590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622668
Old  loss*** tensor(2415.8276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.0879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8188858
Old  loss*** tensor(2926.5249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2396.4897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85488784
Old  loss*** tensor(1866.0826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1595.2914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87685764
Old  loss*** tensor(412.7038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(361.8825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8517746
Old  loss*** tensor(1153.0162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(982.1099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8102808
Old  loss*** tensor(3041.9565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2464.8389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8896048
Old  loss*** tensor(1757.2054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.2184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86983764
Old  loss*** tensor(661.6340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(575.5142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8176417
Old  loss*** tensor(2144.8765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.7404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80715036
Old  loss*** tensor(3259.4832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2630.8931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8964455
Old  loss*** tensor(1184.3279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.6854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519584
Old  loss*** tensor(1323.9082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1127.9147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8173381
Old  loss*** tensor(3423.4541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2798.1194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8584905
Old  loss*** tensor(1551.7976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1332.2035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.808125
Old  loss*** tensor(4258.2803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3441.2229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89821637
Old  loss*** tensor(1299.6211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1167.3409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770014
Old  loss*** tensor(133.6578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(117.2181, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563124
Old  loss*** tensor(3927.0271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.7620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914572
Old  loss*** tensor(359.7830, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(320.7312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024571
Old  loss*** tensor(2318.3130, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1860.3467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8486264
Old  loss*** tensor(1815.3580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1540.5607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542356
Old  loss*** tensor(2205.8555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1884.3202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88848954
Old  loss*** tensor(1160.1046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1030.7408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87799656
Old  loss*** tensor(1012.0814, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.6040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81647223
Old  loss*** tensor(3482.0371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2842.9866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87721413
Old  loss*** tensor(955.7350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(838.3842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8218534
Old  loss*** tensor(2696.0698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2215.7742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88724464
Old  loss*** tensor(166.8575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(148.0434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85914373
Old  loss*** tensor(752.7554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.7251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7766067
Old  loss*** tensor(2353.9875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1828.1224, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387726
Old  loss*** tensor(3226.0598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2705.9307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7427147
Old  loss*** tensor(4715.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3502.3960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81520516
Old  loss*** tensor(2149.1506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1751.9987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310132
Old  loss*** tensor(3467.7725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2881.7646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744406
Old  loss*** tensor(1734.1450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1516.4069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827244
Old  loss*** tensor(684.3739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(604.1135, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86783695
Old  loss*** tensor(1425.5347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1237.1317, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800802
Old  loss*** tensor(574.9890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(506.0365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89105463
Old  loss*** tensor(1286.4155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.2665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86701524
Old  loss*** tensor(1109.1559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.6550, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8981445
Old  loss*** tensor(553.2437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.8927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79546124
Old  loss*** tensor(2699.7258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2147.5273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609195
Old  loss*** tensor(980.4479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.0867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79885536
Old  loss*** tensor(3746.2561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2992.7168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881533
Old  loss*** tensor(1675.6348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.1274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83754945
Old  loss*** tensor(3931.1597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3292.5405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704424
Old  loss*** tensor(1741.4921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.8685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87169695
Old  loss*** tensor(792.0214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.4026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78009224
Old  loss*** tensor(4475.3008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3491.1475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7590339
Old  loss*** tensor(3497.5557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2654.7634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7940795
Old  loss*** tensor(2913.7803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2313.7732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87217635
Old  loss*** tensor(1870.5746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1631.4709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387377
Old  loss*** tensor(1742.9668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1461.8920, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83058095
Old  loss*** tensor(2162.3979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1796.0465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347749
Old  loss*** tensor(2880.0798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.2185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7817253
Old  loss*** tensor(3332.7878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2605.3245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7291766
Old  loss*** tensor(4094.7109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2985.7673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85383785
Old  loss*** tensor(4536.5635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3873.4895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91554594
Old  loss*** tensor(728.3232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.8134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90868175
Old  loss*** tensor(1051.8005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(955.7520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636051
Old  loss*** tensor(3049.2742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.3687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673974
Old  loss*** tensor(1821.1813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1579.6880, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8894944
Old  loss*** tensor(1005.5728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(894.4514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855512
Old  loss*** tensor(1297.8986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.3556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8074138
Old  loss*** tensor(3183.8989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2570.7239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84114647
Old  loss*** tensor(3477.3792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2924.9851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8935137
Old  loss*** tensor(188.8578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(168.7470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284502
Old  loss*** tensor(4950.0518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4100.8716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80969644
Old  loss*** tensor(2361.1333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1911.8013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80686694
Old  loss*** tensor(4914.1372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3965.0549, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814413
Old  loss*** tensor(496.3750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(437.5254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929479
Old  loss*** tensor(474.7473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(423.9246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90173376
Old  loss*** tensor(745.3937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(672.1467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83469087
Old  loss*** tensor(2762.8521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2306.1274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86019844
Old  loss*** tensor(1683.3721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1448.0341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8084077
Old  loss*** tensor(3550.3713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2870.1477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826699
Old  loss*** tensor(1517.5813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1339.5233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86852574
Old  loss*** tensor(3856.3010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3349.2966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864216
Old  loss*** tensor(2361.6069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2040.9386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8737838
Old  loss*** tensor(843.7794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(737.2808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87893367
Old  loss*** tensor(1102.6643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(969.1688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79884505
Old  loss*** tensor(2500.6750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1997.6519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8743853
Old  loss*** tensor(2081.2712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1819.8330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85813224
Old  loss*** tensor(2955.7590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2536.4321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84735334
Old  loss*** tensor(4265.5088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3614.3931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760816
Old  loss*** tensor(495.0909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(433.7401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7431649
Old  loss*** tensor(4861.0654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.5732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82592297
Old  loss*** tensor(4225.0693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3489.5818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.818124
Old  loss*** tensor(2135.0176, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1746.7091, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87029415
Old  loss*** tensor(2009.0133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1748.4325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795968
Old  loss*** tensor(1167.6338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1027.0470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678838
Old  loss*** tensor(1210.0330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1050.1680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8687973
Old  loss*** tensor(1025.0875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.5933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7705156
Old  loss*** tensor(3840.5291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2959.1877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85089576
Old  loss*** tensor(2185.7971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1859.8855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773263
Old  loss*** tensor(1335.8702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1171.9941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88498384
Old  loss*** tensor(1233.8960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1091.9780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870034
Old  loss*** tensor(556.0746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.8038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9051369
Old  loss*** tensor(928.8651, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(840.7501, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775038
Old  loss*** tensor(251.5402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(220.7275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847947
Old  loss*** tensor(1238.1123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.8536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764132
Old  loss*** tensor(516.6975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(452.8405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401675
Old  loss*** tensor(3040.8870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2554.8545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86029905
Old  loss*** tensor(2229.4084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1917.9580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77174956
Old  loss*** tensor(4632.2710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3574.9531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87632716
Old  loss*** tensor(1812.5068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.3490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80192184
Old  loss*** tensor(4364.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.6348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78960675
Old  loss*** tensor(3316.6265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2618.8306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78958
Old  loss*** tensor(2977.5774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2351.0354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609191
Old  loss*** tensor(1470.9312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1266.3528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83534527
Old  loss*** tensor(1340.0226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1119.3815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509235
Old  loss*** tensor(1693.7701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1441.2688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7854023
Old  loss*** tensor(3756.5393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2950.3945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85990727
Old  loss*** tensor(3563.3865, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3064.1819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73926044
Old  loss*** tensor(4265.1836, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.0815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75647825
Old  loss*** tensor(3167.4333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2396.0945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7702384
Old  loss*** tensor(4128.7886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3180.1516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79986817
Old  loss*** tensor(4390.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3511.5239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8508109
Old  loss*** tensor(1327.3291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1129.3060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76181686
Old  loss*** tensor(4741.9932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.5303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85292447
Old  loss*** tensor(2392.3259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2040.4733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531941
Old  loss*** tensor(1814.1907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1547.8568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9016713
Old  loss*** tensor(772.8730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(696.8774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801446
Old  loss*** tensor(1470.5735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.3173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90108275
Old  loss*** tensor(1055.1497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(950.7772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814789
Old  loss*** tensor(1789.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1577.0183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85797596
Old  loss*** tensor(2095.2595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1797.6823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744968
Old  loss*** tensor(845.3681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.2717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83629227
Old  loss*** tensor(2684.9575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2245.4092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8838303
Old  loss*** tensor(762.8476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.2278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8210774
Old  loss*** tensor(2933.3955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2408.5447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8147033
Old  loss*** tensor(3615.4963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2945.5566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8513448
Old  loss*** tensor(2478.3623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2109.9409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8340806
Old  loss*** tensor(2235.8064, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.8427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84808064
Old  loss*** tensor(1746.9344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1481.5413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839677
Old  loss*** tensor(2149.3220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1804.7362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442714
Old  loss*** tensor(4019.4124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3393.4751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738763
Old  loss*** tensor(846.7203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(739.9288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8335376
Old  loss*** tensor(2397.2209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1998.1737, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8490227
Old  loss*** tensor(1165.4060, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.4561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8485229
Old  loss*** tensor(1601.6182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.0096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629936
Old  loss*** tensor(1400.8523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.9265, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7679933
Old  loss*** tensor(4347.4907, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3338.8435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760008
Old  loss*** tensor(453.1249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(396.9378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83312345
Old  loss*** tensor(3189.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2657.6174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8456992
Old  loss*** tensor(1415.4686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.0607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91270196
Old  loss*** tensor(897.4762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(819.1283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7411437
Old  loss*** tensor(4322.3765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3203.5022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801476
Old  loss*** tensor(461.9002, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(406.5404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86090755
Old  loss*** tensor(1099.5754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(946.6328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81951874
Old  loss*** tensor(2585.7510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2119.0713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89998263
Old  loss*** tensor(662.1014, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.8798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87481165
Old  loss*** tensor(1470.6766, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1286.5651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800156
Old  loss*** tensor(695.5592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(612.1030, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91200787
Old  loss*** tensor(1315.4537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.7041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929906
Old  loss*** tensor(968.9579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(865.2703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8387724
Old  loss*** tensor(2656.4321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2228.1421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8018625
Old  loss*** tensor(3566.1455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2859.5583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8669385
Old  loss*** tensor(627.7445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(544.2159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85225105
Old  loss*** tensor(1896.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1616.2523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857606
Old  loss*** tensor(592.4394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(508.0796, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87935734
Old  loss*** tensor(1425.0309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1253.1113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86874056
Old  loss*** tensor(1049.3221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.5887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520318
Old  loss*** tensor(941.3179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.0328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82586753
Old  loss*** tensor(1761.0824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1454.4208, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8059864
Old  loss*** tensor(2799.3696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2256.2539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8986819
Old  loss*** tensor(1555.3162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1397.7345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680517
Old  loss*** tensor(3352.4749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2910.1216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7894566
Old  loss*** tensor(3212.5330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2536.1553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8586801
Old  loss*** tensor(1516.1271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1301.8682, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8376999
Old  loss*** tensor(3232.7197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2708.0491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8993559
Old  loss*** tensor(848.4996, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(763.1031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801985
Old  loss*** tensor(585.1460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(515.0446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.68368936
Old  loss*** tensor(4678.1421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3198.3960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8092077
Old  loss*** tensor(2547.6384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2061.5686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78651935
Old  loss*** tensor(3185.8418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2505.7263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86826503
Old  loss*** tensor(883.7712, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(767.3477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8978466
Old  loss*** tensor(337.8445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(303.3325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86448056
Old  loss*** tensor(3932.8442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3399.8674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8439398
Old  loss*** tensor(1535.9703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1296.2665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88168186
Old  loss*** tensor(975.7244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(860.2785, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82945
Old  loss*** tensor(2677.6648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2220.9890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.883355
Old  loss*** tensor(132.1347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(116.7219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83673906
Old  loss*** tensor(1448.9882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1212.4250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480366
Old  loss*** tensor(2962.2834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2512.1248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459972
Old  loss*** tensor(2006.7367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1697.6936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8662485
Old  loss*** tensor(856.3301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(741.7947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74252963
Old  loss*** tensor(3352.0557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2489.0007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84160507
Old  loss*** tensor(3537.9019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2977.5161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8340654
Old  loss*** tensor(2213.2312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1845.9795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8580835
Old  loss*** tensor(4144.9844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3556.7427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8307989
Old  loss*** tensor(3976.9895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3304.0786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862548
Old  loss*** tensor(1105.6570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(979.8938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864456
Old  loss*** tensor(1615.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1396.0990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8909595
Old  loss*** tensor(463.2283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.7176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86620724
Old  loss*** tensor(1586.1932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.9720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85480845
Old  loss*** tensor(2494.7417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.5264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78033936
Old  loss*** tensor(2648.5183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2066.7432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8413574
Old  loss*** tensor(2166.0356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1822.4102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77843904
Old  loss*** tensor(4992.4224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3886.2964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774604
Old  loss*** tensor(611.5292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(536.5927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86689967
Old  loss*** tensor(1024.5320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.1664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7771069
Old  loss*** tensor(4569.3169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3550.8477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85063636
Old  loss*** tensor(1277.5665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1086.7445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82629615
Old  loss*** tensor(2629.3899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2172.6548, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.784874
Old  loss*** tensor(3828.2573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3004.6997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80139345
Old  loss*** tensor(3556.2051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2849.9194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8555472
Old  loss*** tensor(1615.5143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1382.1487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88387084
Old  loss*** tensor(162.5260, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(143.6520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86383444
Old  loss*** tensor(1400.2588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1209.5918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847747
Old  loss*** tensor(1046.5792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.9868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208396
Old  loss*** tensor(3305.3782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2713.1853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281902
Old  loss*** tensor(1508.5267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.3470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8309555
Old  loss*** tensor(3467.7007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2881.5049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72140396
Old  loss*** tensor(4329.8232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3123.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83631533
Old  loss*** tensor(2845.1384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2379.4329, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641958
Old  loss*** tensor(1449.2885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1252.4690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85141516
Old  loss*** tensor(2511.2478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2138.1145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87965566
Old  loss*** tensor(1197.9320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.7677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87709236
Old  loss*** tensor(623.2546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(546.6519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8429897
Old  loss*** tensor(3437.8743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2898.0925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8972082
Old  loss*** tensor(263.9139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(236.7857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860724
Old  loss*** tensor(1168.9965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1035.8156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401449
Old  loss*** tensor(2075.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1743.5509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.774306
Old  loss*** tensor(4305.6338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3333.8782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8134844
Old  loss*** tensor(2159.2573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1756.5221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634022
Old  loss*** tensor(4166.9526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3597.7561, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8333261
Old  loss*** tensor(2742.4705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2285.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9023567
Old  loss*** tensor(1110.2734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.8627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87553346
Old  loss*** tensor(1332.5386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.6821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85081744
Old  loss*** tensor(2617.9355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2227.3853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87086666
Old  loss*** tensor(747.0392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.5715, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.827881
Old  loss*** tensor(1885.1038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1560.6416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8845571
Old  loss*** tensor(1521.6445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1345.9816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88771695
Old  loss*** tensor(1752.6212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1555.8315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85224533
Old  loss*** tensor(1776.8390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1514.3027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.737714
Old  loss*** tensor(3215.1655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2371.8726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86053276
Old  loss*** tensor(1532.8585, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1319.0750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77988416
Old  loss*** tensor(3602.8811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2809.8298, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84569156
Old  loss*** tensor(2220.6973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1878.0249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8234811
Old  loss*** tensor(4083.1353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.3845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83650994
Old  loss*** tensor(3223.0950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2696.1509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878989
Old  loss*** tensor(1144.4243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1005.9363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87919426
Old  loss*** tensor(323.3140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(284.2558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85720515
Old  loss*** tensor(1781.4010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1527.0261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84800667
Old  loss*** tensor(2945.8594, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2498.1084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82987946
Old  loss*** tensor(2964.4910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2460.1702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83450377
Old  loss*** tensor(1664.1246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1388.7183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924031
Old  loss*** tensor(755.8840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.5532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.767398
Old  loss*** tensor(4337.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3328.5723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7631032
Old  loss*** tensor(2252.8435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1719.1521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87303716
Old  loss*** tensor(982.9262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(858.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82557297
Old  loss*** tensor(2101.7896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1735.1807, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88099027
Old  loss*** tensor(855.8575, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(754.0021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82850355
Old  loss*** tensor(2284.9973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1893.1284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85261154
Old  loss*** tensor(2249.9065, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1918.2963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84744585
Old  loss*** tensor(2787.7590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2362.4749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.761336
Old  loss*** tensor(4137.0474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3149.6831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773232
Old  loss*** tensor(904.5236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(793.5596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86469764
Old  loss*** tensor(1198.6984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1036.5116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84259844
Old  loss*** tensor(1410.3868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1188.3898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8191613
Old  loss*** tensor(3181.0703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2605.8096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8294442
Old  loss*** tensor(2945.4688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2443.1021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88255024
Old  loss*** tensor(489.7050, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(432.1893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876703
Old  loss*** tensor(759.6313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.3021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8596372
Old  loss*** tensor(2193.4297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.5537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809333
Old  loss*** tensor(3686.9380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3247.9463, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79189026
Old  loss*** tensor(4064.6042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3218.7205, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8584471
Old  loss*** tensor(2059.7068, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1768.1493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80919504
Old  loss*** tensor(2087.8782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1689.5006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590894
Old  loss*** tensor(1839.1678, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1580.0095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813597
Old  loss*** tensor(958.4030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84793854
Old  loss*** tensor(2351.3193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1993.7743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8709072
Old  loss*** tensor(536.9296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(467.6158, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90331155
Old  loss*** tensor(899.4860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.5161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7639973
Old  loss*** tensor(3172.3811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2423.6907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083064
Old  loss*** tensor(2562.9250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2071.6287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86081874
Old  loss*** tensor(1423.1101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1225.0398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9304532
Old  loss*** tensor(1180.0532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1097.9843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807524
Old  loss*** tensor(1172.6075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1032.7769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90207994
Old  loss*** tensor(589.9771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.2065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86712754
Old  loss*** tensor(1072.4304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.9340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89036417
Old  loss*** tensor(192.1173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(171.0543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8854426
Old  loss*** tensor(715.3311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(633.3846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89511454
Old  loss*** tensor(497.1756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(445.0291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88112974
Old  loss*** tensor(370.6493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(326.5901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8040653
Old  loss*** tensor(5126.7554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4122.2461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89685464
Old  loss*** tensor(834.8388, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(748.7291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748212
Old  loss*** tensor(871.0289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.9946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87770855
Old  loss*** tensor(1811.3346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1589.8239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594017
Old  loss*** tensor(2623.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.0093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76037014
Old  loss*** tensor(5121.4512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3894.1985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.809057
Old  loss*** tensor(3493.4443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2826.3955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939895
Old  loss*** tensor(180.6515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(161.5006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815303
Old  loss*** tensor(973.0406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.7648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86600256
Old  loss*** tensor(2025.0798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.7244, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88592803
Old  loss*** tensor(872.3366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(772.8275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739481
Old  loss*** tensor(1369.9950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1197.3046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418205
Old  loss*** tensor(2441.4675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.2773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90392786
Old  loss*** tensor(709.7600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(641.5718, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849998
Old  loss*** tensor(766.4043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.2676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8485862
Old  loss*** tensor(2521.3491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.5820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9045781
Old  loss*** tensor(714.9194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(646.7004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8431253
Old  loss*** tensor(3246.4109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2737.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772057
Old  loss*** tensor(1096.0591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.4693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8742135
Old  loss*** tensor(2447.9075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.9939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76272774
Old  loss*** tensor(3868.2170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2950.3965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77073073
Old  loss*** tensor(2672.2336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.5725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87449074
Old  loss*** tensor(1531.9480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1339.6743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889674
Old  loss*** tensor(1135.4662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.3924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8835852
Old  loss*** tensor(149.0747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(131.7202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880706
Old  loss*** tensor(1392.0693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1236.2559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85224134
Old  loss*** tensor(2016.6128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1718.6407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8437449
Old  loss*** tensor(3921.8052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3309.0029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86368144
Old  loss*** tensor(2240.5693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1935.1382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8707074
Old  loss*** tensor(1191.8013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1037.7102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8234104
Old  loss*** tensor(2749.7153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2264.1443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542199
Old  loss*** tensor(992.7339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(848.0131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8990755
Old  loss*** tensor(944.4546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(849.1360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84892935
Old  loss*** tensor(1548.9989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1314.9906, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801732
Old  loss*** tensor(3047.4106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2682.2493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85782075
Old  loss*** tensor(3777.9211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3240.7791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8970851
Old  loss*** tensor(374.5497, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(336.0029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88534546
Old  loss*** tensor(540.6954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.7022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8036703
Old  loss*** tensor(2782.1174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2235.9050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8905576
Old  loss*** tensor(761.8533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.4742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88477856
Old  loss*** tensor(1236.4413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1093.9767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764635
Old  loss*** tensor(1419.9200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1244.5081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83535177
Old  loss*** tensor(1688.2413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.2754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81460315
Old  loss*** tensor(4124.0854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3359.4929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813231
Old  loss*** tensor(1044.2008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(920.2783, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83973444
Old  loss*** tensor(2842.9148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2387.2935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8868885
Old  loss*** tensor(765.5441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.9523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8754573
Old  loss*** tensor(1139.3563, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(997.4578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86997396
Old  loss*** tensor(438.9763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(381.8980, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81386614
Old  loss*** tensor(4727.3052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3847.3936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8298543
Old  loss*** tensor(2594.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2153.3220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79058486
Old  loss*** tensor(3049.0364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2410.5220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890831
Old  loss*** tensor(4162.9990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3708.5286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8475314
Old  loss*** tensor(1749.9722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1483.1564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88077664
Old  loss*** tensor(690.2372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(607.9448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88347465
Old  loss*** tensor(275.9426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(243.7883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616775
Old  loss*** tensor(1491.4548, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1285.1531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7852167
Old  loss*** tensor(4571.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3589.9106, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748115
Old  loss*** tensor(1437.8159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1257.8179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7978679
Old  loss*** tensor(4841.5239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3862.8965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8372165
Old  loss*** tensor(2065.3333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1729.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78671205
Old  loss*** tensor(3653.0488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2873.8975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8270991
Old  loss*** tensor(2104.6621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1740.7642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82256585
Old  loss*** tensor(4774.1475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3927.0508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.836678
Old  loss*** tensor(1933.3954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1617.6294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438339
Old  loss*** tensor(1746.9756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.1572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86646295
Old  loss*** tensor(1235.5427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1070.5520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8199527
Old  loss*** tensor(3654.8643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2996.8159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421297
Old  loss*** tensor(2349.5420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1978.6191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615216
Old  loss*** tensor(2032.3320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1750.8979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88298666
Old  loss*** tensor(1108.2966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.6111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78105223
Old  loss*** tensor(3502.3032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2735.4817, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699552
Old  loss*** tensor(3809.8018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2933.3767, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87653124
Old  loss*** tensor(484.7155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(424.8682, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85808253
Old  loss*** tensor(2312.5945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1984.3970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542565
Old  loss*** tensor(1536.8745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1312.8850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86359835
Old  loss*** tensor(1696.7407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.3025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90077096
Old  loss*** tensor(680.8939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(613.3294, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827126
Old  loss*** tensor(603.9825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(533.1430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71631634
Old  loss*** tensor(4554.4756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3262.4453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570348
Old  loss*** tensor(2852.8650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2445.0046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8580964
Old  loss*** tensor(168.5295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(144.6145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86755276
Old  loss*** tensor(2144.5452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1860.5061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87849617
Old  loss*** tensor(938.5747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(824.5343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7915224
Old  loss*** tensor(3380.0327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2675.3716, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798336
Old  loss*** tensor(1324.5936, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1165.4220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615173
Old  loss*** tensor(2470.0278, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2127.9717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729736
Old  loss*** tensor(1212.0695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1058.1046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79921377
Old  loss*** tensor(2945.9700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2354.4597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616518
Old  loss*** tensor(3120.5396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2688.8184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90258
Old  loss*** tensor(4128.8521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3726.6194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8651728
Old  loss*** tensor(1535.9456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.8583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87641716
Old  loss*** tensor(689.9317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(604.6680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297759
Old  loss*** tensor(2698.2095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2238.9092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813069
Old  loss*** tensor(975.0046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(859.2783, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88203776
Old  loss*** tensor(666.9367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(588.2634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8472452
Old  loss*** tensor(1867.8940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1582.5643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7985185
Old  loss*** tensor(3943.4265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3148.8989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80913085
Old  loss*** tensor(1492.2716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.4430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83447
Old  loss*** tensor(1823.8652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1521.9608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79324836
Old  loss*** tensor(2485.0815, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1971.2869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8447188
Old  loss*** tensor(2974.3552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2512.4939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86020935
Old  loss*** tensor(1678.3938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.7700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87131333
Old  loss*** tensor(1789.0422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1558.8164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86750245
Old  loss*** tensor(998.4109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(866.1239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86042583
Old  loss*** tensor(1809.0156, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1556.5238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86531204
Old  loss*** tensor(1534.6372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1327.9401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86895937
Old  loss*** tensor(3225.8904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2803.1677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84438676
Old  loss*** tensor(2014.1118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1700.6893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7725594
Old  loss*** tensor(2913.5054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2250.8560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455175
Old  loss*** tensor(1633.6328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1381.2651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84312725
Old  loss*** tensor(2710.6011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2285.3816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76521707
Old  loss*** tensor(4320.6431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3306.2297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8849788
Old  loss*** tensor(1151.5262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87831557
Old  loss*** tensor(653.3016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(573.8050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8767019
Old  loss*** tensor(1005.3629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.4036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84813195
Old  loss*** tensor(1497.0426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1269.6897, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87176853
Old  loss*** tensor(1882.1158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1640.7694, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85158026
Old  loss*** tensor(3126.9700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2662.8660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.813354
Old  loss*** tensor(3461.0437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2815.0537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86606556
Old  loss*** tensor(1229.0978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.4792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8658602
Old  loss*** tensor(1207.3127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1045.3641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731636
Old  loss*** tensor(844.2319, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(737.1526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84311515
Old  loss*** tensor(2289.5615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1930.3640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85046077
Old  loss*** tensor(1928.2975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1639.9414, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8569704
Old  loss*** tensor(2882.8386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2470.5076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83524
Old  loss*** tensor(2611.9307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2181.5889, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8949214
Old  loss*** tensor(456.9598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.9431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811047
Old  loss*** tensor(515.5519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(454.2552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79812497
Old  loss*** tensor(3109.5571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2481.8152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7796811
Old  loss*** tensor(3354.2734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2615.2637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8203535
Old  loss*** tensor(3904.5176, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3203.0847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502768
Old  loss*** tensor(3849.9463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3273.5200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88150954
Old  loss*** tensor(1990.6021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1754.7347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8167299
Old  loss*** tensor(2527.1917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2064.0330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7343925
Old  loss*** tensor(4072.2100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2990.6006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8306999
Old  loss*** tensor(3992.1130, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3316.2480, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540529
Old  loss*** tensor(3387.5564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2893.1523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87680364
Old  loss*** tensor(808.5472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.9371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88542366
Old  loss*** tensor(876.0080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(775.6382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9083376
Old  loss*** tensor(561.5146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.0449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88858676
Old  loss*** tensor(1608.0376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1428.8809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8978682
Old  loss*** tensor(781.5671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(701.7443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495146
Old  loss*** tensor(1634.7819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1388.7711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79060996
Old  loss*** tensor(3382.2932, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2674.0747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85387766
Old  loss*** tensor(2066.5645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1764.5933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86896586
Old  loss*** tensor(1511.1705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1313.1556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8276246
Old  loss*** tensor(3116.8132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2579.5513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634814
Old  loss*** tensor(1268.8506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1095.6289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8160144
Old  loss*** tensor(4277.9839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3490.8965, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8596016
Old  loss*** tensor(2083.5583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1791.0302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8086388
Old  loss*** tensor(3089.3254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2498.1484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503792
Old  loss*** tensor(1268.0355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1078.3110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77705926
Old  loss*** tensor(3121.1777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2425.3401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8418062
Old  loss*** tensor(2392.7671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2014.2461, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84229755
Old  loss*** tensor(1942.7725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1636.3925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87390023
Old  loss*** tensor(947.2128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(827.7695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80342215
Old  loss*** tensor(3545.7402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2848.7263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8040911
Old  loss*** tensor(4929.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3963.6045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88025224
Old  loss*** tensor(104.7912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(92.2427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774837
Old  loss*** tensor(159.9917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(140.3901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8943309
Old  loss*** tensor(389.0199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(347.9125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9110973
Old  loss*** tensor(1081.5045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.3558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8654066
Old  loss*** tensor(1852.6001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1603.2523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88104975
Old  loss*** tensor(552.6244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(486.8896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827828
Old  loss*** tensor(1270.3667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1121.4579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7888633
Old  loss*** tensor(3555.7473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2804.9985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850056
Old  loss*** tensor(876.8189, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(775.9896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822026
Old  loss*** tensor(189.2950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(166.9966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875278
Old  loss*** tensor(406.8337, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(361.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81277895
Old  loss*** tensor(2606.9453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2118.8704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88231975
Old  loss*** tensor(1591.7947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.4719, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86114895
Old  loss*** tensor(2244.2361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1932.6216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86417186
Old  loss*** tensor(1789.5526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1546.4810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8753987
Old  loss*** tensor(896.1538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(784.4919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87012875
Old  loss*** tensor(1419.7734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1235.3857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80769014
Old  loss*** tensor(2661.3479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2149.5444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8346675
Old  loss*** tensor(2159.8718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1802.7748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7827757
Old  loss*** tensor(3782.8120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2961.0933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8786777
Old  loss*** tensor(2722.1914, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.9290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.894137
Old  loss*** tensor(887.8984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(793.9029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8470254
Old  loss*** tensor(1259.3358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1066.6895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8501495
Old  loss*** tensor(3585.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3048.2188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8486105
Old  loss*** tensor(1942.4714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1648.4017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451275
Old  loss*** tensor(1644.9294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1390.1752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75169086
Old  loss*** tensor(3912.7729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2941.1958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85752493
Old  loss*** tensor(1241.2605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1064.4119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74869704
Old  loss*** tensor(4529.6523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3391.3374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80685526
Old  loss*** tensor(3434.4077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2771.0698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.809301
Old  loss*** tensor(2556.8682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.2761, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.784152
Old  loss*** tensor(4584.9624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3595.3074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8952348
Old  loss*** tensor(1693.2607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1515.8660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88552713
Old  loss*** tensor(455.2265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(403.1154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87010837
Old  loss*** tensor(759.9184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.2114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8491024
Old  loss*** tensor(4103.4082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3484.2136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736616
Old  loss*** tensor(1091.8271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(953.8875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86860275
Old  loss*** tensor(2742.8574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2382.4536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85756576
Old  loss*** tensor(3927.9768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3368.4985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684051
Old  loss*** tensor(911.1369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(791.2360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708559
Old  loss*** tensor(1078.6680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(939.3644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79731876
Old  loss*** tensor(2221.9395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1771.5940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656768
Old  loss*** tensor(1375.2738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.5426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86775744
Old  loss*** tensor(603.1769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(523.4113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8913363
Old  loss*** tensor(736.6803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(656.6299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87811685
Old  loss*** tensor(1210.3846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1062.8591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80891657
Old  loss*** tensor(2819.4111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2280.6685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647586
Old  loss*** tensor(1542.3484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8223079
Old  loss*** tensor(3599.3979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2959.8132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8006493
Old  loss*** tensor(2609.0166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2088.9072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8784871
Old  loss*** tensor(246.6799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(216.7051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803988
Old  loss*** tensor(795.9788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(700.7787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84490454
Old  loss*** tensor(2276.2478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1923.2122, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650915
Old  loss*** tensor(1589.1758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.7825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8095505
Old  loss*** tensor(2880.2427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2331.7019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81974006
Old  loss*** tensor(4548.3477, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3728.4626, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83439785
Old  loss*** tensor(2660.2502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2219.7070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874845
Old  loss*** tensor(482.9245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(422.4841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8299187
Old  loss*** tensor(1614.0562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1339.5354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83686924
Old  loss*** tensor(4244.0488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3551.7139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9050422
Old  loss*** tensor(1332.1117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1205.6173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8016628
Old  loss*** tensor(3388.6309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2716.5393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872756
Old  loss*** tensor(613.1835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(535.1595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83889145
Old  loss*** tensor(2449.9673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.2566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8209568
Old  loss*** tensor(1842.9225, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.9598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84292877
Old  loss*** tensor(3015.2463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2541.6379, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8562846
Old  loss*** tensor(1400.2690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.0288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8430754
Old  loss*** tensor(2089.6196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1761.7069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88872635
Old  loss*** tensor(1187.5690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1055.4238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8639895
Old  loss*** tensor(1250.4363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1080.3638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874506
Old  loss*** tensor(1838.6122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1607.8773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848234
Old  loss*** tensor(1271.7393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1125.2646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8932683
Old  loss*** tensor(1182.4244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.2223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8953663
Old  loss*** tensor(2007.7006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1797.6274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799352
Old  loss*** tensor(589.1819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.4419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87681025
Old  loss*** tensor(2164.4448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.8074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888885
Old  loss*** tensor(657.9799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(584.8685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641624
Old  loss*** tensor(1129.1166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.7401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8614994
Old  loss*** tensor(3902.9875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.4216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85109437
Old  loss*** tensor(2265.5198, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1928.1711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87057674
Old  loss*** tensor(1459.2953, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1270.4286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84777105
Old  loss*** tensor(1186.6801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.0330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8990188
Old  loss*** tensor(901.9948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(810.9103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79206806
Old  loss*** tensor(4092.2205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3241.3171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101046
Old  loss*** tensor(3328.7366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2696.6248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8568536
Old  loss*** tensor(2051.1667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1757.5496, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7746948
Old  loss*** tensor(4686.5986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3630.6836, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895394
Old  loss*** tensor(236.1331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(211.4322, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830414
Old  loss*** tensor(432.5844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(381.9899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83756423
Old  loss*** tensor(3235.6265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2710.0449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890022
Old  loss*** tensor(452.3578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.1471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860477
Old  loss*** tensor(892.1670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(790.5025, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9032637
Old  loss*** tensor(768.4903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(694.1494, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85723877
Old  loss*** tensor(1060.7753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(909.3377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82547224
Old  loss*** tensor(3000.3740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2476.7253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84460247
Old  loss*** tensor(1607.7805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.9354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7962515
Old  loss*** tensor(4794.7744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3817.8462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8488597
Old  loss*** tensor(1147.9095, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.4142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8361189
Old  loss*** tensor(3411.3855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2852.3237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728821
Old  loss*** tensor(2103.8320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1836.3973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87647843
Old  loss*** tensor(815.1313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(714.4451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590628
Old  loss*** tensor(2079.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1786.3789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89089334
Old  loss*** tensor(609.7614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(543.2324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840806
Old  loss*** tensor(813.4119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.1216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459948
Old  loss*** tensor(2333.4019, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1974.0458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7184723
Old  loss*** tensor(4207.5273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3022.9919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83866113
Old  loss*** tensor(799.6348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(670.6226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724588
Old  loss*** tensor(1759.7389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1535.2997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8691453
Old  loss*** tensor(1499.8257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1303.5664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8021504
Old  loss*** tensor(3072.5271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2464.6289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84121746
Old  loss*** tensor(1310.3008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1102.2479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88247836
Old  loss*** tensor(1350.8323, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1192.0802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87871885
Old  loss*** tensor(157.2577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(138.1853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73249394
Old  loss*** tensor(4451.1494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3260.4399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862612
Old  loss*** tensor(1847.3662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1593.5603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7535807
Old  loss*** tensor(3789.6292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2855.7913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.820664
Old  loss*** tensor(3257.6455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2673.4324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87680817
Old  loss*** tensor(1444.8035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1266.8154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82808036
Old  loss*** tensor(2146.1292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1777.1674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8124245
Old  loss*** tensor(2874.3906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2335.2253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8693416
Old  loss*** tensor(1000.5457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.8160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463458
Old  loss*** tensor(3815.3804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3229.1311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8081508
Old  loss*** tensor(3256.7849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2631.9734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8420427
Old  loss*** tensor(2195.6704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1848.8483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808716
Old  loss*** tensor(2929.6904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2580.6812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75444865
Old  loss*** tensor(5032.5918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3796.8320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77397746
Old  loss*** tensor(3516.5300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2721.7151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84978795
Old  loss*** tensor(1492.2742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.1166, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86740047
Old  loss*** tensor(1442.4868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1251.2137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8997002
Old  loss*** tensor(310.4867, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(279.3449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80327374
Old  loss*** tensor(3632.9111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2918.2222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83666134
Old  loss*** tensor(1799.9259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1505.9285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886037
Old  loss*** tensor(978.0503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(866.5887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869457
Old  loss*** tensor(685.4307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.9525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75644064
Old  loss*** tensor(5058.1133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3826.1624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86075747
Old  loss*** tensor(1169.4294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.5952, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88511324
Old  loss*** tensor(660.9328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(585.0004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509861
Old  loss*** tensor(3811.2913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3243.3560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76237226
Old  loss*** tensor(4504.5449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3434.1401, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616869
Old  loss*** tensor(1077.6758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(928.6191, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454571
Old  loss*** tensor(2297.2581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1942.2330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8327332
Old  loss*** tensor(2441.0703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2032.7604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848239
Old  loss*** tensor(891.9810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(789.2462, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815037
Old  loss*** tensor(4079.5283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3324.9666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79836226
Old  loss*** tensor(3804.8359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3037.6375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8048526
Old  loss*** tensor(1879.7527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.9238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816114
Old  loss*** tensor(801.7777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.8564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9139174
Old  loss*** tensor(879.3649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(803.6669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8565587
Old  loss*** tensor(1790.3809, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1533.5663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7497049
Old  loss*** tensor(3257.5825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2442.2256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8103934
Old  loss*** tensor(2380.4470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.0985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8726491
Old  loss*** tensor(1570.8365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1370.7891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696004
Old  loss*** tensor(1011.8593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.9132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852253
Old  loss*** tensor(1989.3761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1695.4518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9074318
Old  loss*** tensor(601.1707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(545.5214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83162606
Old  loss*** tensor(2056.4604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1710.2061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88009393
Old  loss*** tensor(877.3762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(772.1735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739265
Old  loss*** tensor(443.0929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(387.2306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8196939
Old  loss*** tensor(1602.6589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1313.6898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73630154
Old  loss*** tensor(4160.4097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3063.3162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8412353
Old  loss*** tensor(1723.9293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.2302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9026012
Old  loss*** tensor(483.9425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(436.8071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8141309
Old  loss*** tensor(3421.8140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2785.8044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9044968
Old  loss*** tensor(1128.8085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.0037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8172804
Old  loss*** tensor(3261.4946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2665.5557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83572954
Old  loss*** tensor(2729.0701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2280.7644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81601185
Old  loss*** tensor(2429.7776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.7273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8377781
Old  loss*** tensor(1593.5985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1335.0819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8167527
Old  loss*** tensor(3759.7263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3070.7666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82017344
Old  loss*** tensor(3152.4314, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2585.5405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86287796
Old  loss*** tensor(813.2764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(701.7582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8103333
Old  loss*** tensor(974.0985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(789.3445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815066
Old  loss*** tensor(3309.2883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2697.2883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8856771
Old  loss*** tensor(1098.3212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.7579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7372603
Old  loss*** tensor(3930.2935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2897.6492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792546
Old  loss*** tensor(167.8152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(147.5522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8893732
Old  loss*** tensor(779.0554, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.8710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83247346
Old  loss*** tensor(2845.5947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2368.8821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79266024
Old  loss*** tensor(4201.5889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3330.4324, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79738677
Old  loss*** tensor(2589.7183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2065.0071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88192034
Old  loss*** tensor(538.7969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(475.1759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924057
Old  loss*** tensor(761.1967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(679.2962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89483726
Old  loss*** tensor(463.5604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(414.8111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8462081
Old  loss*** tensor(2370.7795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.1729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682771
Old  loss*** tensor(1476.6564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1282.1469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8198861
Old  loss*** tensor(4122.1826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3379.7202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79125214
Old  loss*** tensor(2810.2112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2223.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798144
Old  loss*** tensor(1127.7552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(992.2153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667513
Old  loss*** tensor(1339.5626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1161.0676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88290393
Old  loss*** tensor(307.1321, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(271.1682, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89106673
Old  loss*** tensor(1691.6510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.3739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8241252
Old  loss*** tensor(1764.3254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1454.0250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8191992
Old  loss*** tensor(3326.9692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2725.4504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806636
Old  loss*** tensor(1380.1552, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1215.4524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572376
Old  loss*** tensor(870.9994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(746.6534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8457556
Old  loss*** tensor(1734.0515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.5837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88419837
Old  loss*** tensor(1320.0265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1167.1653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79021233
Old  loss*** tensor(4971.6299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3928.6433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500528
Old  loss*** tensor(2014.4172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1712.3610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7629817
Old  loss*** tensor(4197.9116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3202.9297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87829685
Old  loss*** tensor(553.9159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(486.5026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86936295
Old  loss*** tensor(1258.8107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1094.3634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88141716
Old  loss*** tensor(1157.6097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1020.3371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208041
Old  loss*** tensor(2526.7527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2073.9690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8362161
Old  loss*** tensor(2630.5203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2199.6833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7113009
Old  loss*** tensor(4954.7632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3524.3276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7687971
Old  loss*** tensor(3875.1123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2979.1750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90780896
Old  loss*** tensor(729.6303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(662.3649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88383
Old  loss*** tensor(936.4669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(827.6776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616853
Old  loss*** tensor(1305.7290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1125.1274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8451234
Old  loss*** tensor(2632.9890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2225.2007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84684
Old  loss*** tensor(2278.2988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1929.3546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84552455
Old  loss*** tensor(2679.6951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.7480, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860502
Old  loss*** tensor(225.1854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(199.5256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415352
Old  loss*** tensor(2454.9719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2065.9453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8305927
Old  loss*** tensor(2863.8789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2378.7168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78682876
Old  loss*** tensor(4273.7954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.7451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8273909
Old  loss*** tensor(2046.4724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.2327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858239
Old  loss*** tensor(1422.3890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.7498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885255
Old  loss*** tensor(630.0208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(559.7895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87251484
Old  loss*** tensor(550.7365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.5257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8018892
Old  loss*** tensor(3308.0479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2652.6877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390467
Old  loss*** tensor(4166.9893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3496.2986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80724597
Old  loss*** tensor(3277.1987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2645.5054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83922744
Old  loss*** tensor(2930.5796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.4229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84431416
Old  loss*** tensor(3380.5693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2854.2625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831392
Old  loss*** tensor(1088.1891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.0225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384565
Old  loss*** tensor(4272.6538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3582.4343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82095915
Old  loss*** tensor(2760.0859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2265.9177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87130487
Old  loss*** tensor(1017.3137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(886.3903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520776
Old  loss*** tensor(1577.0228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1343.7458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8863811
Old  loss*** tensor(746.0159, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.2544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86210704
Old  loss*** tensor(1541.4094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.8599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7585845
Old  loss*** tensor(4232.3784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3210.6167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.880823
Old  loss*** tensor(241.5263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(212.7419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8591917
Old  loss*** tensor(4195.7979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3604.9949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81273836
Old  loss*** tensor(1791.6771, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1456.1647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8406445
Old  loss*** tensor(3136.3313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2636.5396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8397764
Old  loss*** tensor(2053.7341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1724.6775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8507506
Old  loss*** tensor(1049.1450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(892.5608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8056215
Old  loss*** tensor(4770.7300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3843.4026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8372847
Old  loss*** tensor(2521.3232, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2111.0654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518945
Old  loss*** tensor(1656.0316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.7643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492186
Old  loss*** tensor(1493.7568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.5261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682784
Old  loss*** tensor(638.7864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(554.6445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7838415
Old  loss*** tensor(4368.4478, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3424.1707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76707673
Old  loss*** tensor(2899.3813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2224.0479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8928389
Old  loss*** tensor(949.5538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(847.7986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86211985
Old  loss*** tensor(541.8765, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(467.1625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74761605
Old  loss*** tensor(4206.7646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3145.0447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8157172
Old  loss*** tensor(3012.6152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2457.4421, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907113
Old  loss*** tensor(1849.6249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1647.4818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89135635
Old  loss*** tensor(536.2760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(478.0130, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9160038
Old  loss*** tensor(532.8108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(488.0567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840252
Old  loss*** tensor(663.8855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(586.8915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87207663
Old  loss*** tensor(1151.7664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1004.4285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88409597
Old  loss*** tensor(411.9463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(364.2000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559656
Old  loss*** tensor(1452.9539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1243.6786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8792819
Old  loss*** tensor(631.2357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(555.0341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88679576
Old  loss*** tensor(658.5950, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(584.0393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7551206
Old  loss*** tensor(3595.9490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2715.3750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86663693
Old  loss*** tensor(2088.6343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1810.0876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.805042
Old  loss*** tensor(1986.4764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1599.1970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.844754
Old  loss*** tensor(2479.8584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.8704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446196
Old  loss*** tensor(1899.8394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1604.6415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8274759
Old  loss*** tensor(2923.5977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2419.2065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8487323
Old  loss*** tensor(1565.2343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.4648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8484019
Old  loss*** tensor(3005.8569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2550.1748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82173985
Old  loss*** tensor(2442.3679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.9911, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7340797
Old  loss*** tensor(4767.5024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.7268, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575307
Old  loss*** tensor(2283.5930, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1958.2511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9050573
Old  loss*** tensor(786.8769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.1687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890283
Old  loss*** tensor(1583.3013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1407.5996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738158
Old  loss*** tensor(763.5740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(667.2230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88605225
Old  loss*** tensor(1409.0172, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1248.4629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8180095
Old  loss*** tensor(1095.2323, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89298457
Old  loss*** tensor(192.0463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(171.4944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86197364
Old  loss*** tensor(2440.8442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2103.9434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8393954
Old  loss*** tensor(2380.8816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1998.5011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88666594
Old  loss*** tensor(1982.9780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1758.2391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.791131
Old  loss*** tensor(3988.6414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3155.5378, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8983502
Old  loss*** tensor(1062.6853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(954.6635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758943
Old  loss*** tensor(1224.8043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1072.7992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80521715
Old  loss*** tensor(3667.1389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2952.8430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632143
Old  loss*** tensor(1948.2982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1681.7990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79620063
Old  loss*** tensor(2418.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1925.8540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8652477
Old  loss*** tensor(1064.7798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(921.2983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88142514
Old  loss*** tensor(770.9059, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(679.4958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8490046
Old  loss*** tensor(2681.0583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2276.2310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8380132
Old  loss*** tensor(1738.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1457.0269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8381591
Old  loss*** tensor(3874.0435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3247.0647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884115
Old  loss*** tensor(1286.6655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.0885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87703466
Old  loss*** tensor(761.7003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.0376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7894858
Old  loss*** tensor(3666.9041, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2894.9688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845798
Old  loss*** tensor(3000.4128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2537.7432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8010253
Old  loss*** tensor(5083.2549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4071.8157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8725003
Old  loss*** tensor(1130.7664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(986.5940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83703315
Old  loss*** tensor(1484.4087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.4993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87285733
Old  loss*** tensor(943.1363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(823.2234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632096
Old  loss*** tensor(801.9955, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.2902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88591903
Old  loss*** tensor(980.1447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.3288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8458622
Old  loss*** tensor(2185.5740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1848.6945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442717
Old  loss*** tensor(1122.7322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(947.8911, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8290322
Old  loss*** tensor(3560.9390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2952.1331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85982895
Old  loss*** tensor(1450.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.4441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84114826
Old  loss*** tensor(2666.7988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2243.1731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8335166
Old  loss*** tensor(3129.8279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2608.7634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493829
Old  loss*** tensor(2272.4648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1930.1927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7601416
Old  loss*** tensor(5491.4209, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4174.2573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888764
Old  loss*** tensor(789.3452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(701.5416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88975894
Old  loss*** tensor(2817.0703, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2506.5134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7897475
Old  loss*** tensor(4362.4985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3445.2722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852058
Old  loss*** tensor(1145.7600, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(976.2540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77657795
Old  loss*** tensor(4944.3682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3839.6873, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815217
Old  loss*** tensor(3800.9238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3098.5779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87085426
Old  loss*** tensor(905.2520, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(788.3426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671347
Old  loss*** tensor(1441.8441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1250.2731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8970599
Old  loss*** tensor(1655.5735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.1486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8028089
Old  loss*** tensor(3082.8762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2474.9604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87098914
Old  loss*** tensor(1172.4501, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.1913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8883529
Old  loss*** tensor(119.0443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(105.7533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8914602
Old  loss*** tensor(310.6835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(276.9619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88968205
Old  loss*** tensor(336.3006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(299.2006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80563116
Old  loss*** tensor(4628.3169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3728.7163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89116657
Old  loss*** tensor(1121.1741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.1528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.838907
Old  loss*** tensor(3938.9102, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3304.3794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.791396
Old  loss*** tensor(4124.0283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3263.7395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87155163
Old  loss*** tensor(1704.6813, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.7178, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601607
Old  loss*** tensor(2211.2366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1902.0188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86375463
Old  loss*** tensor(1901.8779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1642.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84949994
Old  loss*** tensor(1542.9266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1310.7161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86822253
Old  loss*** tensor(1265.4052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.6533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86395466
Old  loss*** tensor(1735.3721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1499.2828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031496
Old  loss*** tensor(3389.4580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2722.2417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8206488
Old  loss*** tensor(2490.7363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2044.0198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86577225
Old  loss*** tensor(1387.9100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1201.6140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86864585
Old  loss*** tensor(1576.4867, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1369.4086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8247886
Old  loss*** tensor(4269.6841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3521.5867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88816094
Old  loss*** tensor(1430.7761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1270.7595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8644165
Old  loss*** tensor(1329.5624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.2957, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459984
Old  loss*** tensor(2584.6235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2186.5874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8271214
Old  loss*** tensor(2841.4468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2350.2214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82287407
Old  loss*** tensor(4042.2825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3326.2893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88842916
Old  loss*** tensor(1048.2551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(931.3004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73317343
Old  loss*** tensor(4467.9399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3275.7749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7945245
Old  loss*** tensor(3224.5933, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2562.0183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8478255
Old  loss*** tensor(2668.7893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2262.6677, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864486
Old  loss*** tensor(654.5427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(565.8430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557313
Old  loss*** tensor(2583.9885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2211.2000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314666
Old  loss*** tensor(2980.3872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.0925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8714466
Old  loss*** tensor(2775.0396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2418.2988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82874346
Old  loss*** tensor(2158.0459, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1788.4664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8956342
Old  loss*** tensor(1021.3796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(914.7825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7959753
Old  loss*** tensor(3391.8965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2699.8660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8776684
Old  loss*** tensor(74.8517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(65.6950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82096374
Old  loss*** tensor(4471.2900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3670.7671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75736344
Old  loss*** tensor(4871.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3689.2146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7544136
Old  loss*** tensor(4167.9297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3144.3428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87453
Old  loss*** tensor(972.7273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.6792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7801058
Old  loss*** tensor(4420.0078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3448.0740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88531184
Old  loss*** tensor(1477.1129, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1307.7056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8301537
Old  loss*** tensor(1851.0070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.6202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77885234
Old  loss*** tensor(1912.3315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1489.4240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8412159
Old  loss*** tensor(3472.7546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2921.3364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638054
Old  loss*** tensor(1913.6442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1653.0162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83002996
Old  loss*** tensor(1072.8790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.5217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674979
Old  loss*** tensor(1135.5927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.1243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608753
Old  loss*** tensor(2661.0408, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.8242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880131
Old  loss*** tensor(815.5889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(724.2536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8035867
Old  loss*** tensor(2776.9878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2231.5505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8864707
Old  loss*** tensor(1520.8463, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1348.1857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683688
Old  loss*** tensor(1661.6569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1442.9310, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86207473
Old  loss*** tensor(1470.0397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1267.2841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85886776
Old  loss*** tensor(2243.0203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1926.4578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8349094
Old  loss*** tensor(4160.2036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3473.3931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926508
Old  loss*** tensor(647.7632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(578.2264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820306
Old  loss*** tensor(906.7089, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.7450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86595273
Old  loss*** tensor(597.9409, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(517.7885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8840648
Old  loss*** tensor(1578.8632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.8174, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85948807
Old  loss*** tensor(1966.4570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1690.1464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8766234
Old  loss*** tensor(807.8162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(708.1506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793426
Old  loss*** tensor(896.6583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(788.4698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8362531
Old  loss*** tensor(3341.8718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2794.6506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88007927
Old  loss*** tensor(758.0438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(667.1387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82002187
Old  loss*** tensor(2816.2664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2309.3999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697864
Old  loss*** tensor(1181.7510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1027.8708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8543555
Old  loss*** tensor(804.8767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(687.6509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7923078
Old  loss*** tensor(4749.7422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3763.2578, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8711045
Old  loss*** tensor(1910.9786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1664.6621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8751682
Old  loss*** tensor(445.6733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(390.0391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8170194
Old  loss*** tensor(3444.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2814.2307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85595095
Old  loss*** tensor(1605.6572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.3639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7928744
Old  loss*** tensor(3424.8784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2715.4983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82493013
Old  loss*** tensor(2939.8621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2425.1809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89202416
Old  loss*** tensor(705.4155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.2477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8961224
Old  loss*** tensor(248.4117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(222.6073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90400517
Old  loss*** tensor(456.7717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.9240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85953283
Old  loss*** tensor(2107.0188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1811.0519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83212006
Old  loss*** tensor(3532.9714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2939.8564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90707755
Old  loss*** tensor(694.5447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(630.0059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87131685
Old  loss*** tensor(3164.8430, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2757.5811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82455695
Old  loss*** tensor(2761.1492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2276.7246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8552248
Old  loss*** tensor(1137.7719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(973.0507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819712
Old  loss*** tensor(267.9605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(236.3335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8948492
Old  loss*** tensor(1376.0476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.3551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85314786
Old  loss*** tensor(1227.1255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1046.9194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8462956
Old  loss*** tensor(1709.2740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.5511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8684425
Old  loss*** tensor(1714.4435, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1488.8955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647678
Old  loss*** tensor(1226.2764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1060.4443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864638
Old  loss*** tensor(1771.3158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1531.5469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388121
Old  loss*** tensor(2346.3584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1968.1538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75554967
Old  loss*** tensor(2905.9402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2195.5820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8974066
Old  loss*** tensor(476.7745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(427.8606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75897855
Old  loss*** tensor(4189.2749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3179.5698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8442146
Old  loss*** tensor(2261.8137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1909.4562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8346201
Old  loss*** tensor(1361.0619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1135.9696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7628815
Old  loss*** tensor(4152.5967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3167.9392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807545
Old  loss*** tensor(3907.8606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3441.8657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7902508
Old  loss*** tensor(3044.5549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2405.9619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8235167
Old  loss*** tensor(3834.1992, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3157.5271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638933
Old  loss*** tensor(1398.9469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.5408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78305674
Old  loss*** tensor(1962.1924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.5079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85044795
Old  loss*** tensor(2214.5598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1883.3679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8750921
Old  loss*** tensor(1078.0490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(943.3921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884331
Old  loss*** tensor(702.2416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(623.8947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493161
Old  loss*** tensor(2514.8567, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2135.9084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8693999
Old  loss*** tensor(1591.0303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1383.2416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.829393
Old  loss*** tensor(4045.4382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3355.2583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8334925
Old  loss*** tensor(2963.8684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2470.3621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79640853
Old  loss*** tensor(4710.4033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3751.4055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7431012
Old  loss*** tensor(4125.0669, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3065.3420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8396502
Old  loss*** tensor(1263.7747, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1061.1287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518498
Old  loss*** tensor(2084.7507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1775.8945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9028166
Old  loss*** tensor(1195.2084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1079.0540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8522706
Old  loss*** tensor(1259.3317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1073.2914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661824
Old  loss*** tensor(1802.9850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1561.7139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579627
Old  loss*** tensor(2401.0300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.9944, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638607
Old  loss*** tensor(1170.9056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1011.4994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8989539
Old  loss*** tensor(1286.0392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1156.0900, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8404446
Old  loss*** tensor(3971.9561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3338.2092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86525434
Old  loss*** tensor(773.1031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.9308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889392
Old  loss*** tensor(539.8801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(479.9206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529353
Old  loss*** tensor(1747.7437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.7123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9182772
Old  loss*** tensor(750.9847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(689.6121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82649624
Old  loss*** tensor(2013.0057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1663.7417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7944759
Old  loss*** tensor(4387.0405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3485.3979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87339354
Old  loss*** tensor(1333.3008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1164.4963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8426613
Old  loss*** tensor(2082.7686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1755.0685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86852354
Old  loss*** tensor(2422.5662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2104.0557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82920784
Old  loss*** tensor(2564.3223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2126.3562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88093567
Old  loss*** tensor(4195.9780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3696.3867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8796872
Old  loss*** tensor(1070.9083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.0643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9049783
Old  loss*** tensor(1134.0472, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1026.2881, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8151868
Old  loss*** tensor(4474.0015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3647.1470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78367937
Old  loss*** tensor(4050.5610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3174.3411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8007501
Old  loss*** tensor(3556.1606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2847.5959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88227
Old  loss*** tensor(349.2395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(308.1235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88395023
Old  loss*** tensor(368.6543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(325.8720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8871158
Old  loss*** tensor(858.8097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.8636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724345
Old  loss*** tensor(1678.6042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1464.4723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845695
Old  loss*** tensor(4133.8252, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3495.9553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87418425
Old  loss*** tensor(1015.2377, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.5048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86959064
Old  loss*** tensor(1354.7921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1178.1145, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860979
Old  loss*** tensor(182.1070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(161.3646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78780395
Old  loss*** tensor(4523.7827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3563.8540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769635
Old  loss*** tensor(152.6027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(133.8270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81544715
Old  loss*** tensor(4076.8560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3324.4607, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8521602
Old  loss*** tensor(1397.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1190.8756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8681712
Old  loss*** tensor(2327.1636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2020.3765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85904276
Old  loss*** tensor(1293.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1111.5405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83529073
Old  loss*** tensor(1560.8661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1303.7770, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78865147
Old  loss*** tensor(2904.2307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2290.4258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85440934
Old  loss*** tensor(2207.4465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.0630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81676877
Old  loss*** tensor(1987.3921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1623.2397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80640745
Old  loss*** tensor(4575.4673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3689.6909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080791
Old  loss*** tensor(2712.5598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2191.9629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85156417
Old  loss*** tensor(915.6457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(779.7311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87892544
Old  loss*** tensor(895.8376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(787.3745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8771306
Old  loss*** tensor(2366.0947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.3743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85254025
Old  loss*** tensor(1107.6536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.3193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8243865
Old  loss*** tensor(2732.5613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2252.6865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77773196
Old  loss*** tensor(4466.2163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3473.5190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8857436
Old  loss*** tensor(1452.6250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1286.6533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8505394
Old  loss*** tensor(1468.9902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1249.4341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88769066
Old  loss*** tensor(577.1343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(512.3168, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7758819
Old  loss*** tensor(3023.8245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2346.1306, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74337
Old  loss*** tensor(3518.5081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2615.5532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88591933
Old  loss*** tensor(1728.9579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1531.7172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78918815
Old  loss*** tensor(3337.0066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2633.5261, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813695
Old  loss*** tensor(1222.8032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1077.7415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87155896
Old  loss*** tensor(167.3922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(145.8922, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8886601
Old  loss*** tensor(447.7431, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(397.8914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85590476
Old  loss*** tensor(935.0829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(800.3419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90591085
Old  loss*** tensor(392.6565, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(355.7118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7916435
Old  loss*** tensor(3009.9062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2382.7727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8964008
Old  loss*** tensor(1116.1938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1000.5571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90112984
Old  loss*** tensor(1258.6825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1134.2363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9040205
Old  loss*** tensor(1642.5076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1484.8605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8505813
Old  loss*** tensor(1415.7694, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1204.2269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869007
Old  loss*** tensor(1783.2397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1549.6478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675806
Old  loss*** tensor(1497.0322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.7961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75756276
Old  loss*** tensor(3433.9224, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2601.4116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81047297
Old  loss*** tensor(2571.2229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.9067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87560654
Old  loss*** tensor(721.9749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(632.1660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803531
Old  loss*** tensor(613.9173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(540.4640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8233265
Old  loss*** tensor(1891.3779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1557.2217, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7553946
Old  loss*** tensor(2274.0334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1717.7925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9158269
Old  loss*** tensor(895.4490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(820.0763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81190866
Old  loss*** tensor(3383.4023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2747.0137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8576149
Old  loss*** tensor(3837.0576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3290.7178, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8845089
Old  loss*** tensor(524.2330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(463.6887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758336
Old  loss*** tensor(541.9778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(474.6823, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86759895
Old  loss*** tensor(776.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(673.2598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8602739
Old  loss*** tensor(562.2327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.6741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518947
Old  loss*** tensor(1381.6969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1177.0602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9023727
Old  loss*** tensor(971.9145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(877.0291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8910147
Old  loss*** tensor(892.5615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(795.2855, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8353012
Old  loss*** tensor(2250.1465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1879.5500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76931846
Old  loss*** tensor(4766.6738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3667.0901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756113
Old  loss*** tensor(1965.4624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.9811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88869196
Old  loss*** tensor(606.0299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(538.5739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.867848
Old  loss*** tensor(996.4745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.7884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7882302
Old  loss*** tensor(4832.0352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3808.7559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8328372
Old  loss*** tensor(2852.1948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.4141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.820989
Old  loss*** tensor(3948.4856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3241.6633, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620062
Old  loss*** tensor(1782.4753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.5048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79441476
Old  loss*** tensor(3475.6248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2761.0876, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83414406
Old  loss*** tensor(3275.6135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2732.3335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8232098
Old  loss*** tensor(2391.2336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1968.4871, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86361575
Old  loss*** tensor(2099.8318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1813.4478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8487274
Old  loss*** tensor(2080.8406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1766.0664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7970495
Old  loss*** tensor(3092.8389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2465.1458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84024125
Old  loss*** tensor(2765.9885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2324.0977, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86977947
Old  loss*** tensor(2764.8738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2404.8303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8158016
Old  loss*** tensor(2463.5894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2009.8002, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9052875
Old  loss*** tensor(737.4659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(667.6187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79604363
Old  loss*** tensor(4108.5083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3270.5518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77120125
Old  loss*** tensor(3792.7649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2924.9851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9068067
Old  loss*** tensor(732.5483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(664.2797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84189165
Old  loss*** tensor(1596.1417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1343.7784, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87174326
Old  loss*** tensor(1663.3173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.9856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88467926
Old  loss*** tensor(1974.7084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1746.9835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8843279
Old  loss*** tensor(714.5742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(631.9179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88620913
Old  loss*** tensor(1139.9310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1010.2173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86400676
Old  loss*** tensor(3146.9648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2718.9988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735442
Old  loss*** tensor(875.5717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(764.8505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8637673
Old  loss*** tensor(1098.8949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(949.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9214884
Old  loss*** tensor(1019.7621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(939.6989, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8328829
Old  loss*** tensor(2306.2278, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1920.8176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880685
Old  loss*** tensor(1290.8192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.3359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8961649
Old  loss*** tensor(4346.7212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3895.3789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89388657
Old  loss*** tensor(585.7165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(523.5641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78185415
Old  loss*** tensor(4633.1572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3622.4531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822507
Old  loss*** tensor(392.3013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(346.1081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8482462
Old  loss*** tensor(4543.9849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3854.4180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8841189
Old  loss*** tensor(642.4337, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(567.9878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8606722
Old  loss*** tensor(1280.0356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1101.6910, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7927669
Old  loss*** tensor(3261.6357, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2585.7170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.841959
Old  loss*** tensor(1723.1650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.8344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9027651
Old  loss*** tensor(554.7666, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.8239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81455123
Old  loss*** tensor(3610.2395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2940.7251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7907353
Old  loss*** tensor(3483.8660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2754.8159, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76968884
Old  loss*** tensor(4883.8843, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3759.0713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9157725
Old  loss*** tensor(883.4257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(809.0170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88647395
Old  loss*** tensor(979.9738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(868.7213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8153181
Old  loss*** tensor(3825.4126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.9282, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84671974
Old  loss*** tensor(958.0610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(811.2092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8966388
Old  loss*** tensor(1613.9991, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1447.1743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87636244
Old  loss*** tensor(1374.1448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1204.2489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86762804
Old  loss*** tensor(1214.5454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1053.7737, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867662
Old  loss*** tensor(444.7184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(394.3613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642962
Old  loss*** tensor(1336.9675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1155.5360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8794985
Old  loss*** tensor(1247.8385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1097.4720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703643
Old  loss*** tensor(1854.8079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.3585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8946514
Old  loss*** tensor(919.2711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.4271, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741035
Old  loss*** tensor(1488.1589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1300.8049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80036914
Old  loss*** tensor(2649.9001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2120.8982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500568
Old  loss*** tensor(2390.3550, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2031.9376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8988245
Old  loss*** tensor(943.4092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(847.9594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90023947
Old  loss*** tensor(608.5651, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(547.8543, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579955
Old  loss*** tensor(475.3987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(407.8899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81389713
Old  loss*** tensor(3403.7539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2770.3057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8505074
Old  loss*** tensor(2085.9099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1774.0818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847527
Old  loss*** tensor(2124.6213, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1800.6740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8861112
Old  loss*** tensor(601.7421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(533.2104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83869356
Old  loss*** tensor(1932.6722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1620.9198, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86265075
Old  loss*** tensor(1421.2266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.0222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7923007
Old  loss*** tensor(2638.3318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2090.3521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89317733
Old  loss*** tensor(253.2131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(226.1642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83574176
Old  loss*** tensor(1659.1471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.6185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878489
Old  loss*** tensor(867.2236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.8464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.856139
Old  loss*** tensor(2554.4944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2187.0022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90568054
Old  loss*** tensor(594.7987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(538.6976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86408055
Old  loss*** tensor(1682.0090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1453.3912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89000535
Old  loss*** tensor(1249.8208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1112.3472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87183523
Old  loss*** tensor(284.6699, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(248.1852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8600074
Old  loss*** tensor(1416.4169, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1218.1290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8719373
Old  loss*** tensor(1658.6469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1446.2360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889339
Old  loss*** tensor(706.3331, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(627.8834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82819676
Old  loss*** tensor(3616.8381, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2995.4536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7282926
Old  loss*** tensor(4730.9395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3445.5081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85586345
Old  loss*** tensor(2186.2219, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1871.1074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727097
Old  loss*** tensor(2030.5295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1772.0629, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799975
Old  loss*** tensor(754.4313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(663.8977, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79766464
Old  loss*** tensor(3953.7034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.7295, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87326556
Old  loss*** tensor(1335.4419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1166.1954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87428516
Old  loss*** tensor(1016.9515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(889.1057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85526145
Old  loss*** tensor(1620.3997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1385.8654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622519
Old  loss*** tensor(2153.1106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1856.5237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827574
Old  loss*** tensor(1993.2507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1759.5569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601682
Old  loss*** tensor(2404.4480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2068.2297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8052516
Old  loss*** tensor(3492.4531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2812.3035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86625886
Old  loss*** tensor(714.3685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(618.8281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8178596
Old  loss*** tensor(2686.9353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2197.5359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87100065
Old  loss*** tensor(1604.6006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1397.6082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7140204
Old  loss*** tensor(3525.4810, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2517.2651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890884
Old  loss*** tensor(1316.6886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1170.6526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8180119
Old  loss*** tensor(4250.0923, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3476.6260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77002347
Old  loss*** tensor(3654.4922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2814.0447, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8258256
Old  loss*** tensor(3221.4673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2660.3701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826573
Old  loss*** tensor(1875.3407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1655.2831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80898786
Old  loss*** tensor(2619.4067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2119.0684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79589605
Old  loss*** tensor(3338.9121, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2657.4270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83098555
Old  loss*** tensor(1882.0505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.9568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7990643
Old  loss*** tensor(2822.5171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.3726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88259935
Old  loss*** tensor(100.1098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(88.3568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7787343
Old  loss*** tensor(3587.7629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2793.9141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8482647
Old  loss*** tensor(544.5728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.9419, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83032894
Old  loss*** tensor(2405.4976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1997.3542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518746
Old  loss*** tensor(2026.9729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1726.7267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8454273
Old  loss*** tensor(4236.2217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3581.4172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8504577
Old  loss*** tensor(1898.8754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.9132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81185496
Old  loss*** tensor(3157.9419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2563.7908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208103
Old  loss*** tensor(3214.5601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2638.5439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8211995
Old  loss*** tensor(4591.3525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3770.4163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673185
Old  loss*** tensor(3966.3479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3440.0869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.878901
Old  loss*** tensor(1586.2872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1394.1895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.848131
Old  loss*** tensor(2935.3879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2489.5935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7396961
Old  loss*** tensor(4034.4880, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2984.2949, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83532536
Old  loss*** tensor(810.6094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.1226, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85503733
Old  loss*** tensor(2042.9735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1746.8186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800896
Old  loss*** tensor(1032.1250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(908.3625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.830053
Old  loss*** tensor(2676.3755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2221.5334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.851671
Old  loss*** tensor(3378.7947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2877.6213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85832727
Old  loss*** tensor(3082.9551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2646.1843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81002223
Old  loss*** tensor(3059.0581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2477.9050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85363173
Old  loss*** tensor(3411.5422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2912.2007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86187553
Old  loss*** tensor(1474.8101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1271.1027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8960893
Old  loss*** tensor(512.4203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(459.1743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87775713
Old  loss*** tensor(1095.5378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.6161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8027251
Old  loss*** tensor(2581.4312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2072.1794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560074
Old  loss*** tensor(1901.9271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1628.0637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8930135
Old  loss*** tensor(1411.1549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.1803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710358
Old  loss*** tensor(1243.7161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1083.3213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8991558
Old  loss*** tensor(1043.9440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(938.6683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7848184
Old  loss*** tensor(3424.4631, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2687.5818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8985387
Old  loss*** tensor(992.9893, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(892.2393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85774755
Old  loss*** tensor(1183.0707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1014.7760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81406057
Old  loss*** tensor(1706.7101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1389.3654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807764
Old  loss*** tensor(910.5672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.0061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84490573
Old  loss*** tensor(2739.7764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2314.8528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80151045
Old  loss*** tensor(4514.0039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3618.0212, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642069
Old  loss*** tensor(1331.5173, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.7064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87446547
Old  loss*** tensor(1677.9796, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1467.3352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82209814
Old  loss*** tensor(3716.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3055.3352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670137
Old  loss*** tensor(1801.8721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890072
Old  loss*** tensor(1309.8834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1164.4958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83276653
Old  loss*** tensor(2089.5444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1740.1027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8854488
Old  loss*** tensor(815.4288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(722.0204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86179703
Old  loss*** tensor(1652.8011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1424.3792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77630997
Old  loss*** tensor(2287.8132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1776.0522, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8856311
Old  loss*** tensor(191.2034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(169.3356, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534173
Old  loss*** tensor(1223.4783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.1375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.838519
Old  loss*** tensor(2993.0134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2509.6985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83950996
Old  loss*** tensor(2414.0293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2026.6017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8204392
Old  loss*** tensor(2526.7073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2073.0098, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642181
Old  loss*** tensor(2029.3037, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1753.7610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.824667
Old  loss*** tensor(2804.9299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2313.1331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91483796
Old  loss*** tensor(459.9756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(420.8031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89772177
Old  loss*** tensor(604.2389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(542.4384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81586975
Old  loss*** tensor(3895.2402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3178.0088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8689938
Old  loss*** tensor(1248.4480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.8936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81279975
Old  loss*** tensor(2553.0742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.1382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8445769
Old  loss*** tensor(2234.1692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.9277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84354484
Old  loss*** tensor(1501.1390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1266.2781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81229293
Old  loss*** tensor(1491.3918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1211.4470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800067
Old  loss*** tensor(1040.9178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(916.0146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798656
Old  loss*** tensor(784.8275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.5427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87244064
Old  loss*** tensor(1633.6230, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1425.2391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9150943
Old  loss*** tensor(643.6710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(589.0197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8917683
Old  loss*** tensor(1373.5964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1224.9297, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87029195
Old  loss*** tensor(738.3217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.5554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597614
Old  loss*** tensor(1620.4307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1393.1837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8456199
Old  loss*** tensor(2029.8318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1716.4662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90991837
Old  loss*** tensor(3087.9717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2809.8022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86258876
Old  loss*** tensor(466.3163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(402.2392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8896588
Old  loss*** tensor(243.4769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(216.6114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85794497
Old  loss*** tensor(1198.2073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1027.9958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88101375
Old  loss*** tensor(1435.0344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1264.2850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80613977
Old  loss*** tensor(4045.6401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3261.3513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82067037
Old  loss*** tensor(4437.4468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3641.6812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735537
Old  loss*** tensor(670.1214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(585.3870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8957976
Old  loss*** tensor(465.1208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(416.6541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503448
Old  loss*** tensor(3833.9507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3260.1799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85431165
Old  loss*** tensor(2507.0466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.7991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8190185
Old  loss*** tensor(2486.7722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.7124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9001464
Old  loss*** tensor(935.4468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(842.0391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665068
Old  loss*** tensor(2197.6389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1904.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716996
Old  loss*** tensor(1908.9076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1663.9939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7489381
Old  loss*** tensor(4141.1997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3101.5022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9137795
Old  loss*** tensor(702.3837, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(641.8238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7654177
Old  loss*** tensor(4392.7329, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3362.2754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82999814
Old  loss*** tensor(4493.8931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3729.9229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8553117
Old  loss*** tensor(1257.7135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1075.7371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8438245
Old  loss*** tensor(2498.7007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2108.4648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80078495
Old  loss*** tensor(2927.9922, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2344.6921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9012961
Old  loss*** tensor(696.8778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(628.0933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83711445
Old  loss*** tensor(3831.0864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3207.0579, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75697494
Old  loss*** tensor(4179.6294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3163.8748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87496173
Old  loss*** tensor(1089.8461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(953.5736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7491081
Old  loss*** tensor(3866.3633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2896.3240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88852835
Old  loss*** tensor(451.2228, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(400.9243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84072316
Old  loss*** tensor(1746.3473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1468.1946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.882192
Old  loss*** tensor(455.5104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.8476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8405388
Old  loss*** tensor(2407.0513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2023.2200, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8657412
Old  loss*** tensor(734.3118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.7239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7962873
Old  loss*** tensor(2952.9785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2351.4192, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336825
Old  loss*** tensor(1942.9449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1619.7992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81390667
Old  loss*** tensor(1929.6649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1570.5671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8518629
Old  loss*** tensor(3852.3096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3281.6396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88819504
Old  loss*** tensor(1304.5013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1158.6516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830085
Old  loss*** tensor(883.6823, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(780.2990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78790843
Old  loss*** tensor(4627.0513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3645.6926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8198839
Old  loss*** tensor(3547.8093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2908.7917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8312558
Old  loss*** tensor(2269.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.5151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851404
Old  loss*** tensor(260.1214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(230.2440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8677718
Old  loss*** tensor(712.9091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(618.6425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7498647
Old  loss*** tensor(5143.7397, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3857.1089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84871507
Old  loss*** tensor(3120.3674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2648.3027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77046645
Old  loss*** tensor(4276.3018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3294.7471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86974657
Old  loss*** tensor(2903.7612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2525.5364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8092895
Old  loss*** tensor(3084.2351, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2496.0391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7656586
Old  loss*** tensor(3295.0103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2522.8530, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86131537
Old  loss*** tensor(3152.7737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2715.5325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.867635
Old  loss*** tensor(1894.5603, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1643.7869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86845684
Old  loss*** tensor(1037.5485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(901.0660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8215865
Old  loss*** tensor(2004.3856, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1646.7761, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787251
Old  loss*** tensor(589.7175, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(518.1996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877627
Old  loss*** tensor(613.1780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(544.3566, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85203624
Old  loss*** tensor(2507.8386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2136.7693, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87738836
Old  loss*** tensor(2298.3711, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2016.5641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798554
Old  loss*** tensor(785.3053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(690.9551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88619006
Old  loss*** tensor(1917.7111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1699.4564, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8791872
Old  loss*** tensor(971.7108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.3157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81800604
Old  loss*** tensor(4370.0327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3574.7131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78395486
Old  loss*** tensor(3188.8503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2499.9148, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8031074
Old  loss*** tensor(1973.1656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.6639, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88996696
Old  loss*** tensor(430.1161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(382.7891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84146154
Old  loss*** tensor(2157.3750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1815.3481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697804
Old  loss*** tensor(1553.5892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1351.2815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86578906
Old  loss*** tensor(1558.2253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1349.0945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.872817
Old  loss*** tensor(1487.2692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1298.1138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83700323
Old  loss*** tensor(4051.5203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3391.1355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8411354
Old  loss*** tensor(1904.8243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1602.2152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79052955
Old  loss*** tensor(3858.0623, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3049.9121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7092628
Old  loss*** tensor(4993.4502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3541.6685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.831781
Old  loss*** tensor(4513.6812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3754.3943, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88340974
Old  loss*** tensor(748.9194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(661.6027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73685443
Old  loss*** tensor(2853.6614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2102.7332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8965304
Old  loss*** tensor(1894.6078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1698.5735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728665
Old  loss*** tensor(1620.4048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.3971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8119081
Old  loss*** tensor(4392.3354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3566.1729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.868998
Old  loss*** tensor(310.8234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(270.1049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8400607
Old  loss*** tensor(1422.2990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.8175, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621352
Old  loss*** tensor(2104.5420, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1814.3997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84797573
Old  loss*** tensor(3137.9775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2660.9287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9035907
Old  loss*** tensor(746.5702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.5939, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77398723
Old  loss*** tensor(4803.6450, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3717.9600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87626565
Old  loss*** tensor(1486.4452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1302.5209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88093966
Old  loss*** tensor(1296.7380, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1142.3480, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86123866
Old  loss*** tensor(1952.6404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1681.6893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774011
Old  loss*** tensor(1368.5057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.7285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8995998
Old  loss*** tensor(1298.9066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1168.4961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8029386
Old  loss*** tensor(3614.8352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2902.4907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8922316
Old  loss*** tensor(140.8264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(125.6497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622198
Old  loss*** tensor(1417.9692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1222.6012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84208834
Old  loss*** tensor(1424.5516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.5983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8261627
Old  loss*** tensor(4459.2549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3684.0701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7780225
Old  loss*** tensor(3211.3618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2498.5117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90539944
Old  loss*** tensor(447.2889, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(404.9751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865636
Old  loss*** tensor(923.0942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.0635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82590413
Old  loss*** tensor(2728.8467, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2253.7656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7717211
Old  loss*** tensor(3819.3787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2947.4951, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808635
Old  loss*** tensor(731.5033, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.3546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80410033
Old  loss*** tensor(3382.1328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2719.5742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7903444
Old  loss*** tensor(4932.5029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3898.3762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78912973
Old  loss*** tensor(4057.3015, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3201.7373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81057966
Old  loss*** tensor(3303.5405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2677.7827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790859
Old  loss*** tensor(169.2878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(148.8185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8312099
Old  loss*** tensor(4061.8489, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3376.2490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84761465
Old  loss*** tensor(1156.8872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(980.5945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8437369
Old  loss*** tensor(2788.0564, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2352.3860, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84679925
Old  loss*** tensor(1263.9304, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1070.2953, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79235446
Old  loss*** tensor(3963.3108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3140.3469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7900015
Old  loss*** tensor(2890.4441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2283.4553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78604704
Old  loss*** tensor(2906.0461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2284.2891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8818874
Old  loss*** tensor(1090.2371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.4663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8152805
Old  loss*** tensor(1501.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1223.8088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89462775
Old  loss*** tensor(2102.5986, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1881.0431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.911897
Old  loss*** tensor(1019.8077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.9596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8393542
Old  loss*** tensor(2628.2217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2206.0090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88934743
Old  loss*** tensor(553.7684, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(492.4925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83685946
Old  loss*** tensor(2616.4915, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2189.6357, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88577324
Old  loss*** tensor(596.8008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(528.6302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8649806
Old  loss*** tensor(1498.7869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1296.4215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636557
Old  loss*** tensor(590.9808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.4040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84561455
Old  loss*** tensor(2156.3801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1823.4664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81603074
Old  loss*** tensor(4388.3086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3580.9946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88210607
Old  loss*** tensor(855.6084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(754.7374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84744537
Old  loss*** tensor(2219.3049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1880.7397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79864436
Old  loss*** tensor(3577.5024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.1521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809277
Old  loss*** tensor(1093.7494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(963.5141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85878706
Old  loss*** tensor(2766.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.4060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8957665
Old  loss*** tensor(742.9028, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.4675, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8628924
Old  loss*** tensor(1779.7069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1535.6956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8855625
Old  loss*** tensor(4151.7676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3676.6497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82497406
Old  loss*** tensor(2396.3911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1976.9604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8678967
Old  loss*** tensor(1671.3245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1450.5370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.858544
Old  loss*** tensor(1777.7721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1526.2955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84292376
Old  loss*** tensor(2604.1404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2195.0918, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8340446
Old  loss*** tensor(3738.7678, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.2991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8897996
Old  loss*** tensor(449.2141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.7105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8903284
Old  loss*** tensor(1080.9248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(962.3781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452717
Old  loss*** tensor(2755.3110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2328.9866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9146946
Old  loss*** tensor(535.8918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(490.1774, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697686
Old  loss*** tensor(1013.1307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.1893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79132944
Old  loss*** tensor(2482.6562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1964.5990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887738
Old  loss*** tensor(811.8010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(720.6666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87875867
Old  loss*** tensor(383.0214, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(336.5834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8550285
Old  loss*** tensor(2504.5449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.4573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8482226
Old  loss*** tensor(2137.8845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1813.4020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86739355
Old  loss*** tensor(1123.2908, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.3351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84938085
Old  loss*** tensor(3431.7144, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2914.8325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88337135
Old  loss*** tensor(1705.8544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1506.9028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8666503
Old  loss*** tensor(1085.6874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(940.9113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7427422
Old  loss*** tensor(4378.4883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3252.0879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8943957
Old  loss*** tensor(658.5085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(588.9672, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85820675
Old  loss*** tensor(2019.6757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1733.2993, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8602815
Old  loss*** tensor(1644.2876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1414.5503, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7646427
Old  loss*** tensor(5113.2832, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3909.8347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77285683
Old  loss*** tensor(4644.0928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3589.2188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78649384
Old  loss*** tensor(3631.3560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2856.0391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8186996
Old  loss*** tensor(3290.2686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2693.7415, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.797457
Old  loss*** tensor(3009.6731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2400.0847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81730866
Old  loss*** tensor(3103.0962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2536.1875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81974554
Old  loss*** tensor(3806.4829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3120.3474, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7878613
Old  loss*** tensor(1919.2537, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.1057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8352888
Old  loss*** tensor(3017.7646, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2520.7051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8519568
Old  loss*** tensor(1394.8744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1188.3727, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85219634
Old  loss*** tensor(1382.4911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1178.1538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87581396
Old  loss*** tensor(574.2679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(502.9519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85500765
Old  loss*** tensor(2282.3171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1951.3986, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8714568
Old  loss*** tensor(885.1896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(771.4045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8446423
Old  loss*** tensor(1698.6356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1434.7395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8024767
Old  loss*** tensor(3469.0781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2783.8545, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88548386
Old  loss*** tensor(481.5803, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(426.4315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.817644
Old  loss*** tensor(2765.3389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2261.0627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.812204
Old  loss*** tensor(2246.0151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1824.2225, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8029555
Old  loss*** tensor(2306.1389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1851.7269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.786399
Old  loss*** tensor(3975.8245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3126.5845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86419404
Old  loss*** tensor(970.7371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(838.9052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7950475
Old  loss*** tensor(4721.7197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3753.9915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7641479
Old  loss*** tensor(3844.3057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2937.6179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8504697
Old  loss*** tensor(1697.1084, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1443.3392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.827664
Old  loss*** tensor(1493.0613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1235.7531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857985
Old  loss*** tensor(1183.8994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1015.7679, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81750095
Old  loss*** tensor(1826.2988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1493.0010, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8292824
Old  loss*** tensor(3464.8960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2873.3772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8233863
Old  loss*** tensor(2051.1418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1688.8821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86515886
Old  loss*** tensor(1178.9078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1019.9426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84990394
Old  loss*** tensor(1399.2858, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1189.2585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88778174
Old  loss*** tensor(475.9905, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(422.5757, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.879676
Old  loss*** tensor(2558.7798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2250.8972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8274423
Old  loss*** tensor(2992.0735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2475.7681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808446
Old  loss*** tensor(867.6146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(764.2336, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85421693
Old  loss*** tensor(1662.6713, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1420.2820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88794905
Old  loss*** tensor(3734.1265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3315.7141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86569893
Old  loss*** tensor(1201.2861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1039.9521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811349
Old  loss*** tensor(933.9598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(822.9446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7899066
Old  loss*** tensor(2440.6108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1927.8546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88452303
Old  loss*** tensor(1064.0558, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(941.1818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9124448
Old  loss*** tensor(465.5719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(424.8087, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813198
Old  loss*** tensor(173.1804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(152.6273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8293099
Old  loss*** tensor(3617.8237, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3000.2969, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88977134
Old  loss*** tensor(393.2334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(349.8878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8875969
Old  loss*** tensor(1375.9324, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1221.2733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86887014
Old  loss*** tensor(975.6786, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(847.7380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84449786
Old  loss*** tensor(2059.2979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1739.0726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8507567
Old  loss*** tensor(1536.2363, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.9634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85365415
Old  loss*** tensor(1769.1890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1510.2755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7851956
Old  loss*** tensor(2172.4797, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1705.8215, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8938353
Old  loss*** tensor(105.3648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(94.1788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8899561
Old  loss*** tensor(713.9969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(635.4259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79895437
Old  loss*** tensor(4530.7769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3619.8840, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865196
Old  loss*** tensor(2138.5967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1850.3053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83486164
Old  loss*** tensor(3020.4958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2521.6960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87311804
Old  loss*** tensor(799.3093, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(697.8914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85180616
Old  loss*** tensor(1172.8523, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.0428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9092554
Old  loss*** tensor(926.0453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(842.0117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86686146
Old  loss*** tensor(1674.5249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1451.5811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86956656
Old  loss*** tensor(3288.7605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2859.7961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79818064
Old  loss*** tensor(3202.7151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2556.3452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8310592
Old  loss*** tensor(3875.8130, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3221.0300, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89267695
Old  loss*** tensor(636.5120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(568.1996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89371884
Old  loss*** tensor(273.3731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(244.3187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83978575
Old  loss*** tensor(2633.4927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2211.5696, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8937419
Old  loss*** tensor(749.5473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(669.9019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74687713
Old  loss*** tensor(5030.0601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3756.8369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83604276
Old  loss*** tensor(2671.1155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2233.1667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86410505
Old  loss*** tensor(1312.2539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1133.9252, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85472393
Old  loss*** tensor(1794.4906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1533.7941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88134897
Old  loss*** tensor(1350.1571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1189.9596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7863699
Old  loss*** tensor(2419.4119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1902.5527, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8241459
Old  loss*** tensor(2320.4614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1912.3988, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80362415
Old  loss*** tensor(4425.5220, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3556.4563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82958055
Old  loss*** tensor(2511.0469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2083.1157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88797665
Old  loss*** tensor(692.1013, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(614.5698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101258
Old  loss*** tensor(2783.9387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.3406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7551426
Old  loss*** tensor(4508.6333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3404.6611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7939751
Old  loss*** tensor(2954.6392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2345.9099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87492347
Old  loss*** tensor(1047.3052, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(916.3119, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8848767
Old  loss*** tensor(722.5316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(639.3514, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8468542
Old  loss*** tensor(3062.6206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2593.5933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8889328
Old  loss*** tensor(1163.9762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.6967, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8688058
Old  loss*** tensor(2012.9484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1748.8612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9071896
Old  loss*** tensor(870.8784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(790.0519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8323556
Old  loss*** tensor(1651.8945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.9637, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8649708
Old  loss*** tensor(1388.0619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1200.6331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83883834
Old  loss*** tensor(2092.1448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1754.9712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85649765
Old  loss*** tensor(1658.3069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1420.3359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85533094
Old  loss*** tensor(4032.2251, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3448.8870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.847455
Old  loss*** tensor(2507.4937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2124.9880, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85619277
Old  loss*** tensor(1647.3048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1410.4105, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86002904
Old  loss*** tensor(1330.4722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1144.2448, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8703741
Old  loss*** tensor(1100.6755, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(957.9995, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746254
Old  loss*** tensor(3806.7271, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3329.4602, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.902068
Old  loss*** tensor(435.5512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(392.8968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806288
Old  loss*** tensor(1747.1506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1538.5912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84837407
Old  loss*** tensor(1451.6211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.5177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.856839
Old  loss*** tensor(2047.3727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1754.2688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7834121
Old  loss*** tensor(4237.2656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3319.5251, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86110544
Old  loss*** tensor(2916.6289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2511.5249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8602155
Old  loss*** tensor(1338.0250, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1150.9899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7829086
Old  loss*** tensor(4875.1592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3816.8042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8972408
Old  loss*** tensor(786.4761, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(705.6584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83457506
Old  loss*** tensor(3249.4990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2711.9509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8243598
Old  loss*** tensor(4117.2061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3394.0591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847396
Old  loss*** tensor(465.0447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(411.4435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8357873
Old  loss*** tensor(1975.2997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1650.9304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7267339
Old  loss*** tensor(4352.6030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3163.1843, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78760725
Old  loss*** tensor(4653.1382, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3664.8455, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822965
Old  loss*** tensor(647.9262, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.6630, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8577671
Old  loss*** tensor(1554.2297, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1333.1671, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84874034
Old  loss*** tensor(1437.2772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.8751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061743
Old  loss*** tensor(1114.1265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.1801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85273176
Old  loss*** tensor(2427.7681, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2070.2349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8314769
Old  loss*** tensor(1896.8490, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1577.1862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635902
Old  loss*** tensor(1642.4260, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1418.3829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7705025
Old  loss*** tensor(3902.1008, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3006.5784, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.777079
Old  loss*** tensor(3914.3149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3041.7319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88274133
Old  loss*** tensor(1086.4574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(959.0609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82084006
Old  loss*** tensor(1815.6208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.3344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86426675
Old  loss*** tensor(1597.6000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1380.7526, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8882625
Old  loss*** tensor(1298.9075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1153.7708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84887266
Old  loss*** tensor(2467.7715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2094.8237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9021944
Old  loss*** tensor(1276.1838, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1151.3658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80589676
Old  loss*** tensor(2743.0413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2210.6082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8628622
Old  loss*** tensor(1923.6700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1659.8622, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90230674
Old  loss*** tensor(1102.5756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(994.8613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877757
Old  loss*** tensor(2299.8696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2041.7684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8930023
Old  loss*** tensor(1375.5928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1228.4075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86282325
Old  loss*** tensor(1574.7063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1358.6932, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7704764
Old  loss*** tensor(4515.0708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3478.7556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683541
Old  loss*** tensor(2227.3005, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1934.0856, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8358152
Old  loss*** tensor(1301.8988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1088.1469, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81435436
Old  loss*** tensor(3314.6614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2699.3088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8375809
Old  loss*** tensor(2049.4963, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1716.6190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822355
Old  loss*** tensor(857.6591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(756.6573, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632573
Old  loss*** tensor(777.3090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(671.0177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81343544
Old  loss*** tensor(3026.9895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2462.2605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77578896
Old  loss*** tensor(3328.4524, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2582.1765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7698888
Old  loss*** tensor(5231.5029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4027.6755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85605025
Old  loss*** tensor(1064.4327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(911.2079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9054768
Old  loss*** tensor(852.9736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(772.3478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7906941
Old  loss*** tensor(3435.8115, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2716.6760, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8510412
Old  loss*** tensor(3084.3689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2624.9250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87795836
Old  loss*** tensor(1395.0378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1224.7852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87113154
Old  loss*** tensor(1018.2518, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.0313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.841182
Old  loss*** tensor(2391.2183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2011.4497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8379302
Old  loss*** tensor(3132.5317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2624.8430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84745437
Old  loss*** tensor(2155.4668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1826.6598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90299845
Old  loss*** tensor(611.8545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(552.5037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76871747
Old  loss*** tensor(3255.8359, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2502.8179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622811
Old  loss*** tensor(1862.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1606.0970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8777985
Old  loss*** tensor(138.9075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(121.9328, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80212784
Old  loss*** tensor(3523.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2825.9680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8924192
Old  loss*** tensor(556.0975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(496.2721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82148534
Old  loss*** tensor(3818.2197, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3136.6116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8790469
Old  loss*** tensor(912.4284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.0674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7806773
Old  loss*** tensor(4374.1118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3414.7698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8666101
Old  loss*** tensor(267.1475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(231.5127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8336417
Old  loss*** tensor(2262.4480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1886.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86013657
Old  loss*** tensor(1437.2373, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1236.2203, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731285
Old  loss*** tensor(808.6773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(706.0792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86340904
Old  loss*** tensor(772.0221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.5709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8134891
Old  loss*** tensor(2414.1736, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1963.9038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749294
Old  loss*** tensor(761.4725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.2347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.861454
Old  loss*** tensor(274.3980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(236.3813, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80005765
Old  loss*** tensor(4425.9629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3541.0254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8341494
Old  loss*** tensor(2664.7161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2222.7712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7699317
Old  loss*** tensor(4378.0371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3370.7896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74121135
Old  loss*** tensor(4172.5112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3092.7126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85942125
Old  loss*** tensor(2158.9534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1855.4504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85353947
Old  loss*** tensor(1199.2347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1023.5942, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9028553
Old  loss*** tensor(535.2125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(483.2194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80902034
Old  loss*** tensor(2248.4849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1819.0699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87356913
Old  loss*** tensor(1172.5458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1024.2998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83793414
Old  loss*** tensor(2832.0896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2373.1045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83960235
Old  loss*** tensor(3245.2903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2724.7534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8645242
Old  loss*** tensor(919.0140, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(794.5099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84855247
Old  loss*** tensor(4126.1284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3501.2363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85650945
Old  loss*** tensor(2084.5662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1785.4506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88613546
Old  loss*** tensor(923.1606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(818.0453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814694
Old  loss*** tensor(568.0839, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(500.7486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9053725
Old  loss*** tensor(402.3398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(364.2673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.894979
Old  loss*** tensor(1517.8423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1358.4370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667749
Old  loss*** tensor(2485.8174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2154.6440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8671396
Old  loss*** tensor(956.3207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(829.2635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88856286
Old  loss*** tensor(3822.7217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3396.7285, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8322503
Old  loss*** tensor(1435.3284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.5525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8746288
Old  loss*** tensor(1537.8947, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1345.0869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8877824
Old  loss*** tensor(1311.6404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1164.4513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8466917
Old  loss*** tensor(1653.5101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1400.0133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83486736
Old  loss*** tensor(3204.1411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2675.0327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73424256
Old  loss*** tensor(5073.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3725.4231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632238
Old  loss*** tensor(1104.1671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(953.1433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82393026
Old  loss*** tensor(3908.6211, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3220.4312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613871
Old  loss*** tensor(818.1207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(704.7186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8964771
Old  loss*** tensor(907.8407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(813.8584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347684
Old  loss*** tensor(2434.5283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2032.2673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8501048
Old  loss*** tensor(3615.3276, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3073.4075, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8236147
Old  loss*** tensor(2102.3457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1731.5228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85421455
Old  loss*** tensor(1881.5236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1607.2249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90111023
Old  loss*** tensor(295.9048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(266.6428, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8971964
Old  loss*** tensor(514.7578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(461.8389, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8263213
Old  loss*** tensor(1890.4800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.1439, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8291694
Old  loss*** tensor(3115.9158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2583.6221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8117219
Old  loss*** tensor(2491.9609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2022.7793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88193077
Old  loss*** tensor(818.0467, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(721.4606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558292
Old  loss*** tensor(1866.4122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1597.3301, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87099534
Old  loss*** tensor(1440.0111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1254.2429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8956449
Old  loss*** tensor(1420.5042, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1272.2673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814688
Old  loss*** tensor(1360.9821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1199.6632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88158095
Old  loss*** tensor(644.9061, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(568.5369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79608953
Old  loss*** tensor(4317.6997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3437.2756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8000345
Old  loss*** tensor(5056.2212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4045.1516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7565155
Old  loss*** tensor(3460.7466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2618.1084, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8960184
Old  loss*** tensor(868.4000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(778.1024, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8095067
Old  loss*** tensor(732.5825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(593.0305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579255
Old  loss*** tensor(1744.1675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1496.3657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84501475
Old  loss*** tensor(2573.8103, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2174.9077, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78038585
Old  loss*** tensor(3840.1626, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2996.8086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787677
Old  loss*** tensor(985.2018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(865.7635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8604841
Old  loss*** tensor(1272.1016, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1094.6232, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8991806
Old  loss*** tensor(387.5257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(348.4556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667021
Old  loss*** tensor(1502.8147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1302.4927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83311486
Old  loss*** tensor(2480.4001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2066.4583, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85518855
Old  loss*** tensor(3884.0479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3321.5933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87189865
Old  loss*** tensor(1968.5266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1716.3557, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88905334
Old  loss*** tensor(728.6882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.8427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88712573
Old  loss*** tensor(615.8056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(546.2970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8092686
Old  loss*** tensor(4141.3599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3351.4724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8754047
Old  loss*** tensor(1798.0245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1573.9991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86519146
Old  loss*** tensor(1266.9635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1096.1660, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83917844
Old  loss*** tensor(2374.1958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1992.3739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8083716
Old  loss*** tensor(3328.9216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2691.0056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7944656
Old  loss*** tensor(3401.4971, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2702.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648361
Old  loss*** tensor(1537.2188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1329.4423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8303542
Old  loss*** tensor(1979.9634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1644.0709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85156274
Old  loss*** tensor(1255.2256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1068.9033, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83549726
Old  loss*** tensor(4146.9492, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3464.7646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8936112
Old  loss*** tensor(279.8266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(250.0562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915886
Old  loss*** tensor(667.9166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(595.5068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80773854
Old  loss*** tensor(3614.7791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2919.7964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86451334
Old  loss*** tensor(3288.1584, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2842.6567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7698983
Old  loss*** tensor(3855.0298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2967.9810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8361778
Old  loss*** tensor(1447.0505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1209.9916, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7987738
Old  loss*** tensor(4510.5679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3602.9236, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563843
Old  loss*** tensor(1891.4320, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1619.7926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8727779
Old  loss*** tensor(1260.1350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1099.8180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8256844
Old  loss*** tensor(3956.1345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3266.5186, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523419
Old  loss*** tensor(1430.7566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1219.4938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89031315
Old  loss*** tensor(599.5203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(533.7608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8288701
Old  loss*** tensor(2015.3701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1670.4801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89764106
Old  loss*** tensor(925.8066, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(831.0420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8621383
Old  loss*** tensor(2220.0056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1913.9518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87049466
Old  loss*** tensor(914.0778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(795.6998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8301651
Old  loss*** tensor(3111.0779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2582.7083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86354405
Old  loss*** tensor(2408.5127, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2079.8567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77420217
Old  loss*** tensor(3538.4521, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.4773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.726174
Old  loss*** tensor(4833.7476, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3510.1418, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879484
Old  loss*** tensor(1069.5547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(949.7094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822659
Old  loss*** tensor(584.3149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(515.5211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8260231
Old  loss*** tensor(2784.5190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2300.0771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88950753
Old  loss*** tensor(990.9750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(881.4797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9058604
Old  loss*** tensor(979.3743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(887.1765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.889011
Old  loss*** tensor(1162.8484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.7850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8896869
Old  loss*** tensor(1717.7288, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.2407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523512
Old  loss*** tensor(2132.1167, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1817.3123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87568665
Old  loss*** tensor(124.0332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(108.6142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80446637
Old  loss*** tensor(1589.6245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1278.7994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.796731
Old  loss*** tensor(4011.2236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3195.8662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.819847
Old  loss*** tensor(2705.1157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2217.7810, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9119533
Old  loss*** tensor(537.1119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(489.8210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87361395
Old  loss*** tensor(973.6551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.5987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8130468
Old  loss*** tensor(2995.3499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2435.3596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.846251
Old  loss*** tensor(1765.6083, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1494.1478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762698
Old  loss*** tensor(2803.6582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2456.7610, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7887415
Old  loss*** tensor(3922.2168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3093.6152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83216304
Old  loss*** tensor(3925.3330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3266.5171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.871483
Old  loss*** tensor(2272.4541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1980.4052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632984
Old  loss*** tensor(2307.4707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1992.0358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862926
Old  loss*** tensor(1540.5125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1329.3483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531823
Old  loss*** tensor(3958.9216, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3377.6819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390865
Old  loss*** tensor(1861.7401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1562.1609, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84361815
Old  loss*** tensor(1542.1566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1300.9913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82449317
Old  loss*** tensor(1751.8541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1444.3917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885536
Old  loss*** tensor(1011.5574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.8229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82630646
Old  loss*** tensor(3149.4985, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2602.4509, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887757
Old  loss*** tensor(833.6387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(740.0686, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88245314
Old  loss*** tensor(493.2092, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(435.2340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.841429
Old  loss*** tensor(2573.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2165.1853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8123686
Old  loss*** tensor(2677.9756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2175.5032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7513532
Old  loss*** tensor(4585.1846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3445.0930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8249881
Old  loss*** tensor(2604.0630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2148.3210, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8540791
Old  loss*** tensor(1004.0988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(857.5798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890766
Old  loss*** tensor(784.5960, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(698.8915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89215875
Old  loss*** tensor(439.5639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(392.1608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86783934
Old  loss*** tensor(598.5010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.4028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88499177
Old  loss*** tensor(1168.6421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.2386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84845173
Old  loss*** tensor(3820.1943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3241.2505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8210734
Old  loss*** tensor(2769.3767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2273.8616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88614887
Old  loss*** tensor(597.8466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(529.7811, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8033297
Old  loss*** tensor(2194.4390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1762.8580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8039188
Old  loss*** tensor(2268.3967, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1823.6067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79788625
Old  loss*** tensor(2710.4419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2162.6243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84638375
Old  loss*** tensor(1119.1780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(947.2540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87258184
Old  loss*** tensor(1193.3096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1041.2603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86690724
Old  loss*** tensor(2186.3557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1895.3676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71249735
Old  loss*** tensor(4534.0107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3230.4707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9110788
Old  loss*** tensor(744.3499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.1614, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8910094
Old  loss*** tensor(1221.9618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1088.7794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79082835
Old  loss*** tensor(3312.1895, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2619.3733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915912
Old  loss*** tensor(734.8720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(655.2054, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8237225
Old  loss*** tensor(4439.1460, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3656.6243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83341736
Old  loss*** tensor(2708.5347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2257.3398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8578695
Old  loss*** tensor(1850.5336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1587.5164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648473
Old  loss*** tensor(2199.0842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1901.8721, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83640534
Old  loss*** tensor(1649.6111, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1379.7435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638023
Old  loss*** tensor(2679.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2314.7036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076155
Old  loss*** tensor(4325.0088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3492.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8683025
Old  loss*** tensor(1156.0730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.8211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84536254
Old  loss*** tensor(2175.0527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1838.7081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86332446
Old  loss*** tensor(1775.9087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1533.1854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78941715
Old  loss*** tensor(5024.1187, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3966.1255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79155475
Old  loss*** tensor(1564.6104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.4747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8701357
Old  loss*** tensor(2145.5901, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1866.9546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7617294
Old  loss*** tensor(3942.8662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3003.3972, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7841692
Old  loss*** tensor(3320.7100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2603.9985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8466104
Old  loss*** tensor(3364.0859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2848.0703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8436235
Old  loss*** tensor(2103.0864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1774.2131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7809068
Old  loss*** tensor(4626.3647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.7598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8412829
Old  loss*** tensor(3703.1663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3115.4104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579391
Old  loss*** tensor(1617.5272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1387.7399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.810851
Old  loss*** tensor(3754.3862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3044.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8455774
Old  loss*** tensor(1457.4700, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1232.4037, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89246655
Old  loss*** tensor(759.4398, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(677.7747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8957608
Old  loss*** tensor(1634.9855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1464.5559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86959004
Old  loss*** tensor(576.5784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(501.3868, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86399263
Old  loss*** tensor(1243.6924, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1074.5410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90720224
Old  loss*** tensor(1137.3309, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1031.7892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84192866
Old  loss*** tensor(2009.0801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.5021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8817681
Old  loss*** tensor(210.5134, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(185.6240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8830935
Old  loss*** tensor(814.1842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.0007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89414215
Old  loss*** tensor(380.6279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(340.3354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89107955
Old  loss*** tensor(841.2628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(749.6320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8698321
Old  loss*** tensor(1579.7516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.1187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8598141
Old  loss*** tensor(4376.5659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3763.0332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8628699
Old  loss*** tensor(1575.5710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1359.5128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8810766
Old  loss*** tensor(904.6979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(797.1081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83223844
Old  loss*** tensor(3599.0620, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2995.2778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8417464
Old  loss*** tensor(1842.2515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1550.7085, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86476624
Old  loss*** tensor(2204.7583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.6006, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8050827
Old  loss*** tensor(4375.5781, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3522.7021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87803036
Old  loss*** tensor(1018.0233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(893.8554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73624545
Old  loss*** tensor(3294.4958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2425.5576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876802
Old  loss*** tensor(765.4615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(679.4850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8909769
Old  loss*** tensor(1528.3662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1361.7390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86670864
Old  loss*** tensor(1649.6024, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1429.7246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101635
Old  loss*** tensor(2532.9639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2052.1147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81251293
Old  loss*** tensor(3645.9404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2962.3738, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481077
Old  loss*** tensor(3079.6997, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2611.9170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83351487
Old  loss*** tensor(1434.3391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1195.5430, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8151183
Old  loss*** tensor(4089.8704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3333.7283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8376328
Old  loss*** tensor(1032.5808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.9235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804769
Old  loss*** tensor(877.6557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(772.7556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76748747
Old  loss*** tensor(3720.4375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2855.3892, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83294797
Old  loss*** tensor(2475.5859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2062.0342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8601138
Old  loss*** tensor(1219.2086, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.6582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8768289
Old  loss*** tensor(1069.6682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(937.9160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648889
Old  loss*** tensor(978.1473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(845.9888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716439
Old  loss*** tensor(1511.1456, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1317.1809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88347614
Old  loss*** tensor(1727.8926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1526.5519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851451
Old  loss*** tensor(415.5104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(367.7870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8309123
Old  loss*** tensor(3079.8547, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2559.0891, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8102094
Old  loss*** tensor(4428.9189, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3588.3518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8331268
Old  loss*** tensor(3788.3123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3156.1443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7819812
Old  loss*** tensor(3263.9841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2552.3743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90345144
Old  loss*** tensor(493.3436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(445.7120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808613
Old  loss*** tensor(468.0668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.3019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667054
Old  loss*** tensor(1890.4956, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1638.5028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697114
Old  loss*** tensor(2363.2505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.3459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8795847
Old  loss*** tensor(128.1809, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(112.7460, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7812439
Old  loss*** tensor(2656.5046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2075.3782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887235
Old  loss*** tensor(276.6029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(245.4118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8585963
Old  loss*** tensor(3106.8845, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2667.5596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84314954
Old  loss*** tensor(3802.9707, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3206.4729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870622
Old  loss*** tensor(2856.4639, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2486.9001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7994497
Old  loss*** tensor(2668.3210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2133.1885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86736006
Old  loss*** tensor(1430.8734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1241.0824, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7929919
Old  loss*** tensor(2728.1965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2163.4377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8717319
Old  loss*** tensor(1360.1884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1185.7196, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84146297
Old  loss*** tensor(1738.3217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1462.7333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85005105
Old  loss*** tensor(1877.9445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1596.3486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8826804
Old  loss*** tensor(1141.2961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1007.3998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7882583
Old  loss*** tensor(3441.7292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2712.9717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7934408
Old  loss*** tensor(3494.8989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2772.9954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748418
Old  loss*** tensor(997.6730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(872.8061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747853
Old  loss*** tensor(830.3513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(726.3791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8578814
Old  loss*** tensor(1496.8668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1284.1343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80012435
Old  loss*** tensor(4404.4131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3524.0781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86894363
Old  loss*** tensor(2450.5745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2129.4111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83650506
Old  loss*** tensor(2676.4185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2238.8376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87297904
Old  loss*** tensor(1428.1118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1246.7117, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7642853
Old  loss*** tensor(3355.2410, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2564.3613, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8053931
Old  loss*** tensor(2598.1128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2092.5022, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8925948
Old  loss*** tensor(613.4838, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(547.5925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535429
Old  loss*** tensor(1470.8213, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1255.4091, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8364026
Old  loss*** tensor(3384.1902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2830.5454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.803635
Old  loss*** tensor(2723.7510, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2188.9016, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8892999
Old  loss*** tensor(1604.4308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1426.8202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84573656
Old  loss*** tensor(2774.4668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2346.4680, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83966124
Old  loss*** tensor(2745.8137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2305.5535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8734163
Old  loss*** tensor(735.2904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.2146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88534427
Old  loss*** tensor(618.6056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(547.6789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90258944
Old  loss*** tensor(459.8739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(415.0773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759216
Old  loss*** tensor(1161.5624, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.4376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495605
Old  loss*** tensor(1353.0753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1149.5193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101982
Old  loss*** tensor(2143.0527, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1736.2975, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770648
Old  loss*** tensor(3763.3655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3300.7156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88035727
Old  loss*** tensor(653.5748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(575.3793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8123156
Old  loss*** tensor(3791.7864, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3080.1272, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.893559
Old  loss*** tensor(852.4689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(761.7313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87551045
Old  loss*** tensor(1423.7119, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1246.4746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8434697
Old  loss*** tensor(4207.5146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3548.9111, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7906276
Old  loss*** tensor(3850.7000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3044.4697, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8793677
Old  loss*** tensor(417.4635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(367.1039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8559919
Old  loss*** tensor(1276.1704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1092.3915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7909337
Old  loss*** tensor(2719.9194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2151.2761, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8761611
Old  loss*** tensor(1824.1428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1598.2429, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87412804
Old  loss*** tensor(2494.7085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2180.6946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8721859
Old  loss*** tensor(1383.4633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.6371, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7933475
Old  loss*** tensor(4937.2788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3916.9778, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77013755
Old  loss*** tensor(4537.7871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3494.7202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86993295
Old  loss*** tensor(1428.3079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1242.5321, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82902825
Old  loss*** tensor(4217.4902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3496.4185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77381086
Old  loss*** tensor(3291.7000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2547.1531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8039491
Old  loss*** tensor(4378.2974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.9282, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84913504
Old  loss*** tensor(2094.1421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1778.2095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84577894
Old  loss*** tensor(1038.4464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(878.2961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88484514
Old  loss*** tensor(340.9602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(301.6970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8412461
Old  loss*** tensor(2222.3562, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1869.5486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87794733
Old  loss*** tensor(1234.3596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1083.7028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87335515
Old  loss*** tensor(1808.8868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1579.8007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7738838
Old  loss*** tensor(3396.3418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2628.3740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7959448
Old  loss*** tensor(4059.4441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3231.0935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769467
Old  loss*** tensor(87.9151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(77.0968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9116585
Old  loss*** tensor(670.4872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(611.2554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738055
Old  loss*** tensor(577.5943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(504.7051, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.892291
Old  loss*** tensor(330.2731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(294.6997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77336484
Old  loss*** tensor(4142.8628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3203.9443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90239596
Old  loss*** tensor(888.7775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(802.0292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8996146
Old  loss*** tensor(446.2511, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.4540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87297106
Old  loss*** tensor(544.8987, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(475.6808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8822128
Old  loss*** tensor(1166.1715, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1028.8114, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87972474
Old  loss*** tensor(1748.0946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1537.8420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85504854
Old  loss*** tensor(1689.2716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1444.4092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8643758
Old  loss*** tensor(1743.9242, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.4059, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8152266
Old  loss*** tensor(3026.0193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2466.8914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87021947
Old  loss*** tensor(1567.5045, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1364.0730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84207964
Old  loss*** tensor(2322.2419, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1955.5127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8285883
Old  loss*** tensor(2389.8525, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1980.2039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8035587
Old  loss*** tensor(1894.0948, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1522.0164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8726723
Old  loss*** tensor(882.9199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(770.4998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85166645
Old  loss*** tensor(3567.7334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3038.5188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87259555
Old  loss*** tensor(729.9355, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(636.9385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8555788
Old  loss*** tensor(1610.0728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1377.5441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713298
Old  loss*** tensor(1455.5652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.2773, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87814
Old  loss*** tensor(1155.0077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1014.2584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8535427
Old  loss*** tensor(4222.2007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3603.8286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7977891
Old  loss*** tensor(2415.2146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1926.8319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89322186
Old  loss*** tensor(1376.5275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.5444, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8388627
Old  loss*** tensor(878.1264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(736.6275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.819239
Old  loss*** tensor(2000.2878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1638.7139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.754537
Old  loss*** tensor(4004.8193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3021.7844, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8133033
Old  loss*** tensor(4717.3535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3836.6392, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895911
Old  loss*** tensor(117.3939, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(104.4326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76175976
Old  loss*** tensor(4230.5879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3222.6917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87733394
Old  loss*** tensor(4117.4072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.3411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8595095
Old  loss*** tensor(1041.3612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.0599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78641784
Old  loss*** tensor(2987.4785, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2349.4065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.890018
Old  loss*** tensor(1568.8292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1396.2863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85229677
Old  loss*** tensor(2456.8474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2093.9631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.830492
Old  loss*** tensor(2102.5122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1746.1196, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8613527
Old  loss*** tensor(1259.3123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.7120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81136906
Old  loss*** tensor(1836.8475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1490.3612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8987371
Old  loss*** tensor(1019.3795, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(916.1541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8882269
Old  loss*** tensor(732.3451, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.4886, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775842
Old  loss*** tensor(995.1505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(873.3283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8358691
Old  loss*** tensor(2236.5688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1869.4788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71618694
Old  loss*** tensor(3349.7212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2399.0266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83479476
Old  loss*** tensor(2475.4534, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2066.4956, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8449106
Old  loss*** tensor(2289.7183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1934.6073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9018687
Old  loss*** tensor(532.4279, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(480.1800, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83595604
Old  loss*** tensor(1712.4000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1431.4911, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.792676
Old  loss*** tensor(2693.9395, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2135.4211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745861
Old  loss*** tensor(2266.3721, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1982.1376, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81520784
Old  loss*** tensor(3124.6035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2547.2012, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76396817
Old  loss*** tensor(3733.2275, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2852.0669, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7764809
Old  loss*** tensor(3971.0166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3083.4187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8291591
Old  loss*** tensor(4075.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3379.0452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82923627
Old  loss*** tensor(2447.9551, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2029.9331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85904306
Old  loss*** tensor(1184.2775, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.3453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8430927
Old  loss*** tensor(3011.1001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2538.6365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7973006
Old  loss*** tensor(3988.0808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3179.6992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8676642
Old  loss*** tensor(2491.1731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2161.5017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520795
Old  loss*** tensor(3130.8762, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2667.7554, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8118335
Old  loss*** tensor(4686.4658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3804.6299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8470203
Old  loss*** tensor(2252.0076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1907.4962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100593
Old  loss*** tensor(3196.1938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2589.1067, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8881993
Old  loss*** tensor(1488.9962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1322.5254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89917886
Old  loss*** tensor(549.4535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(494.0570, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7998879
Old  loss*** tensor(4743.8354, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3794.5366, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8696383
Old  loss*** tensor(1861.7294, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1619.0312, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86754966
Old  loss*** tensor(2525.7236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2191.1907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8693674
Old  loss*** tensor(963.2607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.4275, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9090235
Old  loss*** tensor(1713.4011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1557.5220, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8770877
Old  loss*** tensor(1250.5906, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1096.8777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865839
Old  loss*** tensor(1474.3136, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1307.1028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.864244
Old  loss*** tensor(1444.6313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1248.5139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907818
Old  loss*** tensor(570.0035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(507.7487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8850047
Old  loss*** tensor(1161.3772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1027.8242, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8777098
Old  loss*** tensor(539.7870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(473.7763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852939
Old  loss*** tensor(2024.9667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1727.1731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86838835
Old  loss*** tensor(1671.5734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1451.5748, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8401042
Old  loss*** tensor(2111.4817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1773.8646, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88725126
Old  loss*** tensor(1950.9004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1730.9388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88601863
Old  loss*** tensor(1800.0664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1594.8923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89857197
Old  loss*** tensor(406.3462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(365.1313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8806081
Old  loss*** tensor(896.9366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(789.8497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804851
Old  loss*** tensor(114.0305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(100.4021, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86383104
Old  loss*** tensor(1362.7847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1177.2157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86944693
Old  loss*** tensor(546.5834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(475.2253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88385254
Old  loss*** tensor(379.2590, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(335.2090, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84130657
Old  loss*** tensor(1648.4100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1386.8182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88290805
Old  loss*** tensor(3155.7886, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2786.2712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8871958
Old  loss*** tensor(755.6709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(670.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8141709
Old  loss*** tensor(1995.0509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1624.3124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.835959
Old  loss*** tensor(2135.3193, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1785.0394, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7049966
Old  loss*** tensor(4777.0615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3367.8120, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84510005
Old  loss*** tensor(2824.4614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2386.9524, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8005417
Old  loss*** tensor(3856.7446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3087.4849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859704
Old  loss*** tensor(1181.8531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1047.0869, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8966143
Old  loss*** tensor(237.3973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(212.8538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8534967
Old  loss*** tensor(3335.0818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2846.4812, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7948709
Old  loss*** tensor(3541.8293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2815.2971, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492367
Old  loss*** tensor(2256.0542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1915.9241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78253716
Old  loss*** tensor(2535.9973, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1984.5121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86451876
Old  loss*** tensor(1157.8873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.0153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81234
Old  loss*** tensor(3340.5640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2713.6738, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.881451
Old  loss*** tensor(789.9185, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(696.2744, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8498869
Old  loss*** tensor(2125.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1806.0121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89151794
Old  loss*** tensor(529.5757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(472.1263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89407116
Old  loss*** tensor(413.2500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(369.4749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88185656
Old  loss*** tensor(952.1805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.6866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876256
Old  loss*** tensor(1085.1737, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(963.2279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77120256
Old  loss*** tensor(3889.7842, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2999.8115, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631075
Old  loss*** tensor(3040.7295, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2624.4763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82962835
Old  loss*** tensor(3053.5464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.3086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.71883905
Old  loss*** tensor(4155.5586, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2987.1777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8232411
Old  loss*** tensor(2785.4822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2293.1235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7283829
Old  loss*** tensor(4694.2676, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3419.2241, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8533546
Old  loss*** tensor(1414.7356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1207.2711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83985776
Old  loss*** tensor(1268.1831, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1065.0934, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7340379
Old  loss*** tensor(4546.6665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3337.4255, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88701344
Old  loss*** tensor(751.1236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(666.2567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8927388
Old  loss*** tensor(434.7108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(388.0832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7887928
Old  loss*** tensor(3511.3000, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2769.6882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88599545
Old  loss*** tensor(1518.7267, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1345.5850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9088326
Old  loss*** tensor(804.0439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(730.7413, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8085759
Old  loss*** tensor(3835.0728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3100.9475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89950085
Old  loss*** tensor(1073.2808, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(965.4169, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84733486
Old  loss*** tensor(2355.6201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1995.9990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8568655
Old  loss*** tensor(1039.5988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.7963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8748683
Old  loss*** tensor(1064.6469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(931.4258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85756856
Old  loss*** tensor(443.1057, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(379.9935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8787911
Old  loss*** tensor(772.5959, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(678.9504, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7970351
Old  loss*** tensor(3095.8994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2467.5405, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82406366
Old  loss*** tensor(2525.8806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2081.4863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84257203
Old  loss*** tensor(2349.5938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1979.7020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9145272
Old  loss*** tensor(795.3599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(727.3782, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87123895
Old  loss*** tensor(1692.8928, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.9142, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7712203
Old  loss*** tensor(4599.4741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3547.2080, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82958704
Old  loss*** tensor(1540.1873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1277.7194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.859985
Old  loss*** tensor(1201.2855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1033.0875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8629638
Old  loss*** tensor(771.6509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(665.9068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.832885
Old  loss*** tensor(2716.6821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2262.6838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8440125
Old  loss*** tensor(3714.1724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3134.8079, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8428979
Old  loss*** tensor(1325.9613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1117.6500, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8724797
Old  loss*** tensor(956.1099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.1864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84646386
Old  loss*** tensor(1777.2759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1504.3998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8100077
Old  loss*** tensor(2820.2595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2284.4319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84525204
Old  loss*** tensor(1590.1970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1344.1173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83612907
Old  loss*** tensor(5076.9116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4244.9536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83200777
Old  loss*** tensor(2346.8628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1952.6080, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731094
Old  loss*** tensor(1644.5592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1435.8801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.897251
Old  loss*** tensor(444.8432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(399.1360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7947491
Old  loss*** tensor(2746.8020, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2183.0183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8880536
Old  loss*** tensor(1035.2787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.3829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82851547
Old  loss*** tensor(2135.4900, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1769.2865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86551464
Old  loss*** tensor(1405.8461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.7804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539257
Old  loss*** tensor(2398.7720, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2048.3730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89064646
Old  loss*** tensor(139.8184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(124.5287, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884536
Old  loss*** tensor(1041.6244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(925.4349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7917869
Old  loss*** tensor(4242.5166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3359.1692, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81029433
Old  loss*** tensor(3135.4062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2540.6018, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79393864
Old  loss*** tensor(2688.8210, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2134.7590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8680245
Old  loss*** tensor(544.0493, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(472.2481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88771033
Old  loss*** tensor(1818.8826, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1614.6409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8674471
Old  loss*** tensor(1880.5546, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1631.2816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86381686
Old  loss*** tensor(1040.2509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.5862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85545444
Old  loss*** tensor(1909.1470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1633.1882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8979287
Old  loss*** tensor(785.6466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(705.4547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84055895
Old  loss*** tensor(1793.1794, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1507.2731, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8939295
Old  loss*** tensor(450.9505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(403.1180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8763418
Old  loss*** tensor(2394.2896, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2098.2161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87136877
Old  loss*** tensor(1621.0610, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1412.5420, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813994
Old  loss*** tensor(3685.0266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3247.9802, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.875589
Old  loss*** tensor(851.2532, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.3479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75543416
Old  loss*** tensor(3198.5688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2416.3081, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88822556
Old  loss*** tensor(991.5078, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(880.6826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653641
Old  loss*** tensor(1455.2356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1259.3086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8636261
Old  loss*** tensor(1656.6461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.7229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759564
Old  loss*** tensor(1841.3702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1612.9601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8041246
Old  loss*** tensor(4200.8223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3377.9846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86153704
Old  loss*** tensor(1981.4390, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1707.0830, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8433193
Old  loss*** tensor(2082.5830, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1756.2825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87494844
Old  loss*** tensor(100.9221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(88.3017, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87625337
Old  loss*** tensor(1746.6724, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1530.5276, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86785984
Old  loss*** tensor(1426.5391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1238.0360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83782476
Old  loss*** tensor(3570.0452, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2991.0723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815663
Old  loss*** tensor(4044.8931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3299.2695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86192644
Old  loss*** tensor(1434.5402, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1236.4681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931945
Old  loss*** tensor(504.2980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(450.4362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87292004
Old  loss*** tensor(997.4849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(870.7245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87689984
Old  loss*** tensor(1619.0974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1419.7863, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7341844
Old  loss*** tensor(4018.0569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2949.9946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86605823
Old  loss*** tensor(1252.0779, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.3723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87901735
Old  loss*** tensor(2186.3965, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1921.8805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84384835
Old  loss*** tensor(2800.0486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2362.8164, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87755376
Old  loss*** tensor(1382.2673, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1213.0139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80649066
Old  loss*** tensor(3009.0117, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2426.7397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.854511
Old  loss*** tensor(3918.9375, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3348.7754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75392795
Old  loss*** tensor(3129.9453, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2359.7532, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.73189247
Old  loss*** tensor(4275.1807, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3128.9724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80013674
Old  loss*** tensor(1104.7571, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(883.9567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.70664614
Old  loss*** tensor(5185.0439, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3663.9912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84569144
Old  loss*** tensor(2718.9788, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2299.4170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77141273
Old  loss*** tensor(3189.9714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2460.7847, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79858315
Old  loss*** tensor(4110.3247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3282.4360, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87834585
Old  loss*** tensor(1502.5582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1319.7657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79596466
Old  loss*** tensor(4046.2112, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3220.6411, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7954259
Old  loss*** tensor(2743.6799, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2182.3940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8058213
Old  loss*** tensor(2270.7183, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1829.7931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879777
Old  loss*** tensor(575.3133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.8654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9016813
Old  loss*** tensor(633.2784, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.0153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8404037
Old  loss*** tensor(2058.5291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1729.9954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7353786
Old  loss*** tensor(4263.2671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3135.1155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7924018
Old  loss*** tensor(2687.6006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2129.6594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90256846
Old  loss*** tensor(767.4343, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(692.6620, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9098489
Old  loss*** tensor(602.4080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(548.1003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8723509
Old  loss*** tensor(1679.5739, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.1777, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78142977
Old  loss*** tensor(2728.6428, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.2427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87169856
Old  loss*** tensor(1434.2789, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1250.2589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88072896
Old  loss*** tensor(528.1816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(465.1848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87979984
Old  loss*** tensor(767.1536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(674.9416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8606416
Old  loss*** tensor(2879.1206, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2477.8909, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87362
Old  loss*** tensor(1852.7618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1618.6097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800154
Old  loss*** tensor(733.8829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(645.8282, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89210796
Old  loss*** tensor(239.6059, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(213.7544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81402063
Old  loss*** tensor(4601.8120, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3745.9700, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.828396
Old  loss*** tensor(3599.1853, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2981.5508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756092
Old  loss*** tensor(469.9244, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(411.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84643626
Old  loss*** tensor(2098.9233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1776.6049, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80723184
Old  loss*** tensor(4110.0654, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3317.7756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8810156
Old  loss*** tensor(967.4689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(852.3552, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88979065
Old  loss*** tensor(1006.7970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.8386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8769319
Old  loss*** tensor(735.6006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(645.0717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77680963
Old  loss*** tensor(3536.9004, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2747.4983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244022
Old  loss*** tensor(3497.2080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2883.1060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88252604
Old  loss*** tensor(1161.0243, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1024.6342, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8429157
Old  loss*** tensor(3939.6560, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3320.7979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8279015
Old  loss*** tensor(3339.4827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2764.7627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88433385
Old  loss*** tensor(1178.0735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1041.8103, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80599517
Old  loss*** tensor(4595.2075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3703.7151, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83773947
Old  loss*** tensor(2493.3572, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2088.7837, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8288686
Old  loss*** tensor(3634.1372, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3012.2224, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90501547
Old  loss*** tensor(944.6946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.9632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8799356
Old  loss*** tensor(1073.5605, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.6642, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8739298
Old  loss*** tensor(1208.6249, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1056.2533, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7877604
Old  loss*** tensor(4258.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3354.4146, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647284
Old  loss*** tensor(1144.0233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(989.2695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572768
Old  loss*** tensor(1193.2729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1022.9652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8926802
Old  loss*** tensor(709.7989, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(633.6234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87954646
Old  loss*** tensor(1358.0018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1194.4257, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82855
Old  loss*** tensor(2005.4589, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1661.6229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7428045
Old  loss*** tensor(5083.1978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3775.8223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8265443
Old  loss*** tensor(2873.7935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.3176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8400326
Old  loss*** tensor(3431.3433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2882.4402, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87635064
Old  loss*** tensor(1145.1879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.5861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641608
Old  loss*** tensor(2302.2368, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1989.5028, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84505296
Old  loss*** tensor(1544.2640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1304.9849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756523
Old  loss*** tensor(596.3804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(522.2219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823736
Old  loss*** tensor(1370.1334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.9695, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86257064
Old  loss*** tensor(1835.2958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1583.0723, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83320117
Old  loss*** tensor(2008.4191, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1673.4171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7252227
Old  loss*** tensor(5130.6514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3720.8650, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88367623
Old  loss*** tensor(1061.4717, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(937.9973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88862497
Old  loss*** tensor(367.3406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(326.4280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7302841
Old  loss*** tensor(3486.7241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2546.2991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8291918
Old  loss*** tensor(3039.0032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2519.9165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8140104
Old  loss*** tensor(4528.6069, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3686.3330, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88079476
Old  loss*** tensor(1301.0806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1145.9850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89498717
Old  loss*** tensor(982.6296, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(879.4409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8308915
Old  loss*** tensor(3359.3650, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2791.2678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8673413
Old  loss*** tensor(1059.9592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.3464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8462455
Old  loss*** tensor(2125.6636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1798.8333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.857959
Old  loss*** tensor(2457.6189, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2108.5361, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8250897
Old  loss*** tensor(2869.7954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2367.8386, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84131
Old  loss*** tensor(1769.5549, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1488.7443, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8886982
Old  loss*** tensor(1246.7645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1107.9974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7842413
Old  loss*** tensor(4210.4399, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3302.0010, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84192854
Old  loss*** tensor(1534.9978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1292.3585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8529872
Old  loss*** tensor(1880.5734, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1604.1050, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9111353
Old  loss*** tensor(223.2316, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(203.3941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82024527
Old  loss*** tensor(1172.5312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.7632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8203284
Old  loss*** tensor(4385.4023, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3597.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83840907
Old  loss*** tensor(2959.2349, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2481.0493, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8659734
Old  loss*** tensor(1543.1611, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.3365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86731756
Old  loss*** tensor(1322.6685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1147.1736, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.818415
Old  loss*** tensor(2066.9036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1691.5848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8612995
Old  loss*** tensor(2080.1240, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1791.6099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86517787
Old  loss*** tensor(945.4277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(817.9631, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8480685
Old  loss*** tensor(2201.4272, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1866.9611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8976551
Old  loss*** tensor(646.0582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(579.9374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8434869
Old  loss*** tensor(1285.6500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1084.4290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8523921
Old  loss*** tensor(1695.1174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1444.9047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84656185
Old  loss*** tensor(3343.4277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2830.4185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86387277
Old  loss*** tensor(601.8350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.9089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9033483
Old  loss*** tensor(748.7898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(676.4180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8706402
Old  loss*** tensor(1509.4662, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1314.2020, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8255459
Old  loss*** tensor(2540.1328, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2096.9963, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.907534
Old  loss*** tensor(836.6109, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(759.2529, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8126675
Old  loss*** tensor(3481.1365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2829.0063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690454
Old  loss*** tensor(1903.0424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1653.8302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801091
Old  loss*** tensor(732.3101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.5128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87126803
Old  loss*** tensor(969.2899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(844.5113, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85179716
Old  loss*** tensor(2655.7944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2262.1982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8417518
Old  loss*** tensor(2788.6199, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2347.3259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7325802
Old  loss*** tensor(4408.3291, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3229.4546, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811246
Old  loss*** tensor(135.4110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(119.3140, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87130606
Old  loss*** tensor(1619.5876, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1411.1565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884717
Old  loss*** tensor(295.0506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(262.1441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9109321
Old  loss*** tensor(716.7261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.8888, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81776416
Old  loss*** tensor(4251.1035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3476.4001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8431898
Old  loss*** tensor(2820.3445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2378.0857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7641696
Old  loss*** tensor(3873.6421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2960.1194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87972885
Old  loss*** tensor(1021.8163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.9213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557155
Old  loss*** tensor(1827.5809, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1563.8894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8950546
Old  loss*** tensor(3190.2878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2855.4817, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8211126
Old  loss*** tensor(2109.7417, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1732.3354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9075645
Old  loss*** tensor(521.8245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(473.5894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8290858
Old  loss*** tensor(363.0146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(300.9703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8504714
Old  loss*** tensor(1522.1090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.5101, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8327214
Old  loss*** tensor(2353.9507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1960.1852, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77506495
Old  loss*** tensor(3594.1680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2785.7136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83011615
Old  loss*** tensor(4879.6792, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4050.7004, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7782567
Old  loss*** tensor(2484.6499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1933.6954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83268213
Old  loss*** tensor(2426.6301, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2020.6116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87306714
Old  loss*** tensor(749.2073, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(654.1083, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76723003
Old  loss*** tensor(3173.2852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2434.6396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8874366
Old  loss*** tensor(1087.7772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(965.3334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7910657
Old  loss*** tensor(2571.8254, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2034.4829, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8997839
Old  loss*** tensor(1680.9348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1512.4781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8215825
Old  loss*** tensor(3723.8704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3059.4668, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88122153
Old  loss*** tensor(455.7118, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(401.5831, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284324
Old  loss*** tensor(3956.3274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3277.5498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7730187
Old  loss*** tensor(5277.5879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4079.6743, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88103145
Old  loss*** tensor(1901.0599, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1674.8936, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8557053
Old  loss*** tensor(978.2051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(837.0553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.886833
Old  loss*** tensor(1178.3229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.9756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84146833
Old  loss*** tensor(1170.7162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(985.1206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88005507
Old  loss*** tensor(817.5098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(719.4536, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81030357
Old  loss*** tensor(2908.7085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2356.9368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7636992
Old  loss*** tensor(3489.4192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2664.8665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87018
Old  loss*** tensor(485.9798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(422.8899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8612334
Old  loss*** tensor(3982.5742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3429.9260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7968979
Old  loss*** tensor(4096.2598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3264.3008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7846465
Old  loss*** tensor(4024.0649, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3157.4685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86603165
Old  loss*** tensor(964.2195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.0446, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72914255
Old  loss*** tensor(3451.0342, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2516.2959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7775036
Old  loss*** tensor(2530.6882, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1967.6193, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672836
Old  loss*** tensor(1604.7034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1391.7329, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885607
Old  loss*** tensor(467.1931, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(413.7495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8231815
Old  loss*** tensor(2340.2629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1926.4612, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8885143
Old  loss*** tensor(944.6683, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.3513, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83424973
Old  loss*** tensor(1716.7340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1432.1849, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88593674
Old  loss*** tensor(1423.0690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1260.7490, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609732
Old  loss*** tensor(992.0709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(854.1464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88382596
Old  loss*** tensor(1618.3698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.3572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88726866
Old  loss*** tensor(719.8376, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(638.6894, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815708
Old  loss*** tensor(683.1299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.2274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83431363
Old  loss*** tensor(1799.9764, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1501.7449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8463433
Old  loss*** tensor(2048.2261, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1733.5023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82318264
Old  loss*** tensor(1952.7333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1607.4562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635013
Old  loss*** tensor(935.7612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(808.0311, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8258263
Old  loss*** tensor(1631.9235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1347.6853, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8661911
Old  loss*** tensor(1104.1345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(956.3915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7301582
Old  loss*** tensor(5211.8135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3805.4485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670832
Old  loss*** tensor(4416.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3829.8582, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85953045
Old  loss*** tensor(1019.3462, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(876.1591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8244673
Old  loss*** tensor(1959.0101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1615.1398, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8219363
Old  loss*** tensor(2415.8081, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1985.6404, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.885474
Old  loss*** tensor(614.8270, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(544.4134, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89214885
Old  loss*** tensor(1269.2729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1132.3804, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620627
Old  loss*** tensor(1172.1418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1010.4598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88872206
Old  loss*** tensor(1282.5027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1139.7885, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91236573
Old  loss*** tensor(601.8677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(549.1235, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8676574
Old  loss*** tensor(2502.1018, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2170.9673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752162
Old  loss*** tensor(2311.9609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2023.4656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9274039
Old  loss*** tensor(648.7980, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(601.6978, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84014755
Old  loss*** tensor(4211.5693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3538.3396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895488
Old  loss*** tensor(493.1458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(438.6772, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87228537
Old  loss*** tensor(128.9106, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(112.4468, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.840111
Old  loss*** tensor(1958.0070, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1644.9432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704144
Old  loss*** tensor(612.0819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.7649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81412977
Old  loss*** tensor(3952.5386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3217.8794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83056813
Old  loss*** tensor(2805.8049, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2330.4121, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8385688
Old  loss*** tensor(2979.0256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2498.1179, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86574894
Old  loss*** tensor(1405.4498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.7667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85804325
Old  loss*** tensor(2594.6541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2226.3254, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862252
Old  loss*** tensor(802.0606, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(710.8063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8479149
Old  loss*** tensor(2986.2075, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2532.0498, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76040626
Old  loss*** tensor(4713.6538, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3584.2917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7453517
Old  loss*** tensor(4079.6887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3040.8027, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85621846
Old  loss*** tensor(2920.9258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2500.9507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8897863
Old  loss*** tensor(1336.8962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1189.5520, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84551847
Old  loss*** tensor(1624.9282, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.9069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8775078
Old  loss*** tensor(956.2629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.1281, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89515245
Old  loss*** tensor(421.4702, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(377.2801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682572
Old  loss*** tensor(1205.8710, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1047.0062, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90089726
Old  loss*** tensor(1416.3147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1275.9540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8616341
Old  loss*** tensor(2752.7512, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2371.8643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8591841
Old  loss*** tensor(1864.8772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1602.2728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88895464
Old  loss*** tensor(298.2386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(265.1206, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895414
Old  loss*** tensor(456.7032, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(408.9385, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88041735
Old  loss*** tensor(1194.8878, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1052., device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7742705
Old  loss*** tensor(4145.8105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3209.9788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8417282
Old  loss*** tensor(3123.5273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2629.1611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7438839
Old  loss*** tensor(4155.6978, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3091.3567, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85230064
Old  loss*** tensor(2328.9822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1984.9930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8907485
Old  loss*** tensor(2063.1760, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1837.7710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79973984
Old  loss*** tensor(3168.0884, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.6465, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91064286
Old  loss*** tensor(1191.6021, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1085.1239, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83091164
Old  loss*** tensor(3480.9958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2892.3999, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9095922
Old  loss*** tensor(1580.0408, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1437.1927, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9004824
Old  loss*** tensor(1684.3212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1516.7015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84864134
Old  loss*** tensor(2384.7407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2023.7896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88386214
Old  loss*** tensor(1334.4675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1179.4854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855417
Old  loss*** tensor(933.1408, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(798.2245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7807839
Old  loss*** tensor(2910.2407, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2272.2690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85150844
Old  loss*** tensor(4149.3872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3533.2383, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8185802
Old  loss*** tensor(2882.2080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2359.3184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85656226
Old  loss*** tensor(1192.0994, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.1073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81972307
Old  loss*** tensor(2847.1885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2333.9060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.813774
Old  loss*** tensor(2404.6768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1956.8634, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90303314
Old  loss*** tensor(1305.8671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1179.2412, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8307814
Old  loss*** tensor(2170.8672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1803.5161, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88514733
Old  loss*** tensor(1661.9128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1471.0377, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8937752
Old  loss*** tensor(1042.6943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(931.9344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74760705
Old  loss*** tensor(4948.3403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3699.4141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81217986
Old  loss*** tensor(2048.5208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1663.7673, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8055438
Old  loss*** tensor(3336.0801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2687.3586, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8347688
Old  loss*** tensor(2875.0264, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2399.9822, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9013584
Old  loss*** tensor(1648.2946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.7042, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8631544
Old  loss*** tensor(935.7902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(807.7314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88727117
Old  loss*** tensor(320.2633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(284.1604, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84925437
Old  loss*** tensor(2441.5840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2073.5259, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542837
Old  loss*** tensor(1683.0137, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1437.7711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83309144
Old  loss*** tensor(4024.3022, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3352.6118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7896309
Old  loss*** tensor(4305.6108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3399.8433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7616887
Old  loss*** tensor(3650.7859, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2780.7625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8612081
Old  loss*** tensor(1742.8036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1500.9165, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88207936
Old  loss*** tensor(415.4672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(366.4751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8895273
Old  loss*** tensor(608.3633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(541.1558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82966423
Old  loss*** tensor(3315.2883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2750.5762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77339494
Old  loss*** tensor(4003.4426, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3096.2422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8235316
Old  loss*** tensor(3514.4150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2894.2319, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7615161
Old  loss*** tensor(4997.6318, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3805.7771, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87464154
Old  loss*** tensor(1494.2300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.9156, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80176574
Old  loss*** tensor(3990.8652, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3199.7390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86797994
Old  loss*** tensor(694.4686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.7848, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91199714
Old  loss*** tensor(920.2307, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.2478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78676647
Old  loss*** tensor(3138.7976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2469.5007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86898637
Old  loss*** tensor(1697.0012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1474.6709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86908793
Old  loss*** tensor(802.1645, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(697.1515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8246681
Old  loss*** tensor(2710.3486, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2235.1382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75216675
Old  loss*** tensor(4013.9465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3019.1572, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88288265
Old  loss*** tensor(870.1341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(768.2263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8690663
Old  loss*** tensor(2600.1531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2259.7053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8194742
Old  loss*** tensor(1702.9508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1395.5243, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8578564
Old  loss*** tensor(1125.8445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(965.8129, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88191265
Old  loss*** tensor(469.8285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(414.3477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8271458
Old  loss*** tensor(4293.2998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3551.1851, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72130096
Old  loss*** tensor(4780.5269, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3448.1985, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410336
Old  loss*** tensor(2486.7754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2091.4617, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8709291
Old  loss*** tensor(1634.7155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1423.7213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.831948
Old  loss*** tensor(2587.4805, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2152.6492, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89165044
Old  loss*** tensor(306.7945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(273.5535, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8221982
Old  loss*** tensor(3630.0881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2984.6519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8096505
Old  loss*** tensor(3000.4258, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2429.2961, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824139
Old  loss*** tensor(1141.7804, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1007.5229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.876572
Old  loss*** tensor(1552.2556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1360.6638, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8668458
Old  loss*** tensor(1084.8248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(940.3759, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87851596
Old  loss*** tensor(1049.1174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(921.6664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83332276
Old  loss*** tensor(2801.7891, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2334.7947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675896
Old  loss*** tensor(1582.5670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1373.0187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86124086
Old  loss*** tensor(2296.7227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1978.0314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8648665
Old  loss*** tensor(1977.4875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1710.2627, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8544936
Old  loss*** tensor(4076.4153, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3483.2708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87764883
Old  loss*** tensor(417.7852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(366.6687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8030112
Old  loss*** tensor(3637.5190, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2920.9685, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8440796
Old  loss*** tensor(2178.1396, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1838.5233, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78530407
Old  loss*** tensor(2845.6035, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2234.6641, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83946085
Old  loss*** tensor(2162.8628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1815.6387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83376545
Old  loss*** tensor(1449.5861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1208.6147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8187972
Old  loss*** tensor(3528.5090, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2889.1333, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8762277
Old  loss*** tensor(494.6763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(433.4491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716723
Old  loss*** tensor(1396.0364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1216.8862, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80760086
Old  loss*** tensor(3454.5640, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2789.9089, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8267441
Old  loss*** tensor(2480.5667, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2050.7937, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8608732
Old  loss*** tensor(2759.7366, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.7832, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8694496
Old  loss*** tensor(1245.7415, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1083.1094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415352
Old  loss*** tensor(2442.8618, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2055.7542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8240726
Old  loss*** tensor(2989.5918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2463.6406, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88779366
Old  loss*** tensor(746.8099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(663.0131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84535325
Old  loss*** tensor(1592.8899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1346.5547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8249309
Old  loss*** tensor(2087.1904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1721.7878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88737965
Old  loss*** tensor(535.8964, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(475.5435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774468
Old  loss*** tensor(926.5135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.9663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8045653
Old  loss*** tensor(3980.9338, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3202.9214, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8448663
Old  loss*** tensor(2799.8091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2365.4644, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573824
Old  loss*** tensor(1745.2628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1496.3577, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85857725
Old  loss*** tensor(2985.9163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2563.6399, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8071904
Old  loss*** tensor(4239.6772, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3422.2268, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8951901
Old  loss*** tensor(580.4677, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(519.6290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72083837
Old  loss*** tensor(5310.4248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3827.9580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87345326
Old  loss*** tensor(748.3335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(653.6343, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84831315
Old  loss*** tensor(1666.7706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1413.9435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8836986
Old  loss*** tensor(933.5488, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(824.9758, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.92948806
Old  loss*** tensor(914.7217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.2230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85724676
Old  loss*** tensor(1384.7664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1187.0864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821766
Old  loss*** tensor(1025.2458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.4479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8664057
Old  loss*** tensor(553.9728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(479.9652, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80329883
Old  loss*** tensor(2727.7483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2191.1970, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89418244
Old  loss*** tensor(920.6155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(823.1982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84928155
Old  loss*** tensor(1202.9661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.6569, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8897007
Old  loss*** tensor(1952.5728, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1737.2053, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89750427
Old  loss*** tensor(1269.1475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1139.0653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8925351
Old  loss*** tensor(930.1874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(830.2249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115968
Old  loss*** tensor(4672.9502, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3792.5515, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8427286
Old  loss*** tensor(1461.5006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1231.6484, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88839006
Old  loss*** tensor(581.9203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(516.9722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7320159
Old  loss*** tensor(5528.0088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4046.5903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8333441
Old  loss*** tensor(4167.1162, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3472.6416, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8393455
Old  loss*** tensor(3019.3757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2534.2996, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594411
Old  loss*** tensor(910.7133, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(782.7045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8198168
Old  loss*** tensor(3208.2693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2630.1931, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9167776
Old  loss*** tensor(598.7094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(548.8834, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89699197
Old  loss*** tensor(1181.5627, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1059.8523, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85465235
Old  loss*** tensor(1832.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1565.9147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670863
Old  loss*** tensor(409.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(354.6531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89530724
Old  loss*** tensor(1380.3479, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1235.8354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83068776
Old  loss*** tensor(2236.3555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1857.7131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77164155
Old  loss*** tensor(4740.6436, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3658.0776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8917577
Old  loss*** tensor(2015.8641, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1797.6625, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8272654
Old  loss*** tensor(2962.0051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2450.3643, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79547596
Old  loss*** tensor(3255.8289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2589.9336, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.828177
Old  loss*** tensor(2520.6841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2087.5725, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506478
Old  loss*** tensor(936.4916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(796.6245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.866858
Old  loss*** tensor(1438.7877, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1247.2246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81364936
Old  loss*** tensor(963.0873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(783.6154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7656748
Old  loss*** tensor(3948.5178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3023.2808, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84972584
Old  loss*** tensor(1660.7255, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1411.1614, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831663
Old  loss*** tensor(216.5071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(191.2118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8346877
Old  loss*** tensor(2048.4392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1709.8070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78325427
Old  loss*** tensor(4200.4482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3290.0190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9070951
Old  loss*** tensor(730.8303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(662.9326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77811414
Old  loss*** tensor(3481.3628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2708.8977, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87932605
Old  loss*** tensor(74.7503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(65.7299, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575493
Old  loss*** tensor(1336.7218, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1146.3048, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76343036
Old  loss*** tensor(3967.2246, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3028.6997, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8566936
Old  loss*** tensor(1841.7310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1577.7992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700198
Old  loss*** tensor(1742.9401, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1516.3923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86561924
Old  loss*** tensor(1622.1091, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1404.1289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9193118
Old  loss*** tensor(1678.2844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1542.8667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88272136
Old  loss*** tensor(1180.6393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1042.1755, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87326294
Old  loss*** tensor(1660.2671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1449.8497, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8834661
Old  loss*** tensor(227.3722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(200.8756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7767513
Old  loss*** tensor(4156.2769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3228.3933, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8390262
Old  loss*** tensor(3735.0344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3133.7917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839626
Old  loss*** tensor(2278.5466, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2014.1499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83751744
Old  loss*** tensor(2191.4917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1835.4125, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8128474
Old  loss*** tensor(1306.5763, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1062.0471, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83506846
Old  loss*** tensor(1315.8735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.8445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83166605
Old  loss*** tensor(2205.1157, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1833.9199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8890834
Old  loss*** tensor(1135.9418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.9470, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816319
Old  loss*** tensor(772.8012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(681.3262, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531718
Old  loss*** tensor(1880.4685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1604.3628, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88981855
Old  loss*** tensor(260.1587, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(231.4940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88952374
Old  loss*** tensor(801.0313, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(712.5364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641248
Old  loss*** tensor(656.2269, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(567.0619, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86877114
Old  loss*** tensor(1755.0461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1524.7334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8867644
Old  loss*** tensor(510.9526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(453.0945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8165176
Old  loss*** tensor(2512.0286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2051.1155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87711644
Old  loss*** tensor(1313.5680, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1152.1521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7322246
Old  loss*** tensor(5452.9482, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3992.7827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8137547
Old  loss*** tensor(3003.1768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2443.8491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8896332
Old  loss*** tensor(930.7716, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(828.0453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7859297
Old  loss*** tensor(4322.3892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3397.0940, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8627449
Old  loss*** tensor(1474.6155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1272.2170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76754636
Old  loss*** tensor(4103.8491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3149.8945, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900458
Old  loss*** tensor(807.8087, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(718.9867, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7922683
Old  loss*** tensor(4963.7515, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3932.6228, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.852913
Old  loss*** tensor(3091.6082, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2636.8728, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9101043
Old  loss*** tensor(647.5580, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(589.3453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7708783
Old  loss*** tensor(4163.4268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3209.4954, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79007185
Old  loss*** tensor(2866.7170, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2264.9124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8704338
Old  loss*** tensor(954.7122, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(831.0137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8522371
Old  loss*** tensor(1360.9698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1159.8690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8766522
Old  loss*** tensor(986.2263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(864.5775, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8018514
Old  loss*** tensor(3465.8840, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2779.1240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8503864
Old  loss*** tensor(1983.9446, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1687.1195, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8570572
Old  loss*** tensor(934.7393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(801.1250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8236917
Old  loss*** tensor(2289.3442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1885.7139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9142491
Old  loss*** tensor(719.7166, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(658.0003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86421543
Old  loss*** tensor(1240.0332, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1071.6559, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8124945
Old  loss*** tensor(5116.0508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4156.7632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781351
Old  loss*** tensor(1537.6334, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1350.2499, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88217616
Old  loss*** tensor(1791.8860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1580.7592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83503634
Old  loss*** tensor(2542.4822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2123.0649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764292
Old  loss*** tensor(1499.5404, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1314.2410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8010677
Old  loss*** tensor(3499.0239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2802.9551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86817306
Old  loss*** tensor(1695.7063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1472.1665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83091253
Old  loss*** tensor(1943.7053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1615.0491, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83666885
Old  loss*** tensor(2591.5325, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2168.2544, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8590545
Old  loss*** tensor(1336.2860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1147.9425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87194717
Old  loss*** tensor(1098.8141, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(958.1078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84497553
Old  loss*** tensor(2924.1660, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2470.8486, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.889783
Old  loss*** tensor(1224.3442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1089.4008, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7932486
Old  loss*** tensor(3359.5593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2664.9658, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509321
Old  loss*** tensor(2892.0188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2460.9116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86161834
Old  loss*** tensor(1343.9729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1157.9917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80507815
Old  loss*** tensor(2703.8604, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2176.8188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8512034
Old  loss*** tensor(682.2011, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(580.6919, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670926
Old  loss*** tensor(1493.3470, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1294.8702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8594525
Old  loss*** tensor(2659.9561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2286.1060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87518835
Old  loss*** tensor(3795.7385, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3321.9861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88568723
Old  loss*** tensor(527.7184, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(467.3935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89665246
Old  loss*** tensor(1086.8871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.5600, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7857742
Old  loss*** tensor(4325.5039, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3398.8691, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.896528
Old  loss*** tensor(552.0145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(494.8964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81320465
Old  loss*** tensor(3205.1348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2606.4304, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78159356
Old  loss*** tensor(4097.0352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3202.2163, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86490166
Old  loss*** tensor(1747.2740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1511.2202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8844352
Old  loss*** tensor(940.8414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(832.1133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83527714
Old  loss*** tensor(2055.5007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1716.9127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89007527
Old  loss*** tensor(463.7632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(412.7841, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82891965
Old  loss*** tensor(3483.4897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2887.5332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8360695
Old  loss*** tensor(1919.7135, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1605.0139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.821398
Old  loss*** tensor(4277.2559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3513.3296, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853718
Old  loss*** tensor(1108.3259, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(981.2805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8730265
Old  loss*** tensor(122.3346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(106.8013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8670082
Old  loss*** tensor(987.1511, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.8681, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88081586
Old  loss*** tensor(2975.5630, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2620.9231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8481928
Old  loss*** tensor(2319.0461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1966.9983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8487809
Old  loss*** tensor(2448.9744, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2078.6426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8160751
Old  loss*** tensor(4426.6455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3612.4751, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87370896
Old  loss*** tensor(421.9160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(368.6318, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87236893
Old  loss*** tensor(2444.8647, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2132.8240, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86846983
Old  loss*** tensor(1442.2954, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1252.5901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8423397
Old  loss*** tensor(3316.4099, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2793.5437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8611052
Old  loss*** tensor(895.4576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(771.0833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8972678
Old  loss*** tensor(1052.4689, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.3464, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284779
Old  loss*** tensor(4434.2754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3673.6992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86640465
Old  loss*** tensor(1320.6708, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1144.2354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87076765
Old  loss*** tensor(1149.6642, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1001.0904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76467
Old  loss*** tensor(4718.4819, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3608.0815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86384165
Old  loss*** tensor(751.6097, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(649.2717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86665845
Old  loss*** tensor(1877.3541, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1627.0248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8502911
Old  loss*** tensor(1735.6071, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1475.7712, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87824
Old  loss*** tensor(651.8031, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(572.4396, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8071117
Old  loss*** tensor(2824.6147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2279.7795, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7839893
Old  loss*** tensor(3056.4768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2396.2451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8635766
Old  loss*** tensor(1503.0029, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1297.9581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667965
Old  loss*** tensor(969.7080, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(840.5395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7950586
Old  loss*** tensor(3827.9846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3043.4722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88139254
Old  loss*** tensor(1903.4750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1677.7086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82805246
Old  loss*** tensor(3480.1726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2881.7654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80778223
Old  loss*** tensor(3108.4094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2510.9180, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79358613
Old  loss*** tensor(5105.7759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4051.8730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82901716
Old  loss*** tensor(2248.6147, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1864.1403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.69929266
Old  loss*** tensor(4072.5911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2847.9331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88190186
Old  loss*** tensor(1317.4730, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1161.8820, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83988714
Old  loss*** tensor(2329.5825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1956.5864, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8162252
Old  loss*** tensor(2074.6299, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1693.3651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8186492
Old  loss*** tensor(2775.9919, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2272.5635, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8171039
Old  loss*** tensor(3893.1719, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3181.1260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77932906
Old  loss*** tensor(3427.2498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2670.9553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88253963
Old  loss*** tensor(1152.1403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1016.8094, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86049414
Old  loss*** tensor(4010.8555, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3451.3176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8444613
Old  loss*** tensor(979.2704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.9560, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8419422
Old  loss*** tensor(2718.7852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2289.0598, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460386
Old  loss*** tensor(2168.0674, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1834.2687, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88667583
Old  loss*** tensor(484.6591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(429.7356, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398187
Old  loss*** tensor(2108.0850, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1770.4092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79058444
Old  loss*** tensor(4930.4160, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3897.9102, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88613665
Old  loss*** tensor(1197.1105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1060.8035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90885335
Old  loss*** tensor(410.2506, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(372.8576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90244925
Old  loss*** tensor(1342.6852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1211.7052, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85538733
Old  loss*** tensor(1966.7285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1682.3147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8860607
Old  loss*** tensor(628.3348, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(556.7427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76732314
Old  loss*** tensor(3893.8535, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2987.8440, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85129964
Old  loss*** tensor(2076.3411, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1767.5884, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.762452
Old  loss*** tensor(3720.5046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2836.7063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8811699
Old  loss*** tensor(947.5076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(834.9152, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8264431
Old  loss*** tensor(2464.4485, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.7264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88889444
Old  loss*** tensor(773.0498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(687.1597, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90354383
Old  loss*** tensor(841.1516, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(760.0173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8731164
Old  loss*** tensor(1405.0171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.7434, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8196081
Old  loss*** tensor(2661.2998, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2181.2229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87360525
Old  loss*** tensor(1294.3433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1130.7451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.867151
Old  loss*** tensor(1516.0315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1314.6283, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86519635
Old  loss*** tensor(2842.8330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.6086, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8783367
Old  loss*** tensor(519.0811, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(455.9280, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8459867
Old  loss*** tensor(1877.6143, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.4368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8655225
Old  loss*** tensor(2150.8577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1861.6157, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8352173
Old  loss*** tensor(3186.2158, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2661.1826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7552958
Old  loss*** tensor(4761.0601, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3596.0088, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8622737
Old  loss*** tensor(1197.2126, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1032.3250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88182074
Old  loss*** tensor(1684.5222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1485.4467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80007184
Old  loss*** tensor(3706.4146, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2965.3979, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87874246
Old  loss*** tensor(349.7696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(307.3574, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8146719
Old  loss*** tensor(1820.3344, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1482.9752, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88063955
Old  loss*** tensor(632.0885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(556.6422, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8415485
Old  loss*** tensor(1513.5748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1273.7466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85256124
Old  loss*** tensor(800.6874, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(682.6351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.70795465
Old  loss*** tensor(5025.0449, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3557.5039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8506164
Old  loss*** tensor(1178.1123, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1002.1216, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7774571
Old  loss*** tensor(2900.6055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2255.0964, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814376
Old  loss*** tensor(3918.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3454.2256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87976646
Old  loss*** tensor(763.2464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(671.4786, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8847495
Old  loss*** tensor(214.8315, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(190.0720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7853921
Old  loss*** tensor(3665.5615, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2878.9031, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88128763
Old  loss*** tensor(827.5892, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(729.3441, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81960547
Old  loss*** tensor(2003.3468, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1641.9540, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8827543
Old  loss*** tensor(384.0067, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(338.9835, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8341091
Old  loss*** tensor(2298.0974, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1916.8640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85589945
Old  loss*** tensor(1585.5394, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1357.0624, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8472363
Old  loss*** tensor(2569.9822, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2177.3821, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859339
Old  loss*** tensor(812.7704, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(720.0608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85850024
Old  loss*** tensor(1630.3622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1399.6664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879368
Old  loss*** tensor(1699.0972, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1508.6908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7690661
Old  loss*** tensor(4323.2124, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3324.8362, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8161577
Old  loss*** tensor(1797.1664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.7711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8293153
Old  loss*** tensor(1969.3339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1633.1987, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85910094
Old  loss*** tensor(2290.6829, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1967.9277, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8741212
Old  loss*** tensor(1901.7362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1662.3479, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7986007
Old  loss*** tensor(4382.2285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3499.6506, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800297
Old  loss*** tensor(1112.2195, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(978.7861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82417315
Old  loss*** tensor(4264.1514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3514.3992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.845619
Old  loss*** tensor(2674.0437, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2261.2222, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.869357
Old  loss*** tensor(2025.4816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1760.8666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.871981
Old  loss*** tensor(432.8377, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(377.4263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080137
Old  loss*** tensor(3026.8171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2445.7097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8634895
Old  loss*** tensor(1498.2474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1293.7209, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.848107
Old  loss*** tensor(2360.7317, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2002.1531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88631654
Old  loss*** tensor(134.5192, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(119.2266, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8713153
Old  loss*** tensor(1027.1921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(895.0082, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.839653
Old  loss*** tensor(311.4283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(261.4917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764092
Old  loss*** tensor(2304.6165, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2019.7870, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7554739
Old  loss*** tensor(3915.1970, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2957.8291, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8182537
Old  loss*** tensor(2317.8635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1896.6003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88450134
Old  loss*** tensor(1254.3553, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1109.4790, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85980177
Old  loss*** tensor(723.3107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(621.9038, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.854797
Old  loss*** tensor(4162.0913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3557.7432, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8722477
Old  loss*** tensor(1744.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1521.3682, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8183521
Old  loss*** tensor(3210.2556, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2627.1194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828206
Old  loss*** tensor(899.0825, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(793.7286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85209787
Old  loss*** tensor(3588.4790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3057.7354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8949722
Old  loss*** tensor(411.1465, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(367.9647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85804725
Old  loss*** tensor(1290.7500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1107.5245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774059
Old  loss*** tensor(1062.6693, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(932.3923, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8819722
Old  loss*** tensor(639.5735, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(564.0861, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8759469
Old  loss*** tensor(903.1226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(791.0875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8856014
Old  loss*** tensor(1017.2749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(900.9001, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88569796
Old  loss*** tensor(1164.0748, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1031.0187, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80593073
Old  loss*** tensor(4304.4883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3469.1194, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.862398
Old  loss*** tensor(1163.1213, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1003.0735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7895725
Old  loss*** tensor(5054.1738, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3990.6365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8812892
Old  loss*** tensor(466.1421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(410.8060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79908335
Old  loss*** tensor(4689.4722, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3747.2791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86295915
Old  loss*** tensor(850.6440, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(734.0710, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85845935
Old  loss*** tensor(2149.0027, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1844.8314, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8672935
Old  loss*** tensor(1684.0341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1460.5518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8798483
Old  loss*** tensor(847.1480, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(745.3618, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86139417
Old  loss*** tensor(2534.4758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2183.1826, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85427403
Old  loss*** tensor(2424.9001, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2071.5293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8324575
Old  loss*** tensor(690.7412, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(575.0127, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88095
Old  loss*** tensor(1395.9619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.7726, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8879615
Old  loss*** tensor(1270.5200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1128.1729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8804239
Old  loss*** tensor(3542.8638, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3119.2219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8824862
Old  loss*** tensor(487.3767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(430.1032, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8779286
Old  loss*** tensor(852.3079, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(748.2655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87597096
Old  loss*** tensor(2958.1104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2591.2188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90198606
Old  loss*** tensor(1162.7833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1048.8143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8191409
Old  loss*** tensor(2449.2568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2006.2865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8349625
Old  loss*** tensor(3844.9644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3210.4011, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8111762
Old  loss*** tensor(2836.9131, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2301.2363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8524023
Old  loss*** tensor(1794.2539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1529.4263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.887489
Old  loss*** tensor(1153.3105, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1023.5505, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8853662
Old  loss*** tensor(118.5429, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(104.9539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7662707
Old  loss*** tensor(5428.8496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4159.9683, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642346
Old  loss*** tensor(706.9758, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(610.9929, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8397644
Old  loss*** tensor(3455.9709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2902.2014, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8708526
Old  loss*** tensor(978.9727, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(852.5410, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7876005
Old  loss*** tensor(2704.4619, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2130.0356, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87438333
Old  loss*** tensor(1244.7455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1088.3846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929125
Old  loss*** tensor(1271.6356, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1135.4594, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8447076
Old  loss*** tensor(1829.9938, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1545.8097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78508776
Old  loss*** tensor(3485.4849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2736.4116, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8531493
Old  loss*** tensor(1542.9125, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1316.3347, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88688153
Old  loss*** tensor(379.3448, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(336.4339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8450746
Old  loss*** tensor(2070.9155, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1750.0781, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8801013
Old  loss*** tensor(1095.8475, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(964.4568, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853912
Old  loss*** tensor(1860.4222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1588.6368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8624903
Old  loss*** tensor(2423.1418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2089.9363, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8791226
Old  loss*** tensor(954.7927, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(839.3799, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7413494
Old  loss*** tensor(4755.0205, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3525.1316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8785825
Old  loss*** tensor(915.3085, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(804.1740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79442483
Old  loss*** tensor(3463.7273, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2751.6709, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8061228
Old  loss*** tensor(2570.5056, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2072.1431, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87806374
Old  loss*** tensor(2153.6648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1891.0549, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823636
Old  loss*** tensor(1526.7828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1347.1776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7333287
Old  loss*** tensor(4477.3389, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3283.3611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8828933
Old  loss*** tensor(953.7821, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(842.0878, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82055926
Old  loss*** tensor(2300.4277, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1887.6373, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84111404
Old  loss*** tensor(1965.2921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1653.0348, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9013136
Old  loss*** tensor(483.3731, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(435.6707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87205386
Old  loss*** tensor(615.5178, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(536.7647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8353778
Old  loss*** tensor(1444.0427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1206.3213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8774613
Old  loss*** tensor(1189.8290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1044.0289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8747008
Old  loss*** tensor(1402.2340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1226.5352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.854125
Old  loss*** tensor(2014.5051, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1720.6393, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88481015
Old  loss*** tensor(485.5096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(429.5838, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8937937
Old  loss*** tensor(686.0613, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(613.1973, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127053
Old  loss*** tensor(4311.9253, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3504.3245, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82121444
Old  loss*** tensor(2553.5034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2096.9739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8341537
Old  loss*** tensor(3692.2561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3079.9092, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78786325
Old  loss*** tensor(4264.3418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3359.7183, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84500295
Old  loss*** tensor(4164.6030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3519.1018, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7937254
Old  loss*** tensor(3245.1658, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2575.7705, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7764782
Old  loss*** tensor(5239.4629, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4068.3286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81322765
Old  loss*** tensor(3552.8384, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2889.2664, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89735055
Old  loss*** tensor(1720.8542, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1544.2095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8814471
Old  loss*** tensor(1544.8191, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1361.6763, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82645565
Old  loss*** tensor(3037.6370, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2510.4722, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8978051
Old  loss*** tensor(1528.5245, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1372.3171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8145671
Old  loss*** tensor(2486.2063, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2025.1819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9002633
Old  loss*** tensor(762.4425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.3990, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8780948
Old  loss*** tensor(1050.0968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(922.0845, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8543419
Old  loss*** tensor(2383.6289, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2036.4341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8432517
Old  loss*** tensor(3693.1433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3114.2495, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84634537
Old  loss*** tensor(697.2231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(590.0916, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8542677
Old  loss*** tensor(1554.9424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1328.3370, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7757062
Old  loss*** tensor(2542.3567, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1972.1218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.827765
Old  loss*** tensor(2842.4280, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2352.8623, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8649441
Old  loss*** tensor(836.5221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(723.5449, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8949078
Old  loss*** tensor(704.8378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(630.7648, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8464848
Old  loss*** tensor(2004.8958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1697.1138, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85575104
Old  loss*** tensor(1862.6910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1593.9998, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88994396
Old  loss*** tensor(175.6663, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(156.3332, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85536575
Old  loss*** tensor(1693.8757, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1448.8833, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83832604
Old  loss*** tensor(1724.6930, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1445.8551, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8758191
Old  loss*** tensor(1752.4559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1534.8344, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8125204
Old  loss*** tensor(3052.5583, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2480.2659, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8650341
Old  loss*** tensor(1163.4899, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1006.4584, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873061
Old  loss*** tensor(1062.0885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.3976, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076384
Old  loss*** tensor(3304.0835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2668.5046, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75465846
Old  loss*** tensor(4179.2441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3153.9019, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8906647
Old  loss*** tensor(279.9937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(249.3805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452115
Old  loss*** tensor(4045.6851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3419.4595, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7926113
Old  loss*** tensor(3833.9500, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3038.8320, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8483354
Old  loss*** tensor(1519.8672, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1289.3571, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8492838
Old  loss*** tensor(2123.6855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1803.6118, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7962376
Old  loss*** tensor(2128.1418, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1694.5065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84216744
Old  loss*** tensor(1823.9386, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1536.0616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84188396
Old  loss*** tensor(3360.4570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2829.1147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84549475
Old  loss*** tensor(2491.9912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2106.9656, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86656857
Old  loss*** tensor(1042.9958, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(903.8274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80539143
Old  loss*** tensor(3344.9883, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2694.0249, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89803374
Old  loss*** tensor(920.1473, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.3234, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8093353
Old  loss*** tensor(2288.6487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1852.2842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901073
Old  loss*** tensor(1421.4902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1265.2788, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8560573
Old  loss*** tensor(1136.4221, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.8424, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75285935
Old  loss*** tensor(4064.3433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3059.8789, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638451
Old  loss*** tensor(2003.6520, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1730.8450, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82458997
Old  loss*** tensor(2241.2817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1848.1384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8304195
Old  loss*** tensor(1425.1671, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1183.4866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8513039
Old  loss*** tensor(4299.2759, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3659.9902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8820189
Old  loss*** tensor(590.0212, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(520.4099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81938136
Old  loss*** tensor(3458.6038, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2833.9155, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8452062
Old  loss*** tensor(1582.9030, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1337.8794, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8240825
Old  loss*** tensor(1609.3330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1326.2231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8901961
Old  loss*** tensor(1123.5566, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1000.1857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732953
Old  loss*** tensor(782.5474, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(683.3950, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82262874
Old  loss*** tensor(1424.4930, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1171.8289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85908544
Old  loss*** tensor(2238.8215, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1923.3390, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80676144
Old  loss*** tensor(1430.7827, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1154.3003, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85973966
Old  loss*** tensor(2559.8921, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2200.8408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87612844
Old  loss*** tensor(515.8944, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(451.9898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77134883
Old  loss*** tensor(4010.8364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3093.7539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8839151
Old  loss*** tensor(311.6012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(275.4290, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.870869
Old  loss*** tensor(895.3787, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(779.7576, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85365546
Old  loss*** tensor(1935.3203, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1652.0968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8757745
Old  loss*** tensor(2387.3391, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2090.7708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.901855
Old  loss*** tensor(750.1774, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(676.5512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86941665
Old  loss*** tensor(1307.3455, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1136.6279, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9076161
Old  loss*** tensor(1280.0200, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1161.7667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8065196
Old  loss*** tensor(4656.7812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3755.7854, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83841205
Old  loss*** tensor(1276.9207, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1070.5857, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8263339
Old  loss*** tensor(1882.9655, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1555.9581, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81380093
Old  loss*** tensor(2815.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2291.0066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84127903
Old  loss*** tensor(4263.4966, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3586.7903, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88284755
Old  loss*** tensor(577.7593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(510.0734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929846
Old  loss*** tensor(1742.1405, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1555.7047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8663448
Old  loss*** tensor(743.9498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(644.5170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89762425
Old  loss*** tensor(477.1833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(428.3313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82718354
Old  loss*** tensor(2463.7915, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.0078, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88433105
Old  loss*** tensor(79.9682, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(70.7184, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85318804
Old  loss*** tensor(1202.2010, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1025.7036, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.76727617
Old  loss*** tensor(2555.1726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1960.5231, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86591756
Old  loss*** tensor(1703.8263, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1475.3732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8488198
Old  loss*** tensor(2623.7976, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2227.1313, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86559093
Old  loss*** tensor(1008.6077, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(873.0417, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8755697
Old  loss*** tensor(1226.4945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1073.8815, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8479973
Old  loss*** tensor(2853.8701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2420.0742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87811995
Old  loss*** tensor(3889.0903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3415.0879, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81827426
Old  loss*** tensor(3680.4968, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3011.6558, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647196
Old  loss*** tensor(1639.0690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1417.3351, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87631136
Old  loss*** tensor(1559.7100, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1366.7915, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8093
Old  loss*** tensor(2644.0217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2139.8069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.860631
Old  loss*** tensor(2301.6904, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1980.9061, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85050976
Old  loss*** tensor(1535.9636, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1306.3521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82343054
Old  loss*** tensor(3076.9414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2533.6475, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9025936
Old  loss*** tensor(1044.0916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(942.3904, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8187713
Old  loss*** tensor(4119.3975, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3372.8445, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9055073
Old  loss*** tensor(352.9545, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(319.6029, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8709181
Old  loss*** tensor(2057.4995, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1791.9136, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81664485
Old  loss*** tensor(3649.7017, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2980.5100, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8103455
Old  loss*** tensor(3163.3635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2563.4172, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127583
Old  loss*** tensor(3519.5706, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2860.5603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78945875
Old  loss*** tensor(3308.3911, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2611.8384, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78158045
Old  loss*** tensor(3047.3679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2381.7632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88180363
Old  loss*** tensor(687.4841, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(606.2260, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79459643
Old  loss*** tensor(4299.0977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3416.0476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7459264
Old  loss*** tensor(4644.2544, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3464.2720, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8813852
Old  loss*** tensor(601.5007, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(530.1538, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8878957
Old  loss*** tensor(915.7290, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(813.0718, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79328537
Old  loss*** tensor(2790.0044, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2213.2698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8851106
Old  loss*** tensor(700.9053, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(620.3787, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8773142
Old  loss*** tensor(3054.3208, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2679.5991, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8645251
Old  loss*** tensor(123.2362, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(106.5407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8756378
Old  loss*** tensor(3050.9768, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2671.5508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8705507
Old  loss*** tensor(1417.8918, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1234.3467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89144033
Old  loss*** tensor(1186.5223, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1057.7139, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8716265
Old  loss*** tensor(1441.2151, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1256.2013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.835631
Old  loss*** tensor(1285.2072, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1073.9590, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8626093
Old  loss*** tensor(3875.5750, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3343.1072, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80683553
Old  loss*** tensor(3584.6648, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2892.2349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7687739
Old  loss*** tensor(5013.9937, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3854.6274, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87510705
Old  loss*** tensor(1024.0034, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(896.1126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665128
Old  loss*** tensor(709.5358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(614.8218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8359735
Old  loss*** tensor(4413.9756, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3689.9666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8729773
Old  loss*** tensor(1035.5890, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(904.0457, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815886
Old  loss*** tensor(3021.3054, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2465.0408, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86959404
Old  loss*** tensor(2367.2163, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2058.5171, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8749287
Old  loss*** tensor(1015.1416, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(888.1765, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8150143
Old  loss*** tensor(4594.5898, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3744.6565, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7984235
Old  loss*** tensor(1713.6705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1368.2349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8809502
Old  loss*** tensor(775.5612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(683.2308, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8732343
Old  loss*** tensor(1194.9174, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1043.4427, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615656
Old  loss*** tensor(1138.5530, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(980.9380, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8620924
Old  loss*** tensor(1497.9441, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1291.3662, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744667
Old  loss*** tensor(420.9204, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(368.0809, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7948828
Old  loss*** tensor(4437.5879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3527.3621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9022859
Old  loss*** tensor(244.9352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(221.0015, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8660078
Old  loss*** tensor(1425.2310, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1234.2611, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85332257
Old  loss*** tensor(2224.0696, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1897.8488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8915025
Old  loss*** tensor(242.9692, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(216.6076, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8288555
Old  loss*** tensor(2583.2644, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2141.1528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8927317
Old  loss*** tensor(847.3945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(756.4960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8219676
Old  loss*** tensor(2284.1421, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1877.4908, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8127167
Old  loss*** tensor(3944.0312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3205.3801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83439326
Old  loss*** tensor(2453.2559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2046.9801, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8667003
Old  loss*** tensor(1787.5444, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1549.2653, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699702
Old  loss*** tensor(924.7806, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(804.5316, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80027324
Old  loss*** tensor(1978.2668, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1583.1541, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8115365
Old  loss*** tensor(3663.6406, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2973.1780, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80389166
Old  loss*** tensor(3928.9238, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3158.4292, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8000618
Old  loss*** tensor(2777.4753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2222.1521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87125254
Old  loss*** tensor(1884.5148, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1641.8883, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8284732
Old  loss*** tensor(3307.2048, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2739.9307, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7906581
Old  loss*** tensor(4417.9854, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3493.1160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88212925
Old  loss*** tensor(1393.5670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1229.3063, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8964967
Old  loss*** tensor(508.7607, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(456.1023, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8189943
Old  loss*** tensor(1761.6951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1442.8182, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88217384
Old  loss*** tensor(728.4540, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(642.6230, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87788427
Old  loss*** tensor(997.3979, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(875.6000, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297585
Old  loss*** tensor(2163.7800, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1795.4149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82003236
Old  loss*** tensor(2189.3447, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1795.3335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7304879
Old  loss*** tensor(4375.8438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3196.5007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8180363
Old  loss*** tensor(3154.6912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2580.6519, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8140236
Old  loss*** tensor(4544.8003, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3699.5747, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86368334
Old  loss*** tensor(4065.9741, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3511.7141, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88206583
Old  loss*** tensor(2463.6194, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2173.0745, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8781128
Old  loss*** tensor(461.2327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(405.0143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8476572
Old  loss*** tensor(4197.8818, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3558.3647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83720756
Old  loss*** tensor(1510.2233, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1264.3704, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8076638
Old  loss*** tensor(1994.4171, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1610.8185, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85372615
Old  loss*** tensor(1217.0132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1038.9960, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.819415
Old  loss*** tensor(4281.5312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3508.3508, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89158094
Old  loss*** tensor(410.8852, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(366.3374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87920946
Old  loss*** tensor(1519.6776, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.1150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75887257
Old  loss*** tensor(3360.4634, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2550.1636, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8372946
Old  loss*** tensor(1725.8308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1445.0288, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88726556
Old  loss*** tensor(1151.5817, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1021.7587, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86069405
Old  loss*** tensor(1998.1949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1719.8345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7778327
Old  loss*** tensor(2529.4961, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1967.5248, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609595
Old  loss*** tensor(618.9777, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(532.9147, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78080475
Old  loss*** tensor(2572.6917, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2008.7699, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7903075
Old  loss*** tensor(3711.3445, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2933.1035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88838917
Old  loss*** tensor(1161.6593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1032.0055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7800133
Old  loss*** tensor(4810.2637, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3752.0698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87121665
Old  loss*** tensor(457.3464, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(398.4478, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8697815
Old  loss*** tensor(692.5608, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.3766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8865694
Old  loss*** tensor(1097.0798, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(972.6374, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7697965
Old  loss*** tensor(4061.6536, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3126.6467, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9034966
Old  loss*** tensor(899.7305, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(812.9035, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7518196
Old  loss*** tensor(4491.0894, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3376.4890, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8647623
Old  loss*** tensor(1214.0984, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1049.9065, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8876758
Old  loss*** tensor(678.6591, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(602.4293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87531424
Old  loss*** tensor(1026.3268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(898.3585, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8929041
Old  loss*** tensor(1128.7769, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1007.8895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8675835
Old  loss*** tensor(1648.5055, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1430.2162, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8528261
Old  loss*** tensor(2283.3062, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1947.2632, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84702164
Old  loss*** tensor(1830.9592, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1550.8621, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.846419
Old  loss*** tensor(3148.1265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2664.6340, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87374294
Old  loss*** tensor(720.5952, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(629.6150, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8607787
Old  loss*** tensor(1389.7573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1196.2734, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85161114
Old  loss*** tensor(1100.8726, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(937.5153, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8334715
Old  loss*** tensor(2130.8909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1776.0367, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8291129
Old  loss*** tensor(2177.9268, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1805.7472, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78374195
Old  loss*** tensor(2771.1104, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2171.8354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7840355
Old  loss*** tensor(2489.1870, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1951.6110, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7980119
Old  loss*** tensor(2304.9443, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1839.3730, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87152505
Old  loss*** tensor(1107.2496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(964.9958, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8745761
Old  loss*** tensor(743.7346, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(650.4525, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89641505
Old  loss*** tensor(721.9413, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(647.1591, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84814113
Old  loss*** tensor(2018.2969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1711.8007, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86111695
Old  loss*** tensor(1775.5483, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1528.9547, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89738214
Old  loss*** tensor(594.3753, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(533.3818, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8509645
Old  loss*** tensor(1968.4675, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1675.0959, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77583826
Old  loss*** tensor(4896.0508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3798.5435, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87479633
Old  loss*** tensor(955.4749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(835.8459, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.863879
Old  loss*** tensor(1376.4597, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1189.0947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8816147
Old  loss*** tensor(906.3132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(799.0190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8558172
Old  loss*** tensor(1359.7749, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1163.7188, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85758424
Old  loss*** tensor(1425.8982, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1222.8278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7967406
Old  loss*** tensor(2558.8665, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2038.7528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8932422
Old  loss*** tensor(801.7902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(716.1928, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80178046
Old  loss*** tensor(2873.9705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2304.2935, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84416527
Old  loss*** tensor(3061.5281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2584.4355, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8873707
Old  loss*** tensor(242.5691, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(215.2487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88152903
Old  loss*** tensor(115.3577, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(101.6912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823252
Old  loss*** tensor(341.8098, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(301.5874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89314044
Old  loss*** tensor(742.0393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(662.7453, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8421212
Old  loss*** tensor(1904.2458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1603.6057, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8015537
Old  loss*** tensor(4525.9102, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3627.7603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8682157
Old  loss*** tensor(1506.6909, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1308.1327, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8058294
Old  loss*** tensor(2747.6851, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2214.1655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.866667
Old  loss*** tensor(2064.0857, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1788.8749, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75863767
Old  loss*** tensor(3816.6714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2895.4707, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84900105
Old  loss*** tensor(3600.2568, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3056.6218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86380357
Old  loss*** tensor(2087.9336, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1803.5645, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8712977
Old  loss*** tensor(1942.9292, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1692.8698, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8651816
Old  loss*** tensor(919.7723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(795.7701, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738154
Old  loss*** tensor(2357.2043, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2059.7615, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8642232
Old  loss*** tensor(2659.5281, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2298.4258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208534
Old  loss*** tensor(2836.6287, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2328.4563, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88825905
Old  loss*** tensor(556.8926, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(494.6649, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86117256
Old  loss*** tensor(1417.4816, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1220.6962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8308166
Old  loss*** tensor(2985.0364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2480.0178, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86238885
Old  loss*** tensor(2991.1567, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2579.5403, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78452206
Old  loss*** tensor(4133.8477, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3243.0947, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8242384
Old  loss*** tensor(2373.0913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1955.9930, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8080671
Old  loss*** tensor(2865.2656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2315.3269, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7863953
Old  loss*** tensor(4539.0659, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3569.5002, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86746496
Old  loss*** tensor(1989.7507, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1726.0391, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8257055
Old  loss*** tensor(3600.5881, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2973.0256, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82870007
Old  loss*** tensor(2881.6177, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2387.9968, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.853731
Old  loss*** tensor(1535.0602, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1310.5284, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9102342
Old  loss*** tensor(838.5643, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(763.2899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8101017
Old  loss*** tensor(1869.6096, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1514.5739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83079255
Old  loss*** tensor(3977.5383, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3304.5093, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8339232
Old  loss*** tensor(3015.3423, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2514.5640, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86270124
Old  loss*** tensor(1566.1946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1351.1580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8665346
Old  loss*** tensor(1593.9725, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1381.2323, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88549566
Old  loss*** tensor(139.4767, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(123.5060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86822724
Old  loss*** tensor(1629.9860, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1415.1982, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85431194
Old  loss*** tensor(932.8969, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(796.9850, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8048402
Old  loss*** tensor(3898.5427, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3137.7039, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80839616
Old  loss*** tensor(3504.2231, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2832.8005, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8410233
Old  loss*** tensor(2404.4824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2022.2258, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86693233
Old  loss*** tensor(2005.1582, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1738.3364, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89075303
Old  loss*** tensor(523.7910, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(466.5684, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.850969
Old  loss*** tensor(3542.9705, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3014.9580, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8208357
Old  loss*** tensor(3006.9438, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2468.2068, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87174994
Old  loss*** tensor(634.6887, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(553.2898, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.829973
Old  loss*** tensor(1548.4656, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1285.1846, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85272235
Old  loss*** tensor(1621.2145, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1382.4458, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88234067
Old  loss*** tensor(98.1962, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(86.6425, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86862904
Old  loss*** tensor(1026.1617, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(891.3539, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78912145
Old  loss*** tensor(4550.0942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3590.5769, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.882009
Old  loss*** tensor(617.5469, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(544.6819, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8656465
Old  loss*** tensor(1109.7094, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(960.6160, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84622645
Old  loss*** tensor(1943.4778, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1644.6223, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8580226
Old  loss*** tensor(1267.6869, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1087.7040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89772433
Old  loss*** tensor(875.9213, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.3358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8205266
Old  loss*** tensor(3347.2622, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2746.5176, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88153756
Old  loss*** tensor(522.3873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(460.5041, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8755809
Old  loss*** tensor(924.5875, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(809.5512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8340967
Old  loss*** tensor(3920.9341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3270.4382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81757545
Old  loss*** tensor(2510.3484, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2052.3992, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87169623
Old  loss*** tensor(4218.6387, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3677.3713, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75461674
Old  loss*** tensor(3560.5461, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2686.8477, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8700601
Old  loss*** tensor(1119.9471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(974.4213, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8074731
Old  loss*** tensor(2913.3855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2352.4805, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8200957
Old  loss*** tensor(2169.3508, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1779.0753, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8501714
Old  loss*** tensor(2281.5740, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1939.7289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84888685
Old  loss*** tensor(1867.6392, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1585.4143, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9016314
Old  loss*** tensor(1315.1868, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1185.8137, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8764199
Old  loss*** tensor(2087.4006, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1829.4395, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7998716
Old  loss*** tensor(3148.8574, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2518.6816, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88767314
Old  loss*** tensor(1554.3274, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1379.7346, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8735217
Old  loss*** tensor(911.8635, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(796.5326, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8079427
Old  loss*** tensor(4235.7988, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3422.2827, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85291684
Old  loss*** tensor(1104.1951, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(941.7866, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803607
Old  loss*** tensor(607.2227, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(534.5750, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8466686
Old  loss*** tensor(1339.9196, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1134.4678, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8744446
Old  loss*** tensor(1080.1293, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.5132, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86462015
Old  loss*** tensor(722.6365, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(624.8060, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75309366
Old  loss*** tensor(4245.0454, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3196.9167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77494633
Old  loss*** tensor(3503.1152, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2714.7263, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79591095
Old  loss*** tensor(3918.3235, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3118.6365, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87740993
Old  loss*** tensor(1454.5322, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1276.2211, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81241626
Old  loss*** tensor(4172.0303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3389.4253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8264286
Old  loss*** tensor(2997.4802, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2477.2034, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.697896
Old  loss*** tensor(4564.1533, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3185.3044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83478105
Old  loss*** tensor(3895.7578, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3252.1047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8375472
Old  loss*** tensor(2608.5339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2184.7703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.825107
Old  loss*** tensor(3010.6345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2484.0955, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8834039
Old  loss*** tensor(739.9340, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(653.6606, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87777984
Old  loss*** tensor(376.1236, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(330.1537, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8641429
Old  loss*** tensor(1971.6935, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1703.8250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.815972
Old  loss*** tensor(1554.2047, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1268.1875, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89278734
Old  loss*** tensor(165.3573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(147.6289, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8738077
Old  loss*** tensor(1410.9846, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1232.9293, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86441505
Old  loss*** tensor(2046.6897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1769.1893, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.799885
Old  loss*** tensor(4597.3311, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3677.3359, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8237249
Old  loss*** tensor(2671.1257, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2200.2729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91329145
Old  loss*** tensor(732.0528, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(668.5776, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8322575
Old  loss*** tensor(4163.8076, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3465.3601, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8969985
Old  loss*** tensor(676.1581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(606.5128, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84333706
Old  loss*** tensor(3625.4670, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3057.4907, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78745973
Old  loss*** tensor(3484.9150, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2744.2302, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83869505
Old  loss*** tensor(2061.5679, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1729.0267, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8884279
Old  loss*** tensor(326.0879, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(289.7056, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8269694
Old  loss*** tensor(4831.2598, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3995.3040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88136613
Old  loss*** tensor(778.4360, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.0871, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8823145
Old  loss*** tensor(964.4791, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(850.9739, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8638381
Old  loss*** tensor(866.0424, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(748.1204, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8372544
Old  loss*** tensor(3231.4573, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2705.5518, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7591332
Old  loss*** tensor(4427.0400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3360.7131, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8791953
Old  loss*** tensor(1667.6285, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1466.1711, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89159054
Old  loss*** tensor(1140.8593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.1793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8615583
Old  loss*** tensor(2246.0364, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1935.0913, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8859977
Old  loss*** tensor(2052.2849, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1818.3197, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83961225
Old  loss*** tensor(3352.7495, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2815.0095, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8536217
Old  loss*** tensor(1962.6888, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1675.3938, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.842965
Old  loss*** tensor(1533.8154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1292.9528, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88134426
Old  loss*** tensor(1009.8557, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.0305, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8919649
Old  loss*** tensor(519.2487, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(463.1516, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90398824
Old  loss*** tensor(1138.5754, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1029.2588, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85199755
Old  loss*** tensor(2252.0164, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1918.7124, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8632457
Old  loss*** tensor(1968.4990, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1699.2983, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8263994
Old  loss*** tensor(4155.2837, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3433.9238, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89564013
Old  loss*** tensor(1414.0350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1266.4666, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88511616
Old  loss*** tensor(357.9943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(316.8665, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87866735
Old  loss*** tensor(1191.3977, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1046.8423, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7716094
Old  loss*** tensor(4503.9248, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3475.2708, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.855021
Old  loss*** tensor(1731.6132, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1480.5657, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9005991
Old  loss*** tensor(690.3519, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(621.7303, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83444184
Old  loss*** tensor(2912.0327, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2429.9219, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.78320813
Old  loss*** tensor(3018.1929, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2363.8733, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9073836
Old  loss*** tensor(1453.1698, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1318.5825, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384024
Old  loss*** tensor(2549.2241, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2137.2756, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8893477
Old  loss*** tensor(924.1862, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(821.9229, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89223236
Old  loss*** tensor(1207.8179, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1077.6542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8450337
Old  loss*** tensor(1368.9330, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1156.7946, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8300024
Old  loss*** tensor(1954.6128, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1622.3334, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8493379
Old  loss*** tensor(2553.4946, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2168.7798, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8490191
Old  loss*** tensor(2729.6101, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2317.4912, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8920456
Old  loss*** tensor(647.6790, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(577.7592, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87564516
Old  loss*** tensor(1473.0154, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1289.8387, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88580513
Old  loss*** tensor(1290.8861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1143.4735, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8653343
Old  loss*** tensor(1952.0690, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1689.1921, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7568159
Old  loss*** tensor(4353.0688, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3294.4717, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83284205
Old  loss*** tensor(2028.1561, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1689.1337, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88046026
Old  loss*** tensor(145.9633, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(128.5149, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8572414
Old  loss*** tensor(1539.8312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1320.0071, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89611876
Old  loss*** tensor(911.7723, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(817.0562, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7973242
Old  loss*** tensor(2595.5491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2069.4941, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8382819
Old  loss*** tensor(938.7256, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(786.9167, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86838317
Old  loss*** tensor(864.0588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(750.3341, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7907684
Old  loss*** tensor(3639.0369, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2877.6353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8597244
Old  loss*** tensor(1211.7522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1041.7729, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8802159
Old  loss*** tensor(2542.0745, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2237.5742, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85579664
Old  loss*** tensor(2227.9229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1906.6489, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9013829
Old  loss*** tensor(1047.9341, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(944.5899, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.895623
Old  loss*** tensor(397.7531, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(356.2368, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86907136
Old  loss*** tensor(1766.4847, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1535.2013, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7707932
Old  loss*** tensor(3540.8284, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2729.2463, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9137648
Old  loss*** tensor(1315.3352, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1201.9070, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.828153
Old  loss*** tensor(2638.0298, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2184.6924, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.74733806
Old  loss*** tensor(3198.8467, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2390.6199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8575287
Old  loss*** tensor(1932.2300, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1656.9426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77410203
Old  loss*** tensor(5088.6108, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3939.1040, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495935
Old  loss*** tensor(1188.3621, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1009.6247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88513815
Old  loss*** tensor(2543.1609, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2251.0488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8416812
Old  loss*** tensor(1741.4371, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1465.7349, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8464592
Old  loss*** tensor(1901.4873, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1609.5315, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84773207
Old  loss*** tensor(265.9576, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(225.4608, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.72165996
Old  loss*** tensor(4340.7266, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3132.5286, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8146062
Old  loss*** tensor(3070.4026, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2501.1689, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8579184
Old  loss*** tensor(1013.5414, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(869.5358, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8573006
Old  loss*** tensor(3000.0457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2571.9409, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8800733
Old  loss*** tensor(1587.9265, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1397.4917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7686428
Old  loss*** tensor(2269.6729, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1744.5676, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7524674
Old  loss*** tensor(4779.5303, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3596.4407, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8238988
Old  loss*** tensor(3802.4517, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3132.8354, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8485378
Old  loss*** tensor(4386.4824, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3722.0962, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8043236
Old  loss*** tensor(4396.6226, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3536.3074, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88003314
Old  loss*** tensor(1135.5505, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(999.3221, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8261587
Old  loss*** tensor(3000.5012, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2478.8901, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89267963
Old  loss*** tensor(808.9498, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(722.1331, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8808627
Old  loss*** tensor(1517.1345, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1336.3872, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8960053
Old  loss*** tensor(1865.6685, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1671.6488, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8803147
Old  loss*** tensor(1055.3110, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(929.0058, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8154783
Old  loss*** tensor(3065.6116, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2499.9397, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8500609
Old  loss*** tensor(1291.7949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1098.1044, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7830111
Old  loss*** tensor(5000.8491, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3915.7202, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87725043
Old  loss*** tensor(942.5903, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(826.8877, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88156545
Old  loss*** tensor(1487.2378, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1311.0974, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874674
Old  loss*** tensor(156.9945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(137.3190, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8829709
Old  loss*** tensor(1673.0393, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1477.2451, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.874238
Old  loss*** tensor(1100.2570, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(961.8865, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83043826
Old  loss*** tensor(2243.5229, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1863.1073, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7679826
Old  loss*** tensor(4707.9912, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3615.6553, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8539983
Old  loss*** tensor(3033.4714, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2590.5793, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84613824
Old  loss*** tensor(1762.4861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1491.3069, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88121945
Old  loss*** tensor(496.4992, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(437.5247, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8073831
Old  loss*** tensor(3510.1614, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2834.0452, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82159567
Old  loss*** tensor(4418.9697, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3630.6064, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81259215
Old  loss*** tensor(4072.0432, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3308.9104, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8250996
Old  loss*** tensor(2842.6333, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2345.4556, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8691505
Old  loss*** tensor(480.7742, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(417.8651, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.79688454
Old  loss*** tensor(4054.3350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3230.8369, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9043858
Old  loss*** tensor(984.2872, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(890.1754, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88048106
Old  loss*** tensor(762.9471, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(671.7605, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89063144
Old  loss*** tensor(1161.3308, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1034.3177, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88640594
Old  loss*** tensor(1172.8835, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1039.6510, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9071913
Old  loss*** tensor(635.8773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(576.8623, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8508951
Old  loss*** tensor(1146.1743, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(975.2741, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8304761
Old  loss*** tensor(2513.1433, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2087.1055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.75337464
Old  loss*** tensor(5054.6543, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3808.0483, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8297832
Old  loss*** tensor(3022.0569, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2507.6521, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8520255
Old  loss*** tensor(3994.3718, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3403.3066, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89156693
Old  loss*** tensor(787.0834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(701.7375, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8862165
Old  loss*** tensor(1189.6940, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1054.3264, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84014434
Old  loss*** tensor(4376.7593, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3677.1096, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8760523
Old  loss*** tensor(1409.1353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1234.4762, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88178897
Old  loss*** tensor(1841.5513, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1623.8596, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82579666
Old  loss*** tensor(3422.6504, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2826.4133, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8821244
Old  loss*** tensor(1558.2499, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1374.5703, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.90253603
Old  loss*** tensor(522.3871, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(471.4732, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8710784
Old  loss*** tensor(1547.8579, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1348.3055, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85012543
Old  loss*** tensor(2498.4509, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2123.9966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8706299
Old  loss*** tensor(681.5367, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(593.3663, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8815789
Old  loss*** tensor(509.3422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(449.0253, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81299376
Old  loss*** tensor(2868.7539, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2332.2791, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88783354
Old  loss*** tensor(828.1830, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(735.2887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88939595
Old  loss*** tensor(934.6661, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(831.2882, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8398635
Old  loss*** tensor(1333.4943, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1119.9531, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.88201535
Old  loss*** tensor(374.4139, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(330.2388, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87263215
Old  loss*** tensor(1321.3400, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1153.0437, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85760796
Old  loss*** tensor(2158.7913, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1851.3966, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82469
Old  loss*** tensor(2959.3149, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2440.5173, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85759896
Old  loss*** tensor(1546.3201, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1326.1224, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8214373
Old  loss*** tensor(2304.0222, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1892.6097, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8301544
Old  loss*** tensor(2267.3782, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1882.2740, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8563621
Old  loss*** tensor(1188.0107, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1017.3674, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83965707
Old  loss*** tensor(1139.8612, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(957.0925, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81852615
Old  loss*** tensor(2481.3733, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2031.0690, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.85731924
Old  loss*** tensor(1446.7422, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1240.3199, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.876182
Old  loss*** tensor(1071.9783, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(939.2481, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86692554
Old  loss*** tensor(402.4312, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(348.8779, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8610555
Old  loss*** tensor(2218.0596, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1909.8724, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7469964
Old  loss*** tensor(4334.8628, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3238.1270, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8404962
Old  loss*** tensor(2223.7773, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1869.0764, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87015814
Old  loss*** tensor(656.8695, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(571.5803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8490783
Old  loss*** tensor(2115.1353, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1795.9154, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82222325
Old  loss*** tensor(3664.8347, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3013.3123, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.81890166
Old  loss*** tensor(2507.4358, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2053.3433, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9061125
Old  loss*** tensor(1615.8861, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1464.1746, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8582101
Old  loss*** tensor(2866.0217, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2459.6487, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9042263
Old  loss*** tensor(945.8036, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(855.2205, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8752017
Old  loss*** tensor(1271.0701, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1112.4426, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83338886
Old  loss*** tensor(2015.2283, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1679.4688, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8484119
Old  loss*** tensor(4777.5664, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(4053.3442, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8807572
Old  loss*** tensor(1798.7188, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1584.2345, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8037133
Old  loss*** tensor(3554.3269, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2856.6599, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8495938
Old  loss*** tensor(2228.1514, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1893.0237, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8900647
Old  loss*** tensor(1626.5801, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1447.7616, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8699018
Old  loss*** tensor(825.6687, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(718.2507, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8263851
Old  loss*** tensor(3197.2239, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2642.1382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8736426
Old  loss*** tensor(746.4588, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(652.1382, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84712994
Old  loss*** tensor(2420.6494, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2050.6045, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8706088
Old  loss*** tensor(558.2496, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(486.0170, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8460063
Old  loss*** tensor(1104.4828, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(934.3994, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83845145
Old  loss*** tensor(1614.4844, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1353.6667, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7729743
Old  loss*** tensor(2870.0522, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2218.4766, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83672994
Old  loss*** tensor(1664.5339, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1392.7654, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7715189
Old  loss*** tensor(4647.1855, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3585.3914, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77391934
Old  loss*** tensor(3450.9949, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2670.7917, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.80728936
Old  loss*** tensor(3787.0361, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3057.2339, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86189663
Old  loss*** tensor(2354.3457, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2029.2026, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.83475244
Old  loss*** tensor(1870.9247, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1561.7589, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89084095
Old  loss*** tensor(317.4581, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(282.8047, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8968573
Old  loss*** tensor(940.3403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(843.3511, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8728609
Old  loss*** tensor(1057.2651, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(922.8454, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8609291
Old  loss*** tensor(957.4686, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(824.3126, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8145008
Old  loss*** tensor(3307.8916, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2694.2803, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8772312
Old  loss*** tensor(1484.0833, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1301.8842, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8422852
Old  loss*** tensor(978.5168, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(824.1902, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.865662
Old  loss*** tensor(1061.9902, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(919.3246, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.888844
Old  loss*** tensor(1563.8834, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1390.0485, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8768029
Old  loss*** tensor(847.9526, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(743.4874, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8052449
Old  loss*** tensor(4129.8335, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3325.5273, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.91993713
Old  loss*** tensor(1167.9442, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1074.4353, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.877231
Old  loss*** tensor(568.3709, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(498.5926, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82962906
Old  loss*** tensor(3536.6812, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2934.1335, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8931273
Old  loss*** tensor(3924.6885, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3505.2466, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84042
Old  loss*** tensor(2786.4897, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2341.8218, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8011148
Old  loss*** tensor(2238.5403, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1793.3278, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8831262
Old  loss*** tensor(777.5234, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(686.6512, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8805623
Old  loss*** tensor(100.3503, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(88.3647, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8437096
Old  loss*** tensor(2815.8425, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2375.7534, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7888495
Old  loss*** tensor(3622.6780, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2857.7476, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.82094765
Old  loss*** tensor(3714.8286, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3049.6797, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.9019964
Old  loss*** tensor(1009.3945, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(910.4702, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.84560823
Old  loss*** tensor(1964.0942, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1660.8542, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87738776
Old  loss*** tensor(419.8632, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(368.3828, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.89547604
Old  loss*** tensor(1242.4559, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1112.5895, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8626088
Old  loss*** tensor(3179.1182, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2742.3352, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8836389
Old  loss*** tensor(1534.0088, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1355.5099, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8281987
Old  loss*** tensor(2040.9746, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1690.3325, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.7975669
Old  loss*** tensor(3381.6914, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2697.1250, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.87905157
Old  loss*** tensor(1607.9595, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(1413.4792, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86396813
Old  loss*** tensor(2768.1458, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2391.5896, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.77149224
Old  loss*** tensor(4524.2046, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3490.3887, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8117883
Old  loss*** tensor(2990.0161, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(2427.2603, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.86589116
Old  loss*** tensor(667.3651, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(577.8655, device='cuda:0', grad_fn=<MulBackward0>)
Batch inverse rewards score*** 0.8384185
Old  loss*** tensor(4337.8350, device='cuda:0', grad_fn=<NllLossBackward>)
New LOSS*** tensor(3636.9209, device='cuda:0', grad_fn=<MulBackward0>)

------------------------------------------------------------
Sender: LSF System <rer@dccxc029>
Subject: Job 628184: <python train.py -data data/splits/sarcasm -save_model rewards_model_normal -world_size 1 -train_steps 100000 -save_checkpoint_steps 5000 -gpu_ranks 0> in cluster <dcc> Done

Job <python train.py -data data/splits/sarcasm -save_model rewards_model_normal -world_size 1 -train_steps 100000 -save_checkpoint_steps 5000 -gpu_ranks 0> was submitted from host <dccxl004> by user <abhijimi> in cluster <dcc> at Wed Nov 13 04:50:11 2019
Job was executed on host(s) <dccxc029>, in queue <x86_24h>, as user <abhijimi> in cluster <dcc> at Wed Nov 13 04:50:12 2019
</u/abhijimi> was used as the home directory.
</dccstor/cssblr/abhijit/abhijit/SarcasmGAN/seq2seq_rl/OpenNMT_reinforcement> was used as the working directory.
Started at Wed Nov 13 04:50:12 2019
Terminated at Wed Nov 13 11:21:36 2019
Results reported at Wed Nov 13 11:21:36 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train.py -data data/splits/sarcasm -save_model rewards_model_normal -world_size 1 -train_steps 100000 -save_checkpoint_steps 5000 -gpu_ranks 0
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   23462.41 sec.
    Max Memory :                                 2405 MB
    Average Memory :                             2372.41 MB
    Total Requested Memory :                     162816.00 MB
    Delta Memory :                               160411.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                28
    Run time :                                   23497 sec.
    Turnaround time :                            23485 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/rewards-original/err> for stderr output of this job.

